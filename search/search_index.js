var __index = Promise.resolve({"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","tags":false},"docs":[{"location":"","text":"<p>Welcome! This documentation is focused on helping developers understand the Nano protocol, as well as setup, maintain and build on top of the Nano node. Details of how this documentation has been arranged are below:</p>    Section Details Audience     What is Nano? Take a high-level tour - this is a great place to learn about how Nano is uniquely suited to being a global digital currency. All users, node operators, developers   Running a Node Set up a Nano node to manage the ledger, create and publish blocks and participate in consensus. Node operators, developers   Integration Guides Learn practical concepts, structures and features for building wallets, payment systems and other services on the Nano network. Developers   Commands Explore an exhaustive list of interaction methods for the node via RPC and CLI. Node operators, developers   Protocol Design Dig deeper into the design and behaviors driving the protocol, including the election process, peering mechanics and more. Developers   Node Implementation Details of the Nano Foundation managed node implementation of the protocol. Developers   Releases Review past node releases and get details about the features coming soon in new releases. Everyone   Glossary Commonly used terms throughout the documentation and Nano ecosystem. Everyone    <p>Join the Community</p> <p>If you are looking for other details about Nano, links to wallets, discussions about the network and more, check out our community:</p>  <p>Nano.org | Forum | GitHub | Twitter | Discord | Reddit | Medium</p> <p>Facebook | LinkedIn | YouTube | Instagram</p>  <p>Change cookie settings</p>","title":"Nano Node and Protocol Documentation"},{"location":"glossary/","text":"","title":"Glossary"},{"location":"glossary/#account","text":"<p>Refers to an address (starts with <code>xrb_</code> or <code>nano_</code> which are interchangeable) that you control the private keys of. An address is a reinterpretation of the 256-bit public key using BASE32 encoding and a checksum. Previously supported <code>xrb-</code> or <code>nano-</code> prefixes are deprecated.</p>","title":"account"},{"location":"glossary/#active-transaction","text":"<p>A newly downloaded block to the node which enters into the voting process.</p>","title":"active transaction"},{"location":"glossary/#ad-hoc-accounts","text":"<p>Accounts not derived from a private seed which can be held in the node wallet through the wallet ID. These accounts are only recommended for use with advanced systems.</p>","title":"ad hoc accounts"},{"location":"glossary/#announcement-rounds","text":"<p>A repeating half-second cycle on the node during which votes are collected for active transactions in attempt to reach quorum.</p>","title":"announcement rounds"},{"location":"glossary/#block","text":"<p>A single Nano transaction. All new transactions (e.g. sends, receives, representative changes, etc) on the Nano Protocol are communicated via state blocks (since node V11). The account's entire state, including the balance after each transaction, is recorded in each block. Transaction amounts are interpreted as the difference in balance between consecutive blocks. Before V11, each transaction type (open, send, receive, change) had its own legacy block type.</p>","title":"Block"},{"location":"glossary/#block-hash","text":"<p>A 64 character, uppercase hexadecimal string (0-9A-F) value representing a unique block on an account.</p>","title":"block hash"},{"location":"glossary/#block-height","text":"<p>A local integer value that represents the order of a block in an account chain. For example, the 15th block in an account would have a block height of 15. Related to (but different from) confirmation height.</p>","title":"Block height"},{"location":"glossary/#block-lattice","text":"<p>The Block Lattice is a data-structure in which individual accounts control their own blockchain. This allows transactions to be added quickly without conflict and sent to the network for confirmation.</p>","title":"Block Lattice"},{"location":"glossary/#blocks-per-second-bps","text":"<p>The transmission rate of unconfirmed blocks (transactions) on the network. </p>","title":"Blocks Per Second (BPS)"},{"location":"glossary/#bootstrap-network","text":"<p>A sub-network established between peers via Transmission Control Protocol (TCP) for managing bulk transmission of blocks. This is used on initial bootstrapping of peers and when out-of-sync peers attempt to fill large gaps in their ledgers. This is available within all Nano networks (main, beta and test networks).</p>","title":"bootstrap network"},{"location":"glossary/#bootstrapping","text":"<p>During initial sync, the nano_node requests old transactions to independently verify and populate its local ledger database. Bootstrapping will also occur when the nano_node becomes out of sync with the network.</p>","title":"bootstrapping"},{"location":"glossary/#burn","text":"<p>When a 'burn' takes place, funds are sent to a specifc address that no one can access. Because no one can ever access funds sent to a burn address, it reduces the circulating supply.</p>","title":"burn"},{"location":"glossary/#circulating-supply","text":"<p>133,248,297.920938463463374607431768211455 Nano. This is the supply that resulted after burns were made from the genesis account, landing account and faucet account, following original distribution. Actual circulating supply is lower due to lost keys and sends to burn accounts. The original supply minus any amounts sent to the burn account can be found using the available_supply RPC.</p>","title":"circulating supply"},{"location":"glossary/#cementing","text":"<p>When a specific node marks a confirmed transaction as locally irreversible by setting the account's confirmation height (in the node database) to the now higher block height of the confirmed transaction. Cementing is a node-level operation.</p>","title":"Cementing"},{"location":"glossary/#confirmation","text":"<p>When a block (transaction) gathers enough votes from the network to pass quorum. Note that confirmed sends are irreversible (i.e. fully-settled), but the receiver must publish a corresponding receive block before they will be able to spend the receivable funds. Confirmation is a network-level decision.</p>","title":"Confirmation"},{"location":"glossary/#confirmation-height","text":"<p>A number stored in the local node database that represents the highest (most recent) confirmed block in an account chain. Related to (but different from) block height.</p>","title":"Confirmation Height"},{"location":"glossary/#confirmations-per-second-cps","text":"<p>The rate of confirmed blocks.</p>","title":"Confirmations Per Second (CPS)"},{"location":"glossary/#election","text":"","title":"election"},{"location":"glossary/#frontier","text":"<p>The most recent block added to the account chain. Also called the head block. Can be either confirmed or unconfirmed.</p>","title":"frontier"},{"location":"glossary/#genesis","text":"<p>The first account to be created, containing the maximum amount of Nano to ever exist. From here the funds were sent to other wallets; for distribution or to be burned.</p>","title":"genesis"},{"location":"glossary/#head-block","text":"<p>See frontier.</p>","title":"head block"},{"location":"glossary/#inbound-send","text":"<p>A block with funds being transferred to an account owned by a wallet on your node.</p>","title":"inbound send"},{"location":"glossary/#legacy-blocks","text":"<p>Blocks on an account chain before the first v1 block (which is often the v1 epoch block but can be other types). The first v1 block and all subsequent blocks are stateful blocks.</p>","title":"legacy blocks"},{"location":"glossary/#live-network","text":"<p>A sub-network established between peers via Transmission Control Protocol (TCP) for communicating newly published blocks, votes and other non-bootstrap related traffic. This is available within all Nano networks (main, beta and test networks). In versions prior to V19, this was done via User Datagram Protocol (UDP). UDP was retained as a fallback for peer connection for versions 19 and 20. As of V21, use of UDP is deprecated.</p>","title":"live network"},{"location":"glossary/#node-version","text":"<p>The version used to identify a unique release build of the node. Each node version is tied to a single protocol version, but they are updated independently.</p>","title":"node version"},{"location":"glossary/#online-voting-weight","text":"<p>Also called online stake, it is a trended value. The node samples online representative weights every 5 minutes across a rolling 2 week period. The online voting weight value is the median of those samples.</p>","title":"online voting weight"},{"location":"glossary/#peers","text":"<p>Nodes connected over the public internet to share Nano network data.</p>","title":"peers"},{"location":"glossary/#pending","text":"<p>See receivable</p>","title":"pending"},{"location":"glossary/#private-key","text":"<p>See wallet.</p>","title":"Private Key"},{"location":"glossary/#public-key","text":"<p>A public key is derived from a private key using the ED25519 elliptic curve algorithm. An address is a representation of the public key, see account for more info.</p>","title":"Public Key"},{"location":"glossary/#open-representative-voting-orv","text":"<p>A consensus mechanism unique to Nano which involves accounts delegating their balance as voting weight to Representatives. The Representatives vote themselves on the validity of transactions published to the network using the voting weight delegated to them. These votes are shared with their directly connected peers and they also rebroadcast votes seen from Principal Representatives. Votes are tallied and once quorum is reached on a published block, it is considered confirmed by the network.</p>","title":"Open Representative Voting (ORV)"},{"location":"glossary/#proof-of-work-pow","text":"<p>A Proof-of-Work is a piece of data which satisfies certain requirements and is difficult (costly, time-consuming) to produce, but easy for others to verify. In some systems this data is a central part of the security model used to protect against double-spends and other types of attacks, but with Nano it is only used to increase economic costs of spamming the network.</p>","title":"Proof-of-Work (PoW)"},{"location":"glossary/#principal-representative","text":"<p>A Nano account with &gt;= 0.1% of the online voting weight delegated to it. When configured on a node which is voting, the votes it produces will be rebroadcasted by other nodes to who receive them, helping the network reach consensus more quickly.</p>","title":"Principal Representative"},{"location":"glossary/#protocol-version","text":"<p>The version used to identify the set of protocol rules nodes are required to follow in order to properly communicate with peers. Nodes running older protocol versions are periodically de-peered on the network to keep communication efficient - see Active Releases and Inactive Releases for the latest versions allowed to peer with one another.</p>","title":"protocol version"},{"location":"glossary/#qualified-root","text":"<p>The concatenation of the root and previous attributes of a block. For the first block on an account, this would be is the account public key following by 32 zero bytes. For the second or higher block on an account, this would be the previous field repeated twice (root + previous, where root == previous).</p>","title":"qualified root"},{"location":"glossary/#quorum","text":"<p>When the delta between the two successive blocks of a root is &gt; 67% of the online voting weight.</p>","title":"quorum"},{"location":"glossary/#receivable","text":"<p>A transaction state where a block sending funds was published and confirmed by the network, but a matching block receiving those funds has not yet been confirmed.</p>","title":"receivable"},{"location":"glossary/#representative","text":"<p>A Nano account with &gt; 0 voting weight, but &lt; 0.1% of the online voting weight, delegated to it. Unlike Principal Representatives, when configured on a node which is voting, the votes it produces and sends to directly connected peers won't be rebroadcasted by those peers.</p>","title":"Representative"},{"location":"glossary/#root","text":"<p>If the block is the first block on the account, the root is the account public key. Otherwise it is the previous hash included in the block. The root of a block can never be zero.</p>","title":"root"},{"location":"glossary/#seed","text":"<p>A 256-bit random value usually represented to the user as a 64 character hexidecimal (0-9 and A-F) value. Private keys are derived from a seed.</p>","title":"seed"},{"location":"glossary/#transactions-per-second-tps","text":"<p>Historically, TPS was a per-node measurement that represented a node's perception of the rate of transactions on the network (BPS). This measurement was found to be inaccurate due to peering and propagation differences between nodes, so CPS is now the preferred term for describing overall Nano network scalability. It's also important to note that while Nano sends do not require a corresponding receive to be confirmed, a receive block must be confirmed before received funds can be sent again (see receivable).</p>","title":"Transactions Per Second (TPS)"},{"location":"glossary/#unchecked-blocks","text":"<p>Blocks (transactions) that have been downloaded but not yet processed by the Nano node. The node software downloads all blocks from other nodes as unchecked, processes them and adds to block count, confirms the frontier blocks for each account, and then marks them as cemented.</p>","title":"unchecked (blocks)"},{"location":"glossary/#unopened-account","text":"<p>An account address that does not have a first block on it (which must be a block to receive Nano sent from another account, cannot be a block only changing the Representative).</p>","title":"unopened account"},{"location":"glossary/#unpocketed","text":"<p>See receivable.</p>","title":"unpocketed"},{"location":"glossary/#vote-by-hash","text":"<p>Allows representatives to only include the hash of a block in each vote to save bandwidth. Before vote-by-hash was activated the entire block contents were required.</p>","title":"vote-by-hash"},{"location":"glossary/#voting","text":"<p>Each node configured with a Representative votes on every block by appending their Representative signature and a sequence number to the hash. These will be sent out to directly connected peers and if the vote originates from a Principal Representative, it will subsequently be rebroadcasted by nodes to their peers.</p>","title":"voting"},{"location":"glossary/#voting-weight","text":"<p>The amount of weight delegated to a Representative.</p>","title":"voting weight"},{"location":"glossary/#wallet","text":"<p>A wallet is an organizational object in a nano_node that holds a single seed from which multiple accounts are deterministically derived via a 32-bit unsigned integer index starting at 0. Private keys are derived from the seed and index as follows: (<code>||</code> means concatenation; <code>blake2b</code> is a highly optimized cryptographic hash function)</p>   k_{private} = blake2b(\\text{seed} || \\text{index})","title":"wallet"},{"location":"glossary/#wallet_id","text":"<p>A 256-bit random value name/identifier for a specific wallet in the local nano_node database. The WALLET_ID is not stored anywhere in the network and is only used in the local nano_node. Even though a WALLET_ID looks identical to a seed, do not confuse the WALLET_ID with a seed; funds cannot be restored with a WALLET_ID. Do not backup the WALLET_ID as a means to backup funds.</p>","title":"WALLET_ID"},{"location":"glossary/#work-peers","text":"<p>Node peers which are configured to generate work for transactions at the originating nodes request.</p>","title":"work peers"},{"location":"articles/readme/","text":"<p>Please see https://github.com/nanocurrency/nano-docs/issues/555 for details the article management process and list of ideas.</p>","title":"Readme"},{"location":"commands/command-line-interface/","text":"","title":"Command Line Interface"},{"location":"commands/command-line-interface/#nano_node-commands","text":"","title":"nano_node commands"},{"location":"commands/command-line-interface/#-account_create-walletwallet","text":"<p>Insert next deterministic key into <code>&lt;wallet&gt;</code></p>","title":"--account_create --wallet=<code>&lt;wallet&gt;</code>"},{"location":"commands/command-line-interface/#-account_get-keykey","text":"<p>Get account number for the <code>&lt;key&gt;</code></p>","title":"--account_get --key=<code>&lt;key&gt;</code>"},{"location":"commands/command-line-interface/#-account_key-accountaccount","text":"<p>Get the public key for <code>&lt;account&gt;</code></p>","title":"--account_key --account=<code>&lt;account&gt;</code>"},{"location":"commands/command-line-interface/#-clear_send_ids","text":"<p>Remove all send IDs from the database (dangerous: not intended for production use)</p>","title":"--clear_send_ids"},{"location":"commands/command-line-interface/#-compare_rep_weights","text":"<p>version 21.0+ Displays a summarized comparison between the hardcoded bootstrap weights and representative weights from the ledger. Full comparison is output to logs. Optional <code>--data_path</code>.</p> <ul> <li>Differences between total weights (<code>hardcoded weight</code> and <code>ledger weight</code>) are due to unreceived (pending) blocks</li> <li><code>mismatched</code>:<ul> <li><code>samples</code>: the number of mismatched samples is equal to the number of hardcoded weights, even those with zero mismatch</li> <li><code>total</code>: sum of the absolute difference between individual samples from hardcoded and ledger weights</li> <li><code>mean</code>: <code>total</code> divided by <code>samples</code></li> <li><code>sigma</code>: from the samples, a distribution N(\\mu, \\sigma) is obtained</li> </ul> </li> <li><code>outliers</code>: mismatch samples above \\mu + \\sigma\\mu + \\sigma, for potential inspection</li> <li><code>newcomers</code>: large voting weights found in the ledger but not hardcoded, for potential inspection</li> </ul>","title":"--compare_rep_weights"},{"location":"commands/command-line-interface/#-config-keyvalue","text":"<p>version 20.0+ Valid for both nano_node and nano_wallet processes Pass node configuration values. This takes precedence over any values in the configuration file. This option can be repeated multiple times.</p>","title":"--config key=value"},{"location":"commands/command-line-interface/#-confirmation_height_clear","text":"<p>version 19.0+ Sets the confirmation heights of all accounts to 0. Optional <code>--account</code> to only reset a single account. Do not use while the node is running.</p>","title":"--confirmation_height_clear"},{"location":"commands/command-line-interface/#-daemon","text":"<p>Start node daemon. Since version 19.0, network and path will be output, similar to: <pre><code>./nano_node --daemon --network test\nNetwork: test, version: 19.0\nPath: /home/USER/NanoTest\n</code></pre></p>","title":"--daemon"},{"location":"commands/command-line-interface/#-data_pathpath","text":"<p>Use the supplied <code>&lt;path&gt;</code> as the data directory.</p>","title":"--data_path=<code>&lt;path&gt;</code>"},{"location":"commands/command-line-interface/#-diagnostics","text":"<p>Run internal diagnostics and validate existing config file (or create default config file if it doesn't exist)</p>","title":"--diagnostics"},{"location":"commands/command-line-interface/#-final_vote_clear","text":"<p>Either specify a single <code>--root</code> to clear or <code>--all</code> to clear all final votes (not recommended)</p>","title":"--final_vote_clear"},{"location":"commands/command-line-interface/#-generate_config-noderpc","text":"<p>version 20.0+ Write configuration to stdout, populated with commented-out defaults suitable for this system. Pass the configuration type, <code>node</code> or <code>rpc</code>. If <code>--use_defaults</code> is passed, the generated config will not have values commented-out. This is not recommended except for testing and debugging.</p> <p>The output can be piped to a file, using the locations defined in configuration.</p>","title":"--generate_config node|rpc"},{"location":"commands/command-line-interface/#-help","text":"<p>Print out options</p>","title":"--help"},{"location":"commands/command-line-interface/#-initialize","text":"<p>version 23.0+ Initializes the data folder, if it is not already initialized. This command is meant to be run when the data folder is empty, to populate it with the ledger containing only the genesis block.</p>","title":"--initialize"},{"location":"commands/command-line-interface/#-key_create","text":"<p>Generates a adhoc random keypair and prints it to stdout</p>","title":"--key_create"},{"location":"commands/command-line-interface/#-key_expand-keykey","text":"<p>Derive public key and account number from <code>&lt;key&gt;</code></p>","title":"--key_expand --key=<code>&lt;key&gt;</code>"},{"location":"commands/command-line-interface/#-migrate_database_lmdb_to_rocksdb","text":"<p>version 22.0+ Deletes existing rocksdb subfolder if it exists and migrates the ledger from LMDB to RocksDB. Does not delete the data.ldb file afterwards. NOTE: config files must still be updated to enable RocksDB after database is migrated. You must also stop the node using the <code>stop</code> RPC.</p>","title":"--migrate_database_lmdb_to_rocksdb"},{"location":"commands/command-line-interface/#-network","text":"<p>version 19.0+ Allows selection of a different network at runtime. Values <code>live</code>, <code>beta</code> and <code>test</code> supported.</p>","title":"--network"},{"location":"commands/command-line-interface/#-online_weight_clear","text":"<p>version 18.0+ Clear record history for long term online weight trending</p>","title":"--online_weight_clear"},{"location":"commands/command-line-interface/#-peer_clear","text":"<p>version 18.0+ Clear cached peers</p>","title":"--peer_clear"},{"location":"commands/command-line-interface/#-rebuild_database","text":"<p>version 21.0+ Rebuild LMDB database with <code>--vacuum</code> for best compaction. Requires approximately <code>data.ldb size * 2</code> free space on disk.</p>","title":"--rebuild_database"},{"location":"commands/command-line-interface/#-rpcconfig-keyvalue","text":"<p>version 22.0+ Valid for both nano_node and nano_wallet processes Pass RPC configuration values. This takes precedence over any values in the configuration file. This option can be repeated multiple times.</p>","title":"--rpcconfig key=value"},{"location":"commands/command-line-interface/#-snapshot","text":"<p>Compact database and create snapshot, functions similar to vacuum but does not replace the existing database. Optional <code>--unchecked_clear</code>, <code>--clear_send_ids</code>, <code>--online_weight_clear</code>, <code>--peer_clear</code>. Optional <code>--confirmation_height_clear</code> in version 19.0+.</p>","title":"--snapshot"},{"location":"commands/command-line-interface/#-unchecked_clear","text":"<p>Clear unchecked blocks</p>","title":"--unchecked_clear"},{"location":"commands/command-line-interface/#-vacuum","text":"<p>Compact database. If data_path is missing, the database in data directory is compacted. Optional <code>--unchecked_clear</code>, <code>--clear_send_ids</code>, <code>--online_weight_clear</code>, <code>--peer_clear</code>. Optional <code>--confirmation_height_clear</code> in version 19.0+. Optional <code>--rebuild_database</code> in version 21.0+. Requires approximately <code>data.ldb size * 2</code> free space on disk.</p>","title":"--vacuum"},{"location":"commands/command-line-interface/#-validate_blocks","text":"<p>version 21.0+ (version 19.0+ as <code>--debug_validate_blocks</code>) Validate blocks in the ledger, includes checks for confirmation height. Optional <code>--threads</code> for multithreaded validation in version 21.0+. Multithreaded validation can limit other host operations with high I/O &amp; CPU usage.</p>","title":"--validate_blocks"},{"location":"commands/command-line-interface/#-version","text":"<p>Prints out version</p>","title":"--version"},{"location":"commands/command-line-interface/#-vote_dump","text":"<p>Dump most recent votes from representatives</p>","title":"--vote_dump"},{"location":"commands/command-line-interface/#-wallet_add_adhoc-walletwallet-keykey","text":"<p>Insert <code>&lt;key&gt;</code> in to <code>&lt;wallet&gt;</code></p>","title":"--wallet_add_adhoc --wallet=<code>&lt;wallet&gt;</code> --key=<code>&lt;key&gt;</code>"},{"location":"commands/command-line-interface/#-wallet_create-seedseed-passwordpassword","text":"<p>Creates a new wallet with optional <code>&lt;seed&gt;</code> and optional <code>&lt;password&gt;</code>, and prints the ID. Note the legacy <code>--key</code> option can still be used and will function the same as <code>--seed</code>. Use --wallet-list to retrieve the wallet ID in the future.</p>","title":"--wallet_create --seed=<code>&lt;seed&gt;</code> --password=<code>&lt;password&gt;</code>"},{"location":"commands/command-line-interface/#-wallet_change_seed-walletwallet-seedseed","text":"<p>Changes seed for <code>&lt;wallet&gt;</code> to <code>&lt;seed&gt;</code>.  Note the legacy <code>--key</code> option can still be used and will function the same as <code>--seed</code>.</p>","title":"--wallet_change_seed --wallet=<code>&lt;wallet&gt;</code> --seed=<code>&lt;seed&gt;</code>"},{"location":"commands/command-line-interface/#-wallet_decrypt_unsafe-walletwallet-passwordpassword","text":"<p>Decrypts <code>&lt;wallet&gt;</code> using <code>&lt;password&gt;</code> </p>  <p>Danger</p> <p>USE WITH CAUTION: THIS WILL PRINT YOUR PRIVATE KEY AND SEED TO STDOUT</p>  <p>If you didn't set password yet, use --wallet_decrypt_unsafe --wallet=<code>&lt;wallet&gt;</code></p>","title":"--wallet_decrypt_unsafe --wallet=<code>&lt;wallet&gt;</code> --password=<code>&lt;password&gt;</code>"},{"location":"commands/command-line-interface/#-wallet_destroy-walletwallet","text":"<p>Destroys <code>&lt;wallet&gt;</code> and all keys it contains</p>","title":"--wallet_destroy --wallet=<code>&lt;wallet&gt;</code>"},{"location":"commands/command-line-interface/#-wallet_import-filefilepath-walletwallet-passwordpassword","text":"<p>Imports keys in <code>&lt;filepath&gt;</code> using <code>&lt;password&gt;</code> in to <code>&lt;wallet&gt;</code>. If the provided wallet id does not exist and <code>--force</code> is included, a new wallet will be created with the provided wallet id value, and the json file will be imported as is with existing seed and password (instead of a set of private keys without a change of seed).</p>","title":"--wallet_import  --file=<code>&lt;filepath&gt;</code> --wallet=<code>&lt;wallet&gt;</code> --password=<code>&lt;password&gt;</code>"},{"location":"commands/command-line-interface/#-wallet_list","text":"<p>Dumps wallet IDs and public keys</p>","title":"--wallet_list"},{"location":"commands/command-line-interface/#-wallet_remove-walletwallet-accountaccount","text":"<p>Remove <code>&lt;account&gt;</code> from <code>&lt;wallet&gt;</code></p>","title":"--wallet_remove --wallet=<code>&lt;wallet&gt;</code> --account=<code>&lt;account&gt;</code>"},{"location":"commands/command-line-interface/#-wallet_representative_get-walletwallet","text":"<p>Prints default representative for <code>&lt;wallet&gt;</code></p>","title":"--wallet_representative_get --wallet=<code>&lt;wallet&gt;</code>"},{"location":"commands/command-line-interface/#-wallet_representative_set-walletwallet-accountaccount","text":"<p>Set <code>&lt;account&gt;</code> as default representative for <code>&lt;wallet&gt;</code></p>","title":"--wallet_representative_set --wallet=<code>&lt;wallet&gt;</code> --account=<code>&lt;account&gt;</code>"},{"location":"commands/command-line-interface/#launch-options","text":"<p>When initially starting the nano_node or nano_wallet as a service the following launch options are available.</p>  <p>Intended for developer use</p> <p>These options are only for developer use so please understand the impacts before use.</p>","title":"Launch options"},{"location":"commands/command-line-interface/#-allow_bootstrap_peers_duplicates","text":"<p>version 21.0+ Allow multiple connections to the same peer in bootstrap attempts</p>","title":"--allow_bootstrap_peers_duplicates"},{"location":"commands/command-line-interface/#-block_processor_batch_size","text":"<p>Increase block processor transaction batch write size, default 0 (limited by config block_processor_batch_max_time), 256k for fast_bootstrap</p>","title":"--block_processor_batch_size"},{"location":"commands/command-line-interface/#-block_processor_full_size","text":"<p>Increase block processor allowed blocks queue size before dropping live network packets and holding bootstrap download, default 65536, 1 million for fast_bootstrap</p>","title":"--block_processor_full_size"},{"location":"commands/command-line-interface/#-block_processor_verification_size","text":"<p>Increase batch signature verification size in block processor, default 0 (limited by config signature_checker_threads), unlimited for fast_bootstrap</p>","title":"--block_processor_verification_size"},{"location":"commands/command-line-interface/#-disable_add_initial_peers","text":"<p>version 23.0+ Disables the add initial peers function called on startup which reads the peers table and contacts all the peers listed in it</p>","title":"--disable_add_initial_peers"},{"location":"commands/command-line-interface/#-disable_backup","text":"<p>Turn off automatic wallet backup process</p>","title":"--disable_backup"},{"location":"commands/command-line-interface/#-disable_block_processor_unchecked_deletion","text":"<p>version 21.0+ Disable deletion of unchecked blocks after processing.</p>","title":"--disable_block_processor_unchecked_deletion"},{"location":"commands/command-line-interface/#-disable_bootstrap_listener","text":"<p>Turn off listener on the bootstrap network so incoming TCP (bootstrap) connections are rejected. Note: this does not impact TCP traffic for the live network.</p>","title":"--disable_bootstrap_listener"},{"location":"commands/command-line-interface/#-disable_lazy_bootstrap","text":"<p>Turn off use of lazy bootstrap</p>","title":"--disable_lazy_bootstrap"},{"location":"commands/command-line-interface/#-disable_legacy_bootstrap","text":"<p>Turn off use of legacy bootstrap</p>","title":"--disable_legacy_bootstrap"},{"location":"commands/command-line-interface/#-disable_ongoing_bootstrap","text":"<p>version 23.0+ Turn off the ability for ongoing bootstraps to occur</p>","title":"--disable_ongoing_bootstrap"},{"location":"commands/command-line-interface/#-disable_providing_telemetry_metrics","text":"<p>version 21.0+ Do not provide any telemetry data to nodes requesting it. Responses are still made to requests, but they will have an empty payload.</p>","title":"--disable_providing_telemetry_metrics"},{"location":"commands/command-line-interface/#-disable_rep_crawler","text":"<p>version 23.0+ Turn off the rep crawler process</p>","title":"--disable_rep_crawler"},{"location":"commands/command-line-interface/#-disable_request_loop","text":"<p>version 23.0+ Turn off the request loop</p>","title":"--disable_request_loop"},{"location":"commands/command-line-interface/#-disable_tcp_realtime","text":"<p>version 19.0+ Turn off use of TCP live network (TCP for bootstrap will remain available)</p>","title":"--disable_tcp_realtime"},{"location":"commands/command-line-interface/#-disable_unchecked_cleanup","text":"<p>Prevent periodic cleaning of unchecked table</p>","title":"--disable_unchecked_cleanup"},{"location":"commands/command-line-interface/#-disable_unchecked_drop","text":"<p>Prevent drop of all unchecked entries at node/wallet start</p>","title":"--disable_unchecked_drop"},{"location":"commands/command-line-interface/#-disable_wallet_bootstrap","text":"<p>Turn off use of wallet-based bootstrap</p>","title":"--disable_wallet_bootstrap"},{"location":"commands/command-line-interface/#-enable_udp","text":"<p>version 21.0+ Turn on use of the UDP live network.</p>","title":"--enable_udp"},{"location":"commands/command-line-interface/#-fast_bootstrap","text":"<p>Increase bootstrap processor limits to allow more blocks before hitting full state and verify/write more per database call. Also disable deletion of processed unchecked blocks.</p>","title":"--fast_bootstrap"},{"location":"commands/command-line-interface/#-inactive_votes_cache_size","text":"<p>version 21.0+ Increase cached votes without active elections size, default 16384</p>","title":"--inactive_votes_cache_size"},{"location":"commands/command-line-interface/#-vote_processor_capacity","text":"<p>version 21.0+ Vote processor queue size before dropping votes, default 144k</p>","title":"--vote_processor_capacity"},{"location":"commands/command-line-interface/#debug-commands","text":"","title":"Debug commands"},{"location":"commands/command-line-interface/#-debug_account_count","text":"<p>Display the number of accounts</p>","title":"--debug_account_count"},{"location":"commands/command-line-interface/#-debug_account_versions","text":"<p>version 20.0+ Display the total counts of each version for all accounts (including unpocketed)</p>","title":"--debug_account_versions"},{"location":"commands/command-line-interface/#-debug_block_count","text":"<p>Display the number of blocks</p>","title":"--debug_block_count"},{"location":"commands/command-line-interface/#-debug_block_dump","text":"<p>version 23.0+ Print ledger blocks - use with caution due to the potentially large amount of data this can output</p>","title":"--debug_block_dump"},{"location":"commands/command-line-interface/#-debug_bootstrap_generate","text":"<p>Generate bootstrap sequence of blocks</p>","title":"--debug_bootstrap_generate"},{"location":"commands/command-line-interface/#-debug_cemented_block_count","text":"<p>version 19.0+ Display the number of cemented blocks (blocks which are under the confirmation height of their accounts)</p>","title":"--debug_cemented_block_count"},{"location":"commands/command-line-interface/#-debug_dump_frontier_unchecked_dependents","text":"<p>version 19.0+ Dump frontiers which have matching unchecked keys</p>","title":"--debug_dump_frontier_unchecked_dependents"},{"location":"commands/command-line-interface/#-debug_dump_online_weight","text":"<p>List online weights table and current online_weights value</p>","title":"--debug_dump_online_weight"},{"location":"commands/command-line-interface/#-debug_dump_representatives","text":"<p>List representatives and weights</p>","title":"--debug_dump_representatives"},{"location":"commands/command-line-interface/#-debug_generate_crash_report","text":"<p>version 21.0+ After a node crash on linux, this command reads the dump files generated from that crash and produces a \"nano_node_crash_report.txt\" file. Requires <code>addr2line</code> to be installed on the system. See the troubleshooting guide for more information.</p>","title":"--debug_generate_crash_report"},{"location":"commands/command-line-interface/#-debug_opencl","text":"<p>Profile OpenCL work generation for (optional) <code>--device=&lt;device&gt;</code> on <code>--device=&lt;platform&gt;</code> using <code>--threads=&lt;threads&gt;</code> count. To retrieve available platforms &amp; devices run --diagnostics. </p>","title":"--debug_opencl"},{"location":"commands/command-line-interface/#-debug_output_last_backtrace_dump","text":"<p>version 19.0+ Output the stacktrace stored after a node crash. </p> <p>Optionals <code>--difficulty</code> and <code>--multiplier</code> (only the latter is used if both given) in version 21.0+ to set the work generation threshold.</p>","title":"--debug_output_last_backtrace_dump"},{"location":"commands/command-line-interface/#-debug_profile_bootstrap","text":"<p>Profile simulated bootstrap process</p>","title":"--debug_profile_bootstrap"},{"location":"commands/command-line-interface/#-debug_profile_generate","text":"<p>Profile work generation Optional <code>--pow_sleep_interval</code> in version 19.0+ which sets an amount to sleep (in nanoseconds) between batches of POW calculations when using the CPU. Optionals <code>--difficulty</code> and <code>--multiplier</code> (only the latter is used if both given) in version 21.0+ to set the work generation threshold.</p>","title":"--debug_profile_generate"},{"location":"commands/command-line-interface/#-debug_profile_validate","text":"<p>Profile work validation</p>","title":"--debug_profile_validate"},{"location":"commands/command-line-interface/#-debug_profile_kdf","text":"<p>Profile kdf function</p>","title":"--debug_profile_kdf"},{"location":"commands/command-line-interface/#-debug_profile_sign","text":"<p>Profile signature generation</p>","title":"--debug_profile_sign"},{"location":"commands/command-line-interface/#-debug_profile_votes","text":"<p>Profile vote verification</p>","title":"--debug_profile_votes"},{"location":"commands/command-line-interface/#-debug_profile_frontiers_confirmation","text":"<p>version 21.0+ Profile frontiers confirmation speed</p>","title":"--debug_profile_frontiers_confirmation"},{"location":"commands/command-line-interface/#-debug_rpc","text":"<p>version 18.0+ Allows running RPC commands without enabling the RPC server. Not recommended for daily usage. Example: <code>echo '{\"action\": \"block_count\"}' | nano_node --debug_rpc</code></p>","title":"--debug_rpc"},{"location":"commands/command-line-interface/#-debug_stacktrace","text":"<p>version 20.0+ Prints a stacktrace example, useful to verify that it includes the desired information, such as files, function names and line numbers</p>","title":"--debug_stacktrace"},{"location":"commands/command-line-interface/#-debug_sys_logging","text":"<p>version 19.0+ On *nix system this checks writing to the system log. On Windows it writes to the event viewer, a registry entry needs to exist for this to work correctly which can be created by running this command for the first time as an administrator</p>","title":"--debug_sys_logging"},{"location":"commands/command-line-interface/#-debug_unconfirmed_frontiers","text":"<p>version 22.0+ Prints the account, height, frontiers and cemented frontier for all accounts which are not fully confirmed. Sorted by height in descending order</p>","title":"--debug_unconfirmed_frontiers"},{"location":"commands/command-line-interface/#-debug_validate_blocks","text":"<p>Alias to <code>--validate_blocks</code></p>","title":"--debug_validate_blocks"},{"location":"commands/command-line-interface/#-debug_verify_profile","text":"<p>Profile signature verification</p>","title":"--debug_verify_profile"},{"location":"commands/command-line-interface/#deprecated-commands","text":"","title":"Deprecated commands"},{"location":"commands/command-line-interface/#launch-options_1","text":"","title":"Launch options"},{"location":"commands/command-line-interface/#-disable_udp","text":"<p>version 21.0+ This option has been deprecated and will be removed in future versions. It has no effect because it is now the default.</p> <p>version 19.0+ Turn off use of UDP live network</p>","title":"--disable_udp"},{"location":"commands/command-line-interface/#removed-commands","text":"","title":"Removed commands"},{"location":"commands/command-line-interface/#debug","text":"","title":"Debug"},{"location":"commands/command-line-interface/#-debug_mass_activity","text":"<p>Generates fake debug activity. Deprecated in v21 and removed in v22. Use <code>slow_test --gtest_filter=system.generate_mass_activity</code> instead.</p>","title":"--debug_mass_activity"},{"location":"commands/command-line-interface/#-debug_xorshift_profile","text":"<p>Profile xorshift algorithms</p>","title":"--debug_xorshift_profile"},{"location":"commands/command-line-interface/#launch-options_2","text":"","title":"Launch options"},{"location":"commands/command-line-interface/#-batch_size","text":"<p>version 18.0+ Increase sideband upgrade batch size (default 512). Deprecated in v21 and removed in v22 as no longer required.</p>","title":"--batch_size"},{"location":"commands/rpc-protocol/","text":"<p>The RPC protocol accepts JSON HTTP POST requests. The following are RPC commands along with the responses that are expected. This page is split into the following sections:</p>    Section Purpose     Node RPCs For interacting with the node and ledger.   Wallet RPCs For interacting with the built-in, QT-based node wallet. NOTE: This wallet is only recommended for development and testing.   Unit Conversion RPCs For converting different units to and from raw.   Deprecated RPCs No longer recommended for use.","title":"RPC Protocol"},{"location":"commands/rpc-protocol/#node-rpcs","text":"<p>Unconfirmed blocks returned</p> <p>Unless otherwise specified, RPC calls can return unconfirmed blocks and related details. In the most important cases where balances or similar details may include unconfirmed amounts, additional warnings have been included. Refer to Block confirmation procedures for details.</p>","title":"Node RPCs"},{"location":"commands/rpc-protocol/#account_balance","text":"<p>Returns how many RAW is owned and how many have not yet been received by account </p>  <p>The term <code>pending</code> is being deprecated in favor of <code>receivable</code>. For compatibility reasons both terms are still available for many calls and in responses. For more details see: https://docs.nano.org/releases/release-v23-0/#pendingreceivable-term-rpc-updates.</p>  <p>Request: <pre><code>{\n  \"action\": \"account_balance\",\n  \"account\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"balance\": \"10000\",\n  \"pending\": \"10000\",\n  \"receivable\": \"10000\"\n}\n</code></pre></p> <p>Optional \"include_only_confirmed\" version 22.0+  Boolean, true by default. Results in <code>balance</code> only including blocks on this account that have already been confirmed and <code>receivable</code> only including incoming send blocks that have already been confirmed on the sending account.</p>","title":"account_balance"},{"location":"commands/rpc-protocol/#account_block_count","text":"<p>Get number of blocks for a specific account </p> <p>Request: <pre><code>{\n  \"action\": \"account_block_count\",\n  \"account\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"block_count\" : \"19\"\n}\n</code></pre></p>","title":"account_block_count"},{"location":"commands/rpc-protocol/#account_get","text":"<p>Get account number for the public key </p> <p>Request: <pre><code>{\n  \"action\": \"account_get\",\n  \"key\": \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\"\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"account\" : \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\"\n}\n</code></pre></p>","title":"account_get"},{"location":"commands/rpc-protocol/#account_history","text":"<p>Reports send/receive information for an account. Returns only send &amp; receive blocks by default (unless raw is set to true - see optional parameters below): change, state change &amp; state epoch blocks are skipped, open &amp; state open blocks will appear as receive, state receive/send blocks will appear as receive/send entries. Response will start with the latest block for the account (the frontier), and will list all blocks back to the open block of this account when \"count\" is set to \"-1\". Note: \"local_timestamp\" returned since version 18.0, \"height\" field returned since version 19.0 and \"confirmed\" returned since version 23.0</p>  <p>Includes unconfirmed blocks</p> <p>This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network.</p>  <p>Request: <pre><code>{\n  \"action\": \"account_history\",\n  \"account\": \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\",\n  \"count\": \"1\"\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"account\": \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\",\n  \"history\": [\n    {\n      \"type\": \"send\",\n      \"account\": \"nano_38ztgpejb7yrm7rr586nenkn597s3a1sqiy3m3uyqjicht7kzuhnihdk6zpz\",\n      \"amount\": \"80000000000000000000000000000000000\",\n      \"local_timestamp\": \"1551532723\",\n      \"height\": \"60\",\n      \"hash\": \"80392607E85E73CC3E94B4126F24488EBDFEB174944B890C97E8F36D89591DC5\",\n      \"confirmed\": \"true\"\n    }\n  ],\n  \"previous\": \"8D3AB98B301224253750D448B4BD997132400CEDD0A8432F775724F2D9821C72\"\n}\n</code></pre></p> <p>If the <code>count</code> limit results in stopping before the end of the account chain, then the response will also contain a <code>previous</code> field (outside of the <code>history</code> field) which contains the block hash that would be next to process if <code>count</code> was larger.</p> <p>Optional parameters:</p> <ul> <li><code>raw</code> (bool): if set to <code>true</code> instead of the default <code>false</code>, instead of outputting a simplified send or receive explanation of blocks (intended for wallets), output all parameters of the block itself as seen in block_create or other APIs returning blocks. It still includes the \"account\" and \"amount\" properties you'd see without this option.  State/universal blocks in the raw history will also have a <code>subtype</code> field indicating their equivalent \"old\" block. Unfortunately, the \"account\" parameter for open blocks is the account of the source block, not the account of the open block, to preserve similarity with the non-raw history.   </li> <li><code>head</code> (64 hexadecimal digits string, 256 bit): instead of using the latest block for a specified account, use this block as the head of the account instead. Useful for pagination.   </li> <li><code>offset</code> (decimal integer): skips a number of blocks starting from <code>head</code> (if given). Not often used. Available since version 11.0 </li> <li><code>reverse</code> (bool): if set to <code>true</code> instead of the default <code>false</code>, the response starts from <code>head</code> (if given, otherwise the first block of the account), and lists blocks up to the frontier (limited by \"count\"). Note: the field <code>previous</code> in the response changes to <code>next</code>. Available since version 19.0 </li> <li><code>account_filter</code> (array of public addresses): results will be filtered to only show sends/receives connected to the provided account(s). Available since version 19.0. Note: In v19.0, this option does not handle receive blocks; fixed in v20.0.</li> </ul>","title":"account_history"},{"location":"commands/rpc-protocol/#account_info","text":"<p>Returns frontier, open block, change representative block, balance, last modified timestamp from local database &amp; block count for account. Only works for accounts that have received their first transaction and have an entry on the ledger, will return \"Account not found\" otherwise. To open an account, use receive.  </p>  <p>Unconfirmed information</p> <p>This call returns information that may be based on unconfirmed blocks. These details should not be relied on for any process or integration that requires confirmed blocks. The balance is obtained from the frontier, which may be unconfirmed. As long as you follow the guidelines, you can rely on the balance for the purposes of creating transactions for this account. If the frontier is never confirmed, then the blocks that proceed it will also never be confirmed.</p> <p>If you need only details for confirmed blocks, use the <code>include_confirmed</code> option below and referenced the <code>confirmed_*</code> fields added in to the response.</p>  <p>Request: <pre><code>{\n  \"action\": \"account_info\",\n  \"account\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"frontier\": \"FF84533A571D953A596EA401FD41743AC85D04F406E76FDE4408EAED50B473C5\",\n  \"open_block\": \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\",\n  \"representative_block\": \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\",\n  \"balance\": \"235580100176034320859259343606608761791\",\n  \"modified_timestamp\": \"1501793775\",\n  \"block_count\": \"33\",\n  \"account_version\": \"1\",\n  \"confirmation_height\" : \"28\",\n  \"confirmation_height_frontier\" : \"34C70FCA0952E29ADC7BEE6F20381466AE42BD1CFBA4B7DFFE8BD69DF95449EB\"\n}\n</code></pre></p> <p>In response <code>confirmation_height</code> only available for version 19.0+ In response <code>confirmation_height_frontier</code> only available for version 21.0+ which is the block hash at that confirmation height.  </p> <p>Optional \"include_confirmed\" version 22.0+  Boolean, false by default. Adds new return fields with prefix of <code>confirmed_</code> for consistency:</p> <ul> <li><code>confirmed_balance</code>: balance for only blocks on this account that have already been confirmed</li> <li><code>confirmed_height</code>: matches <code>confirmation_height</code> value</li> <li><code>confirmed_frontier</code>: matches <code>confirmation_height_frontier</code> value</li> <li>If <code>representative</code> option also <code>true</code>, <code>confirmed_representative</code> included: representative account from the confirmed frontier block</li> <li>If <code>receivable</code> option also <code>true</code>, <code>confirmed_receivable</code> included: balance of all receivable amounts where the matching incoming send blocks have been confirmed on their account</li> </ul>  <p>The term <code>pending</code> is being deprecated in favor of <code>receivable</code>. For compatibility reasons both terms are still available for many calls and in responses. For more details see: https://docs.nano.org/releases/release-v23-0/#pendingreceivable-term-rpc-updates.</p>  <p>Request: <pre><code>{\n  \"action\": \"account_info\",  \n  \"account\": \"nano_1gyeqc6u5j3oaxbe5qy1hyz3q745a318kh8h9ocnpan7fuxnq85cxqboapu5\",\n  \"representative\": \"true\",\n  \"weight\": \"true\",\n  \"receivable\": \"true\",\n  \"include_confirmed\": \"true\"\n}\n</code></pre></p> <p>Response: <pre><code>{\n    \"frontier\": \"80A6745762493FA21A22718ABFA4F635656A707B48B3324198AC7F3938DE6D4F\",\n    \"open_block\": \"0E3F07F7F2B8AEDEA4A984E29BFE1E3933BA473DD3E27C662EC041F6EA3917A0\",\n    \"representative_block\": \"80A6745762493FA21A22718ABFA4F635656A707B48B3324198AC7F3938DE6D4F\",\n    \"balance\": \"11999999999999999918751838129509869131\",\n    \"confirmed_balance\": \"11999999999999999918751838129509869131\",\n    \"modified_timestamp\": \"1606934662\",\n    \"block_count\": \"22966\",\n    \"account_version\": \"1\",\n    \"confirmed_height\": \"22966\",\n    \"confirmed_frontier\": \"80A6745762493FA21A22718ABFA4F635656A707B48B3324198AC7F3938DE6D4F\",\n    \"representative\": \"nano_1gyeqc6u5j3oaxbe5qy1hyz3q745a318kh8h9ocnpan7fuxnq85cxqboapu5\",\n    \"confirmed_representative\": \"nano_1gyeqc6u5j3oaxbe5qy1hyz3q745a318kh8h9ocnpan7fuxnq85cxqboapu5\",\n    \"weight\": \"11999999999999999918751838129509869131\",\n    \"pending\": \"0\",\n    \"receivable\": \"0\",\n    \"confirmed_pending\": \"0\",\n    \"confirmed_receivable\": \"0\"\n}\n</code></pre></p> <p>Optional \"representative\", \"weight\", \"pending\" version 9.0+  Booleans, false by default. Additionally returns representative, voting weight, pending/receivable balance for account   </p> <p>Request: <pre><code>{\n  \"action\": \"account_info\",\n  \"account\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\",\n  \"representative\": \"true\",\n  \"weight\": \"true\",\n  \"pending\": \"true\"\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"frontier\": \"FF84533A571D953A596EA401FD41743AC85D04F406E76FDE4408EAED50B473C5\",\n  \"open_block\": \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\",\n  \"representative_block\": \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\",\n  \"balance\": \"235580100176034320859259343606608761791\",\n  \"modified_timestamp\": \"1501793775\",\n  \"block_count\": \"33\",\n  \"account_version\": \"1\",\n  \"confirmation_height\" : \"28\",\n  \"confirmation_height_frontier\" : \"34C70FCA0952E29ADC7BEE6F20381466AE42BD1CFBA4B7DFFE8BD69DF95449EB\",\n  \"representative\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\",\n  \"weight\": \"1105577030935649664609129644855132177\",\n  \"pending\": \"2309370929000000000000000000000000\",\n  \"receivable\": \"2309370929000000000000000000000000\"\n}\n</code></pre></p>","title":"account_info"},{"location":"commands/rpc-protocol/#account_key","text":"<p>Get the public key for account </p> <p>Request: <pre><code>{\n  \"action\": \"account_key\",\n  \"account\" : \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\"\n}\n</code></pre> Response: <pre><code>{\n  \"key\": \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\"\n}\n</code></pre></p>","title":"account_key"},{"location":"commands/rpc-protocol/#account_representative","text":"<p>Returns the representative for account </p> <p>Request: <pre><code>{\n  \"action\": \"account_representative\",\n  \"account\": \"nano_39a73oy5ungrhxy5z5oao1xso4zo7dmgpjd4u74xcrx3r1w6rtazuouw6qfi\"\n}\n</code></pre> Response: <pre><code>{\n  \"representative\" : \"nano_16u1uufyoig8777y6r8iqjtrw8sg8maqrm36zzcm95jmbd9i9aj5i8abr8u5\"\n}\n</code></pre></p>","title":"account_representative"},{"location":"commands/rpc-protocol/#account_weight","text":"<p>Returns the voting weight for account </p> <p>Request: <pre><code>{\n  \"action\": \"account_weight\",\n  \"account\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n}\n</code></pre> Response: <pre><code>{\n  \"weight\": \"10000\"\n}\n</code></pre></p>","title":"account_weight"},{"location":"commands/rpc-protocol/#accounts_balances","text":"<p>Returns how many RAW is owned and how many have not yet been received by accounts list </p>  <p>Unconfirmed information</p> <p>This call returns information that may be based on unconfirmed blocks. These details should not be relied on for any process or integration that requires confirmed blocks. The receivable balances are calculated from potentially unconfirmed blocks. Account balances are obtained from their frontiers. An atomic account_info RPC call is recommended for the purposes of creating transactions.</p>   <p>The term <code>pending</code> is being deprecated in favor of <code>receivable</code>. For compatibility reasons both terms are still available for many calls and in responses. For more details see: https://docs.nano.org/releases/release-v23-0/#pendingreceivable-term-rpc-updates.</p>  <p>Request: <pre><code>{\n  \"action\": \"accounts_balances\",\n  \"accounts\": [\"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\", \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\"]\n}\n</code></pre> Response: <pre><code>{\n  \"balances\" : {\n    \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\": {\n        \"balance\": \"325586539664609129644855132177\",\n        \"pending\": \"2309372032769300000000000000000000\",\n        \"receivable\": \"2309372032769300000000000000000000\"\n    },\n    \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\":\n    {\n      \"balance\": \"10000000\",\n      \"pending\": \"0\",\n      \"receivable\": \"0\"\n    }\n  }\n}\n</code></pre></p>","title":"accounts_balances"},{"location":"commands/rpc-protocol/#accounts_frontiers","text":"<p>Returns a list of pairs of account and block hash representing the head block for accounts list </p>  <p>Includes unconfirmed blocks</p> <p>This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network.</p>  <p>Request: <pre><code>{\n  \"action\": \"accounts_frontiers\",\n  \"accounts\": [\"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\", \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\"]\n}\n</code></pre> Response: <pre><code>{\n  \"frontiers\" : {\n    \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\": \"791AF413173EEE674A6FCF633B5DFC0F3C33F397F0DA08E987D9E0741D40D81A\",\n    \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\": \"6A32397F4E95AF025DE29D9BF1ACE864D5404362258E06489FABDBA9DCCC046F\"\n  }\n}\n</code></pre></p>","title":"accounts_frontiers"},{"location":"commands/rpc-protocol/#accounts_pending","text":"<p>Returns a list of confirmed block hashes which have not yet been received by these accounts </p> <p>Request: <pre><code>{\n  \"action\": \"accounts_pending\",\n  \"accounts\": [\"nano_1111111111111111111111111111111111111111111111111117353trpda\", \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"],\n  \"count\": \"1\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\" : {\n    \"nano_1111111111111111111111111111111111111111111111111117353trpda\": [\"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\"],\n    \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\": [\"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\"]\n  }\n}\n</code></pre> Optional \"threshold\" version 8.0+  Number (128 bit, decimal). Returns a list of receivable block hashes with amount more or equal to threshold </p> <p>Request: <pre><code>{\n  \"action\": \"accounts_pending\",\n  \"accounts\": [\"nano_1111111111111111111111111111111111111111111111111117353trpda\", \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"],\n  \"count\": \"1\",\n  \"threshold\": \"1000000000000000000000000\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\" : {\n    \"nano_1111111111111111111111111111111111111111111111111117353trpda\": {\n      \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\": \"6000000000000000000000000000000\"\n    },\n    \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\": {\n      \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\": \"106370018000000000000000000000000\"\n    }\n  }\n}\n</code></pre> Optional \"source\" version 9.0+  Boolean, false by default. Returns a list of receivable block hashes with amount and source accounts   </p> <p>Request: <pre><code>{\n  \"action\": \"accounts_pending\",\n  \"accounts\": [\"nano_1111111111111111111111111111111111111111111111111117353trpda\", \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"],\n  \"count\": \"1\",\n  \"source\": \"true\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\" : {\n    \"nano_1111111111111111111111111111111111111111111111111117353trpda\": {\n      \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\": {\n        \"amount\": \"6000000000000000000000000000000\",\n        \"source\": \"nano_3dcfozsmekr1tr9skf1oa5wbgmxt81qepfdnt7zicq5x3hk65fg4fqj58mbr\"\n      }\n    },\n    \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\": {\n      \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\": {\n        \"amount\": \"106370018000000000000000000000000\",\n        \"source\": \"nano_13ezf4od79h1tgj9aiu4djzcmmguendtjfuhwfukhuucboua8cpoihmh8byo\"\n      }\n    }\n  }\n}\n</code></pre> Optional \"include_active\"</p> <p>version 15.0+  Boolean, false by default. Include active (not confirmed) blocks    </p> <p>Request: <pre><code>{\n  \"action\": \"accounts_pending\",\n  \"accounts\": [\"nano_1111111111111111111111111111111111111111111111111117353trpda\", \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"],\n  \"count\": \"1\",\n  \"include_active\": \"true\"\n}\n</code></pre></p> <p>Optional \"sorting\"</p> <p>version 19.0+  Boolean, false by default. Additionally sorts each account's blocks by their amounts in descending order.</p> <p>Optional \"include_only_confirmed\"</p> <p>version 19.0+ Boolean, true by default (version 22.0+), previously false by default. Only returns confirmed blocks but with the caveat that their confirmation height might not be up-to-date yet. If false, unconfirmed blocks will also be returned.</p>","title":"accounts_pending"},{"location":"commands/rpc-protocol/#accounts_representatives","text":"<p>Returns the representatives for given accounts </p> <p>Request: <pre><code>{\n  \"action\": \"accounts_representatives\",\n  \"accounts\": [\"nano_16u1uufyoig8777y6r8iqjtrw8sg8maqrm36zzcm95jmbd9i9aj5i8abr8u5\",\"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"]\n}\n</code></pre> Response: <pre><code>{\n  \"representatives\" : {\n    \"nano_16u1uufyoig8777y6r8iqjtrw8sg8maqrm36zzcm95jmbd9i9aj5i8abr8u5\": \"nano_3hd4ezdgsp15iemx7h81in7xz5tpxi43b6b41zn3qmwiuypankocw3awes5k\",\n    \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"\n  }\n}\n</code></pre></p>","title":"accounts_representatives"},{"location":"commands/rpc-protocol/#available_supply","text":"<p>Returns how many raw are in the public supply  </p> <p>Request: <pre><code>{\n  \"action\": \"available_supply\"\n}\n</code></pre> Response: <pre><code>{\n  \"available\": \"133248061996216572282917317807824970865\"\n}\n</code></pre></p>","title":"available_supply"},{"location":"commands/rpc-protocol/#block_account","text":"<p>Returns the account containing block  </p> <p>Request: <pre><code>{\n  \"action\": \"block_account\",\n  \"hash\": \"023B94B7D27B311666C8636954FE17F1FD2EAA97A8BAC27DE5084FBBD5C6B02C\"\n}\n</code></pre> Response: <pre><code>{\n  \"account\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"\n}\n</code></pre></p>","title":"block_account"},{"location":"commands/rpc-protocol/#block_confirm","text":"<p>version 12.2+  Request confirmation for block from known online representative nodes. Check results with confirmation history.</p> <p>Request: <pre><code>{\n  \"action\": \"block_confirm\",\n  \"hash\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"started\": \"1\"\n}\n</code></pre></p> <p>NOTE: Unless there was an error encountered during the command, the response will always return <code>\"started\": \"1\"</code>. This response does not indicate the block was successfully confirmed, only that an error did not occur. This response happens even if the block has already been confirmed previously and notifications will be triggered for this block (via HTTP callbacks or WebSockets) in all cases. This behavior may change in a future release.</p>","title":"block_confirm"},{"location":"commands/rpc-protocol/#block_count","text":"<p>Reports the number of blocks in the ledger and unchecked synchronizing blocks   </p> <p>Request: <pre><code>{\n  \"action\": \"block_count\"\n}\n</code></pre> Response: <pre><code>{\n  \"count\": \"1000\",\n  \"unchecked\": \"10\",\n  \"cemented\": \"25\"\n}\n</code></pre> Note: If the node is running the RocksDB backend the unchecked count may only be estimate.  </p> <p>Optional \"include_cemented\"</p> <p>version 19.0+ (enable_control required in version 19.0, not required in version 20.0+) Default \"true\". If \"true\", \"cemented\" in the response will contain the number of cemented blocks. (In V19.0 default was \"false\")</p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>","title":"block_count"},{"location":"commands/rpc-protocol/#block_create","text":"<p>enable_control required, version 9.0+ Creates a json representations of new block based on input data &amp; signed with private key or account in wallet. Use for offline signing. Using the optional <code>json_block</code> is recommended since v19.0.  </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request sample for state block: <pre><code>{\n  \"action\": \"block_create\",\n  \"json_block\": \"true\",\n  \"type\": \"state\",\n  \"balance\": \"1000000000000000000000\",\n  \"key\": \"0000000000000000000000000000000000000000000000000000000000000002\",\n  \"representative\": \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\",\n  \"link\": \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\",\n  \"previous\": \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\"\n}\n</code></pre> Parameters for state block:</p> <ul> <li><code>balance</code>: final balance for account after block creation, formatted in 'raw' units using a decimal integer. If balance is less than previous, block is considered as send subtype!</li> <li><code>wallet</code> (optional): The wallet ID that the account the block is being created for is in.</li> <li><code>account</code> (optional): The account the block is being created for.</li> <li><code>key</code> (optional): Instead of using \"wallet\" &amp; \"account\" parameters, you can directly pass in a private key.</li> <li><code>source</code> (optional): The block hash of the source of funds for this receive block (the send block that this receive block will pocket).</li> <li><code>destination</code> (optional): The account that the sent funds should be accessible to.</li> <li><code>link</code> (optional): Instead of using \"source\" and \"destination\" parameters, you can directly pass \"link\". If the block is sending funds, set link to the public key of the destination account. If it is receiving funds, set link to the hash of the block to receive. If the block has no balance change but is updating representative only, set link to 0. See Block format section for more information</li> <li><code>representative</code>: The account that block account will use as its representative.</li> <li><code>previous</code>: The block hash of the previous block on this account's block chain (\"0\" for first block).</li> </ul> <p>Warning: It is critical that <code>balance</code> is the balance of the account after created block!</p> <p>Optional \"json_block\"</p> <p>version 19.0+ Default \"false\". If \"true\", \"block\" in the response will contain a JSON subtree instead of a JSON string.</p> <p>Optional \"work\"</p> <p>Work value (16 hexadecimal digits string, 64 bit). Uses work value for block from external source  </p> <p>Optional \"version\"</p> <p>version 21.0+ Work version string. Currently \"work_1\" is the default and only valid option. Only used if optional work is not given.</p> <p>Optional \"difficulty\"</p> <p>version 21.0+ Difficulty value (16 hexadecimal digits string, 64 bit). Uses difficulty value to generate work. Only used if optional work is not given.  </p> <p>If difficulty and work values are both not given, RPC processor tries to calculate difficulty for work generation based on ledger data: epoch from previous block or from link for receive subtype; block subtype from previous block balance.  </p> <p>Examples</p> <p>Response sample for above request: <pre><code>{\n  \"hash\": \"FF0144381CFF0B2C079A115E7ADA7E96F43FD219446E7524C48D1CC9900C4F17\",\n  \"difficulty\": \"ffffffe1278b3dc6\", // since V21.0\n  \"block\": {\n    \"type\": \"state\",\n    \"account\": \"nano_3qgmh14nwztqw4wmcdzy4xpqeejey68chx6nciczwn9abji7ihhum9qtpmdr\",\n    \"previous\": \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\",\n    \"representative\": \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\",\n    \"balance\": \"1000000000000000000000\",\n    \"link\": \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\",\n    \"link_as_account\": \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\",\n    \"signature\": \"3BFBA64A775550E6D49DF1EB8EEC2136DCD74F090E2ED658FBD9E80F17CB1C9F9F7BDE2B93D95558EC2F277FFF15FD11E6E2162A1714731B743D1E941FA4560A\",\n    \"work\": \"cab7404f0b5449d0\"\n  }\n}\n</code></pre></p>","title":"block_create"},{"location":"commands/rpc-protocol/#block_hash","text":"<p>version 13.0+  Returning block hash for given block content. Using the optional <code>json_block</code> is recommended since v19.0.  </p> <p>Request: <pre><code>{  \n  \"action\": \"block_hash\",\n  \"json_block\": \"true\", \n  \"block\": {\n    \"type\": \"state\",\n    \"account\": \"nano_3qgmh14nwztqw4wmcdzy4xpqeejey68chx6nciczwn9abji7ihhum9qtpmdr\",\n    \"previous\": \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\",\n    \"representative\": \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\",\n    \"balance\": \"1000000000000000000000\",\n    \"link\": \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\",\n    \"link_as_account\": \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\",\n    \"signature\": \"3BFBA64A775550E6D49DF1EB8EEC2136DCD74F090E2ED658FBD9E80F17CB1C9F9F7BDE2B93D95558EC2F277FFF15FD11E6E2162A1714731B743D1E941FA4560A\",\n    \"work\": \"cab7404f0b5449d0\"\n  }\n}\n</code></pre> Response: <pre><code>{\n  \"hash\": \"FF0144381CFF0B2C079A115E7ADA7E96F43FD219446E7524C48D1CC9900C4F17\"\n}\n</code></pre></p> <p>Optional \"json_block\"</p> <p>version 19.0+ Default \"false\". If \"true\", \"block\" must contain a JSON subtree instead of a JSON string.</p>","title":"block_hash"},{"location":"commands/rpc-protocol/#block_info","text":"<p>Retrieves a json representation of the block in <code>contents</code> along with:</p> <ul> <li>since version 18.0: <code>block_account</code>, transaction <code>amount</code>, block <code>balance</code>, block <code>height</code> in account chain, block local modification <code>timestamp</code></li> <li>since version 19.0: Whether block was <code>confirmed</code>, <code>subtype</code> (for state blocks) of <code>send</code>, <code>receive</code>, <code>change</code> or <code>epoch</code></li> <li>since version 23.0: <code>successor</code> returned</li> </ul> <p>Using the optional <code>json_block</code> is recommended since v19.0.  </p> <p>Request: <pre><code>{  \n  \"action\": \"block_info\",\n  \"json_block\": \"true\",\n  \"hash\": \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\"\n}\n</code></pre> Response: <pre><code>{\n  \"block_account\": \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\",\n  \"amount\": \"30000000000000000000000000000000000\",\n  \"balance\": \"5606157000000000000000000000000000000\",\n  \"height\": \"58\",\n  \"local_timestamp\": \"0\",\n  \"successor\": \"8D3AB98B301224253750D448B4BD997132400CEDD0A8432F775724F2D9821C72\",\n  \"confirmed\": \"true\",\n  \"contents\": {\n    \"type\": \"state\",\n    \"account\": \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\",\n    \"previous\": \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\",\n    \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n    \"balance\": \"5606157000000000000000000000000000000\",\n    \"link\": \"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\",\n    \"link_as_account\": \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\",\n    \"signature\": \"82D41BC16F313E4B2243D14DFFA2FB04679C540C2095FEE7EAE0F2F26880AD56DD48D87A7CC5DD760C5B2D76EE2C205506AA557BF00B60D8DEE312EC7343A501\",\n    \"work\": \"8a142e07a10996d5\"\n  },\n  \"subtype\": \"send\"\n}\n</code></pre></p> <p>Note: The <code>Balance</code> in contents is a uint128. However, it will be a hex-encoded (like <code>0000000C9F2C9CD04674EDEA40000000</code> for 1 nano) when the block is a legacy Send Block. If the block is a State-Block, the same <code>Balance</code> will be a numeric-string (like <code>1000000000000000000000000000000</code>).</p> <p>Optional \"json_block\"</p> <p>version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string.</p>","title":"block_info"},{"location":"commands/rpc-protocol/#blocks","text":"<p>Retrieves a json representations of blocks. Using the optional <code>json_block</code> is recommended since v19.0.  </p> <p>Request: <pre><code>{\n  \"action\": \"blocks\",\n  \"json_block\": \"true\",\n  \"hashes\": [\"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\"]\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\": {\n    \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\": {\n      \"type\": \"state\",\n      \"account\": \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\",\n      \"previous\": \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\",\n      \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n      \"balance\": \"5606157000000000000000000000000000000\",\n      \"link\": \"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\",\n      \"link_as_account\": \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\",\n      \"signature\": \"82D41BC16F313E4B2243D14DFFA2FB04679C540C2095FEE7EAE0F2F26880AD56DD48D87A7CC5DD760C5B2D76EE2C205506AA557BF00B60D8DEE312EC7343A501\",\n      \"work\": \"8a142e07a10996d5\"\n    }\n  }\n}\n</code></pre></p> <p>Optional \"json_block\"</p> <p>version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string.</p>","title":"blocks"},{"location":"commands/rpc-protocol/#blocks_info","text":"<p>Retrieves a json representations of <code>blocks</code> in <code>contents</code> along with:</p> <ul> <li>since version 18.0: <code>block_account</code>, transaction <code>amount</code>, block <code>balance</code>, block <code>height</code> in account chain, block local modification <code>timestamp</code></li> <li>since version 19.0: Whether block was <code>confirmed</code>, <code>subtype</code> (for state blocks) of <code>send</code>, <code>receive</code>, <code>change</code> or <code>epoch</code></li> <li>since version 23.0: <code>successor</code> returned</li> </ul> <p>Using the optional <code>json_block</code> is recommended since v19.0.  </p> <p>Request: <pre><code>{\n  \"action\": \"blocks_info\",\n  \"json_block\": \"true\",\n  \"hashes\": [\"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\"]\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\": {\n    \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\": {\n      \"block_account\": \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\",\n      \"amount\": \"30000000000000000000000000000000000\",\n      \"balance\": \"5606157000000000000000000000000000000\",\n      \"height\": \"58\",\n      \"local_timestamp\": \"0\",\n      \"successor\": \"8D3AB98B301224253750D448B4BD997132400CEDD0A8432F775724F2D9821C72\",\n      \"confirmed\": \"true\",\n      \"contents\": {\n        \"type\": \"state\",\n        \"account\": \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\",\n        \"previous\": \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\",\n        \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n        \"balance\": \"5606157000000000000000000000000000000\",\n        \"link\": \"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\",\n        \"link_as_account\": \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\",\n        \"signature\": \"82D41BC16F313E4B2243D14DFFA2FB04679C540C2095FEE7EAE0F2F26880AD56DD48D87A7CC5DD760C5B2D76EE2C205506AA557BF00B60D8DEE312EC7343A501\",\n        \"work\": \"8a142e07a10996d5\"\n      },\n      \"subtype\": \"send\"\n    }\n  }\n}\n</code></pre> Optional \"pending\", \"source\", \"balance\"</p> <p>pending, source: version 9.0+ balance: version 12.0+ Booleans, false by default. Additionally checks if block is pending, returns source account for receive &amp; open blocks (0 for send &amp; change blocks), and returns the balance of the account at the time of the block.</p>  <p>The term <code>pending</code> is being deprecated in favor of <code>receivable</code>. For compatibility reasons both terms are still available for many calls and in responses. For more details see: https://docs.nano.org/releases/release-v23-0/#pendingreceivable-term-rpc-updates.</p>  <p>Request: <pre><code>{\n  \"action\": \"blocks_info\",\n  \"hashes\": [\"E2FB233EF4554077A7BF1AA85851D5BF0B36965D2B0FB504B2BC778AB89917D3\"],\n  \"pending\": \"true\",\n  \"source\": \"true\",\n  \"balance\": \"true\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\" : {\n    \"E2FB233EF4554077A7BF1AA85851D5BF0B36965D2B0FB504B2BC778AB89917D3\": {\n      \"block_account\": \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\",\n      \"amount\": \"30000000000000000000000000000000000\",\n      \"contents\": {\n        ...\n      },\n      \"pending\": \"0\",\n      \"source_account\": \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\",\n      \"balance\": \"40200000001000000000000000000000000\"\n    }\n  }\n}\n</code></pre></p> <p>Optional \"json_block\" version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string.</p> <p>Optional \"include_not_found\" version 19.0+ Default \"false\". If \"true\", an additional \"blocks_not_found\" is provided in the response, containing a list of the block hashes that were not found in the local database. Previously to this version an error would be produced if any block was not found.</p> <p>Request: <pre><code>{\n  \"action\": \"blocks_info\",\n  \"include_not_found\": \"true\",\n  \"hashes\": [\"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\", \"0000000000000000000000000000000000000000000000000000000000000001\"]\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"blocks\" : {\n    \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\": {\n      \"block_account\": \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\",\n      \"amount\": \"30000000000000000000000000000000000\",\n      \"balance\": \"5606157000000000000000000000000000000\",\n      \"height\": \"58\",\n      \"local_timestamp\": \"0\",\n      \"confirmed\": \"false\",\n      \"contents\": {\n        ...\n      }\n    }\n  },\n  \"blocks_not_found\": [\n    \"0000000000000000000000000000000000000000000000000000000000000001\"\n  ]\n}\n</code></pre></p>","title":"blocks_info"},{"location":"commands/rpc-protocol/#bootstrap","text":"<p>Initialize bootstrap to specific IP address and port. Not compatible with launch flag --disable_legacy_bootstrap </p> <p>Request: <pre><code>{\n  \"action\": \"bootstrap\",\n  \"address\": \"::ffff:138.201.94.249\",\n  \"port\": \"7075\"\n}\n</code></pre> Response: <pre><code>{\n  \"success\": \"\"\n}\n</code></pre></p> <p>Optional \"bypass_frontier_confirmation\" version 20.0-21.3 Default \"false\". If \"true\", frontier confirmation will not be performed for this bootstrap. Normally not to be changed.</p> <p>Optional \"id\" version 21.0+ String, empty by default. Set specific ID for new bootstrap attempt for better tracking.</p>","title":"bootstrap"},{"location":"commands/rpc-protocol/#bootstrap_any","text":"<p>Initialize multi-connection bootstrap to random peers. Not compatible with launch flag --disable_legacy_bootstrap </p> <p>Request: <pre><code>{\n  \"action\": \"bootstrap_any\"\n}\n</code></pre> Response: <pre><code>{\n  \"success\": \"\"\n}\n</code></pre> Optional \"force\" version 20.0+ Boolean, false by default. Manually force closing of all current bootstraps  </p> <p>Optional \"id\" version 21.0+ String, empty by default. Set specific ID for new bootstrap attempt for better tracking.</p> <p>Optional \"account\" version 22.0+ String, empty by default. Public address for targeting a specific account on bootstrap attempt</p>","title":"bootstrap_any"},{"location":"commands/rpc-protocol/#bootstrap_lazy","text":"<p>version 17.0+  Initialize lazy bootstrap with given block hash. Not compatible with launch flag --disable_lazy_bootstrap. As of version 22.0, response includes whether new election was <code>started</code> and whether a new lazy <code>key_inserted</code> was successful.</p> <p>Request: <pre><code>{\n  \"action\": \"bootstrap_lazy\",\n  \"hash\": \"FF0144381CFF0B2C079A115E7ADA7E96F43FD219446E7524C48D1CC9900C4F17\"\n}\n</code></pre> Response: <pre><code>{\n  \"started\": \"1\",\n  \"key_inserted\": \"0\"\n}\n</code></pre> Optional \"force\"</p> <p>Boolean, false by default. Manually force closing of all current bootstraps  </p> <p>Optional \"id\" version 21.0+ String, empty by default. Set specific ID for new bootstrap attempt for better tracking.</p>","title":"bootstrap_lazy"},{"location":"commands/rpc-protocol/#bootstrap_status","text":"<p>version 17.0+</p>  <p>Debug purposes only</p> <p>This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system.</p>  <p>Returning status of current bootstrap attempt</p> <p>Request: <pre><code>{\n  \"action\": \"bootstrap_status\"\n}\n</code></pre> Response: versions 21.0+ <pre><code>{\n  \"bootstrap_threads\": \"2\",\n  \"running_attempts_count\": \"2\",\n  \"total_attempts_count\": \"6\",\n  \"connections\": {\n    \"clients\": \"31\",\n    \"connections\": \"45\",\n    \"idle\": \"0\",\n    \"target_connections\": \"64\",\n    \"pulls\": \"1158514\"\n  },\n  \"attempts\": [\n    {\n      \"id\": \"EE778222D6407F94A666B8A9E03D242D\",\n      \"mode\": \"legacy\",\n      \"started\": \"true\",\n      \"pulling\": \"1158544\",\n      \"total_blocks\": \"4311\",\n      \"requeued_pulls\": \"7\",\n      \"frontier_pulls\": \"0\",\n      \"frontiers_received\": \"true\",\n      \"frontiers_confirmed\": \"false\",\n      \"frontiers_confirmation_pending\": \"false\",\n      \"frontiers_age\": \"4294967295\",\n      \"last_account\": \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\",\n      \"duration\": \"133\"\n    },\n    {\n      \"id\": \"291D2CC32F44E004896C4215A6CDEDAFEF317F6AC802C244E8F4B4F2456175CB\",\n      \"mode\": \"lazy\",\n      \"started\": \"true\",\n      \"pulling\": \"1\",\n      \"total_blocks\": \"1878\",\n      \"requeued_pulls\": \"4\",\n      \"lazy_blocks\": \"1878\",\n      \"lazy_state_backlog\": \"1\",\n      \"lazy_balances\": \"4\",\n      \"lazy_destinations\": \"0\",\n      \"lazy_undefined_links\": \"0\",\n      \"lazy_pulls\": \"13\",\n      \"lazy_keys\": \"2\",\n      \"lazy_key_1\": \"E6D0B5BD5EBDB3CEC7DBC32EDC3C2DBD5ABA17C54E34485A358BF8948039ED6A\",\n      \"duration\": \"17\"\n    }\n  ]\n}\n</code></pre></p>  Response V17.0-V20.0 <pre><code>{\n  \"clients\": \"0\",\n  \"pulls\": \"0\",\n  \"pulling\": \"0\",\n  \"connections\": \"31\",\n  \"idle\": \"31\",\n  \"target_connections\": \"16\",\n  \"total_blocks\": \"13558\",\n  \"runs_count\": \"0\",\n  \"requeued_pulls\": \"31\",\n  \"frontiers_received\": \"true\",\n  \"frontiers_confirmed\": \"false\",\n  \"mode\": \"legacy\",\n  \"lazy_blocks\": \"0\",\n  \"lazy_state_backlog\": \"0\",\n  \"lazy_balances\": \"0\",\n  \"lazy_destinations\": \"0\",\n  \"lazy_undefined_links\": \"0\",\n  \"lazy_pulls\": \"32\",\n  \"lazy_keys\": \"32\",\n  \"lazy_key_1\": \"36897874BDA3028DC8544C106BE1394891F23DDDF84DE100FED450F6FBC8122C\",\n  \"duration\": \"29\"\n}\n</code></pre>","title":"bootstrap_status"},{"location":"commands/rpc-protocol/#chain","text":"<p>Returns a consecutive list of block hashes in the account chain starting at block back to count (direction from frontier back to open block, from newer blocks to older). Will list all blocks back to the open block of this chain when count is set to \"-1\". The requested block hash is included in the answer.  </p> <p>Request: <pre><code>{\n  \"action\": \"chain\",\n  \"block\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"count\": \"1\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\": [\n    \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n  ]\n}\n</code></pre> Optional \"offset\"</p> <p>version 18.0+  Number, 0 by default. Return the account chain block hashes offset by the specified number of blocks    </p> <p>Optional \"reverse\"</p> <p>version 18.0+  Boolean, false by default. Returns a list of block hashes in the account chain starting at block up to count (direction from open block up to frontier, from older blocks to newer). Equal to successors </p>","title":"chain"},{"location":"commands/rpc-protocol/#confirmation_active","text":"<p>version 16.0+  Returns list of active elections qualified roots (excluding stopped &amp; aborted elections); since V21, also includes the number of unconfirmed and confirmed active elections. Find info about specific qualified root with confirmation_info </p>  <p>Note</p> <p>The roots provided are two parts and differ between the first account block and subsequent blocks:</p> <ul> <li>First account block (open): account public key + <code>0000000000000000000000000000000000000000000000000000000000000000</code></li> <li>Other blocks: previous hash + previous hash</li> </ul>  <p>Request: <pre><code>{\n  \"action\": \"confirmation_active\"\n}\n</code></pre> Response: <pre><code>{\n \"confirmations\": [\n   \"8031B600827C5CC05FDC911C28BBAC12A0E096CCB30FA8324F56C123676281B28031B600827C5CC05FDC911C28BBAC12A0E096CCB30FA8324F56C123676281B2\"\n ],\n \"unconfirmed\": \"133\", // since V21.0\n \"confirmed\": \"5\" // since V21.0\n}\n</code></pre></p> <p>Optional \"announcements\"</p> <p>Number, 0 by default. Returns only active elections with equal or higher announcements count. Useful to find long running elections   </p>","title":"confirmation_active"},{"location":"commands/rpc-protocol/#confirmation_height_currently_processing","text":"<p>version 19.0+</p>  <p>Debug purposes only</p> <p>This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system.</p>  <p>Returns the hash of the block which is having the confirmation height set for, error otherwise. When a block is being confirmed, it must confirm all blocks in the chain below and iteratively follow all receive blocks. This can take a long time, so it can be useful to find which block was the original being confirmed.</p> <p>Request: <pre><code>{\n  \"action\": \"confirmation_height_currently_processing\"\n}\n</code></pre> Response: <pre><code>{\n  \"hash\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre></p>","title":"confirmation_height_currently_processing"},{"location":"commands/rpc-protocol/#confirmation_history","text":"<p>version 12.0+</p>  <p>Debug purposes only</p> <p>This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system.</p>  <p>duration, time, confirmation_stats: version 17.0+_  Returns hash, tally weight, election duration (in milliseconds), election confirmation timestamp for recent elections winners; since V20.0, the confirmation request count; since V21.0, the number of blocks and voters. Also returns stats: count of elections in history (limited to 2048) &amp; average duration time.</p> <p>With version 19.0+ <code>confirmation_history_size</code> can be managed in the configuration file to adjust the number of elections to be kept in history and returned by this call. Due to timings inside the node, the default 2048 limit will return all confirmations up to traffic levels of approximately 56 confirmations/sec. To properly track levels above this, increase this value or use the confirmation subscription through the websocket instead.</p> <p>Request: <pre><code>{\n  \"action\": \"confirmation_history\"\n}\n</code></pre> Response: <pre><code>{\n  \"confirmation_stats\": {\n    \"count\": \"2\",\n    \"average\": \"5000\"\n  },\n  \"confirmations\": [\n    {\n      \"hash\": \"EA70B32C55C193345D625F766EEA2FCA52D3F2CCE0B3A30838CC543026BB0FEA\",\n      \"duration\": \"4000\",\n      \"time\": \"1544819986\",\n      \"tally\": \"80394786589602980996311817874549318248\",\n      \"blocks\": \"1\", // since V21.0\n      \"voters\": \"37\", // since V21.0\n      \"request_count\": \"2\" // since V20.0\n    },\n    {\n      \"hash\": \"F2F8DA6D2CA0A4D78EB043A7A29E12BDE5B4CE7DE1B99A93A5210428EE5B8667\",\n      \"duration\": \"6000\",\n      \"time\": \"1544819988\",\n      \"tally\": \"68921714529890443063672782079965877749\",\n      \"blocks\": \"1\", // since V21.0\n      \"voters\": \"64\", // since V21.0\n      \"request_count\": \"7\" // since V20.0\n    }\n  ]\n}\n</code></pre> Optional \"hash\"</p> <p>Valid block hash, filters return for only the provided hash. If there is no confirmation available for that hash anymore, the following return can be expected: <pre><code>{\n  \"confirmation_stats\": {\n    \"count\": \"0\"\n  },\n  \"confirmations\": \"\"\n}\n</code></pre></p> <p>If the block is unknown on the node, the following error will be returned: <code>\"error\": \"Invalid block hash\"</code> </p>","title":"confirmation_history"},{"location":"commands/rpc-protocol/#confirmation_info","text":"<p>version 16.0+  Returns info about an unconfirmed active election by root. Including announcements count, last winner (initially local ledger block), total tally of voted representatives, concurrent blocks with tally &amp; block contents for each. Using the optional <code>json_block</code> is recommended since v19.0.</p>  <p>Note</p> <p>The roots provided are two parts and differ between the first account block and subsequent blocks:</p> <ul> <li>First account block (open): <code>0000000000000000000000000000000000000000000000000000000000000000</code> + account public key</li> <li>Other blocks: previous hash + previous hash</li> </ul>  <p>Request: <pre><code>{\n  \"action\": \"confirmation_info\",\n  \"json_block\": \"true\",\n  \"root\": \"EE125B1B1D85D3C24636B3590E1642D9F21B166C0C6CD99C9C6087A1224A0C44EE125B1B1D85D3C24636B3590E1642D9F21B166C0C6CD99C9C6087A1224A0C44\"\n}\n</code></pre> Response: <pre><code>{\n  \"announcements\": \"2\",\n  \"voters\": \"29\",\n  \"last_winner\": \"B94C505029F04BC057A0486ADA8BD07981B4A8736AE6581F2E98C6D18498146F\",\n  \"total_tally\": \"51145880360832646375807054724596663794\",\n  \"blocks\": {\n    \"B94C505029F04BC057A0486ADA8BD07981B4A8736AE6581F2E98C6D18498146F\": {\n      \"tally\": \"51145880360832646375807054724596663794\",\n      \"contents\": {\n        \"type\": \"state\",\n        \"account\": \"nano_3fihmbtuod33s4nrbqfczhk9zy9ddqimwjshzg4c3857es8c9631i5rg6h9p\",\n        \"previous\": \"EE125B1B1D85D3C24636B3590E1642D9F21B166C0C6CD99C9C6087A1224A0C44\",\n        \"representative\": \"nano_3o7uzba8b9e1wqu5ziwpruteyrs3scyqr761x7ke6w1xctohxfh5du75qgaj\",\n        \"balance\": \"218195000000000000000000000000\",\n        \"link\": \"0000000000000000000000000000000000000000000000000000000000000000\",\n        \"link_as_account\": \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\",\n        \"signature\": \"B1BD285235C612C5A141FA61793D7C6C762D3F104A85102DED5FBD6B4514971C4D044ACD3EC8C06A9495D8E83B6941B54F8DABA825ADF799412ED9E2C86D7A0C\",\n        \"work\": \"05bb28cd8acbe71d\"\n      }\n    }\n  }\n}   \n</code></pre></p> <p>Optional \"contents\"</p> <p>Boolean, true by default. Disable contents for each block   </p> <p>Optional \"json_block\"</p> <p>version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string.</p> <p>Optional \"representatives\"</p> <p>Boolean, false by default. Returns list of votes representatives &amp; its weights for each block   </p> <p>Request: <pre><code>{\n  \"action\": \"confirmation_info\",\n  \"json_block\": \"true\",\n  \"root\": \"EE125B1B1D85D3C24636B3590E1642D9F21B166C0C6CD99C9C6087A1224A0C44EE125B1B1D85D3C24636B3590E1642D9F21B166C0C6CD99C9C6087A1224A0C44\",\n  \"representatives\": \"true\"\n}\n</code></pre> Response: <pre><code>{\n  \"announcements\": \"5\",\n  \"last_winner\": \"B94C505029F04BC057A0486ADA8BD07981B4A8736AE6581F2E98C6D18498146F\",\n  \"total_tally\": \"51145880360792646375807054724596663794\",\n  \"blocks\": {\n    \"B94C505029F04BC057A0486ADA8BD07981B4A8736AE6581F2E98C6D18498146F\": {\n      \"tally\": \"51145880360792646375807054724596663794\",\n      \"contents\": {\n        \"type\": \"state\",\n        \"account\": \"nano_3fihmbtuod33s4nrbqfczhk9zy9ddqimwjshzg4c3857es8c9631i5rg6h9p\",\n        \"previous\": \"EE125B1B1D85D3C24636B3590E1642D9F21B166C0C6CD99C9C6087A1224A0C44\",\n        \"representative\": \"nano_3o7uzba8b9e1wqu5ziwpruteyrs3scyqr761x7ke6w1xctohxfh5du75qgaj\",\n        \"balance\": \"218195000000000000000000000000\",\n        \"link\": \"0000000000000000000000000000000000000000000000000000000000000000\",\n        \"link_as_account\": \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\",\n        \"signature\": \"B1BD285235C612C5A141FA61793D7C6C762D3F104A85102DED5FBD6B4514971C4D044ACD3EC8C06A9495D8E83B6941B54F8DABA825ADF799412ED9E2C86D7A0C\",\n        \"work\": \"05bb28cd8acbe71d\"\n      },\n      \"representatives\": {\n        \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\": \"12617828599372664613607727105312358589\",\n        \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\": \"5953738757270291536911559258663615240\",\n        ...\n        \"nano_3i4n5n6c6xssapbdtkdoutm88c5zjmatc5tc77xyzdkpef8akid9errcpjnx\": \"0\"\n      }\n    }\n  }\n}\n</code></pre></p>","title":"confirmation_info"},{"location":"commands/rpc-protocol/#confirmation_quorum","text":"<p>version 16.0+  Returns information about node elections settings &amp; observed network state:</p> <ul> <li><code>quorum_delta</code>: Online weight times <code>online_weight_quorum_percent</code></li> <li><code>online_weight_quorum_percent</code>: Percent of online vote weight required for confirmation</li> <li><code>online_weight_minimum</code>: When calculating online weight, the node is forced to assume at least this much voting weight is online, thus setting a floor for voting weight to confirm transactions at <code>online_weight_minimum</code> * <code>quorum_delta</code></li> <li><code>online_stake_total</code>: Total online weight from gossip vote traffic</li> <li><code>peers_stake_total</code>: Total online weight from direct node connections</li> <li><code>trended_stake_total</code>: Median of online weight samples taken every 5 minutes over previous 2 week period</li> <li>Removed in version 22.0: <code>peers_stake_required</code></li> </ul> <p>Request: <pre><code>{  \n  \"action\": \"confirmation_quorum\"      \n}\n</code></pre> Response: <pre><code>{\n  \"quorum_delta\": \"41469707173777717318245825935516662250\",\n  \"online_weight_quorum_percent\": \"50\",\n  \"online_weight_minimum\": \"60000000000000000000000000000000000000\",\n  \"online_stake_total\": \"82939414347555434636491651871033324568\",\n  \"peers_stake_total\": \"69026910610720098597176027400951402360\",\n  \"trended_stake_total\": \"81939414347555434636491651871033324568\"\n}   \n</code></pre></p> <p>Optional \"peer_details\"</p> <p>version 17.0+ </p> <p>Boolean, false by default. If true, add account/ip/rep weight for each peer considered in the summation of peers_stake_total.</p> <p>Response field \"peers_stake_required\"</p> <p>version 19.0+</p> <p>The effective stake needed from directly connected peers for quorum. Per v19, this field is computed as <code>max(quorum_delta, online_weight_minimum)</code>. If <code>peers_stake_total</code> is lower than this value, the node will not mark blocks as confirmed.</p>","title":"confirmation_quorum"},{"location":"commands/rpc-protocol/#database_txn_tracker","text":"<p>v19.0+ </p>  <p>Debug purposes only</p> <p>This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system.</p>  <p>Returns a list of open database transactions which are equal or greater than the <code>min_read_time</code> or <code>min_write_time</code> for reads and read-writes respectively.  </p> <p>Request: <pre><code>{\n  \"action\": \"database_txn_tracker\",\n  \"min_read_time\" : \"1000\",\n  \"min_write_time\" : \"0\"\n}\n</code></pre> Response on Windows/Debug: <pre><code>{\n  \"txn_tracking\": [\n    {\n      \"thread\": \"Blck processing\",  // Which thread held the transaction\n      \"time_held_open\": \"2\",        // Seconds the transaction has currently been held open for\n      \"write\": \"true\",              // If true it is a write lock, otherwise false.\n      \"stacktrace\": [\n        {\n          \"name\": \"nano::mdb_store::tx_begin_write\",\n          \"address\": \"00007FF7142C5F86\",\n          \"source_file\": \"c:\\\\users\\\\wesley\\\\documents\\\\raiblocks\\\\nano\\\\node\\\\lmdb.cpp\",\n          \"source_line\": \"825\"\n        },\n        {\n          \"name\": \"nano::block_processor::process_batch\",\n          \"address\": \"00007FF714121EEA\",\n          \"source_file\": \"c:\\\\users\\\\wesley\\\\documents\\\\raiblocks\\\\nano\\\\node\\\\blockprocessor.cpp\",\n          \"source_line\": \"243\"\n        },\n        {\n          \"name\": \"nano::block_processor::process_blocks\",\n          \"address\": \"00007FF71411F8A6\",\n          \"source_file\": \"c:\\\\users\\\\wesley\\\\documents\\\\raiblocks\\\\nano\\\\node\\\\blockprocessor.cpp\",\n          \"source_line\": \"103\"\n        },\n        ...\n      ]\n    }\n    ... // other threads\n  ]\n}\n</code></pre></p>","title":"database_txn_tracker"},{"location":"commands/rpc-protocol/#delegators","text":"<p>version 8.0+  Returns a list of pairs of delegator accounts and balances given a representative account</p> <p>Request: <pre><code>{\n  \"action\": \"delegators\",\n  \"account\": \"nano_1111111111111111111111111111111111111111111111111117353trpda\"\n}\n</code></pre> Response: <pre><code>{\n  \"delegators\": {\n    \"nano_13bqhi1cdqq8yb9szneoc38qk899d58i5rcrgdk5mkdm86hekpoez3zxw5sd\": \"500000000000000000000000000000000000\",\n    \"nano_17k6ug685154an8gri9whhe5kb5z1mf5w6y39gokc1657sh95fegm8ht1zpn\": \"961647970820730000000000000000000000\"\n  }\n}\n</code></pre></p> <p>Optional parameters: since V23.0 </p> <ul> <li><code>threshold</code>: minimum required balance for a delegating account to be included in the response</li> <li><code>count</code>: number of delegators to return</li> <li><code>start</code>: account in the list you would like to start after, to allow for paging responses</li> </ul>","title":"delegators"},{"location":"commands/rpc-protocol/#delegators_count","text":"<p>version 8.0+  Get number of delegators for a specific representative account </p> <p>Request: <pre><code>{\n  \"action\": \"delegators_count\",\n  \"account\": \"nano_1111111111111111111111111111111111111111111111111117353trpda\"\n}\n</code></pre> Response: <pre><code>{\n  \"count\": \"2\"\n}\n</code></pre></p>","title":"delegators_count"},{"location":"commands/rpc-protocol/#deterministic_key","text":"<p>Derive deterministic keypair from seed based on index </p> <p>Request: <pre><code>{\n  \"action\": \"deterministic_key\",\n  \"seed\": \"0000000000000000000000000000000000000000000000000000000000000000\",\n  \"index\": \"0\"\n}\n</code></pre> Response: <pre><code>{\n  \"private\": \"9F0E444C69F77A49BD0BE89DB92C38FE713E0963165CCA12FAF5712D7657120F\",\n  \"public\": \"C008B814A7D269A1FA3C6528B19201A24D797912DB9996FF02A1FF356E45552B\",\n  \"account\": \"nano_3i1aq1cchnmbn9x5rsbap8b15akfh7wj7pwskuzi7ahz8oq6cobd99d4r3b7\"\n}\n</code></pre></p>","title":"deterministic_key"},{"location":"commands/rpc-protocol/#epoch_upgrade","text":"<p>enable_control required, version 20.0+ </p>  <p>Debug purposes only</p> <p>This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system.</p>  <p>Upgrade network to new epoch with epoch signer private key. This spawns a background task to iterate over all accounts and add the epoch block to any accounts that do not have it. It will return <code>{ \"started\" = \"1\" }</code> if the background task was spawned successfully or <code>{ \"started\" = \"0\" }</code> if the operation could not be started. Reasons for not being able to start the operations include the node being stopped and a previous being in progress. <code>epoch</code> can be set to either 1 (representing the network upgrade to state blocks) or 2 (representing the network upgrade for increase work difficulty).</p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"epoch_upgrade\",\n  \"epoch\": \"1\",\n  \"key\": \"0000000000000000000000000000000000000000000000000000000000000000\"\n}\n</code></pre> Response: <pre><code>{\n  \"started\": \"1\"\n}\n</code></pre> Optional \"count\" Number. Determines limit of number of accounts to upgrade.</p> <p>Optional \"threads\" version 21.0+ Number. Determines limit of work threads to use for concurrent upgrade processes (useful with multiple work peers or high work peer latency).</p>","title":"epoch_upgrade"},{"location":"commands/rpc-protocol/#frontier_count","text":"<p>Reports the number of accounts in the ledger  </p> <p>Request: <pre><code>{\n  \"action\": \"frontier_count\"\n}\n</code></pre> Response: <pre><code>{\n  \"count\": \"920471\"\n}\n</code></pre></p>","title":"frontier_count"},{"location":"commands/rpc-protocol/#frontiers","text":"<p>Returns a list of pairs of account and block hash representing the head block starting at account up to count </p> <p>Request: <pre><code>{\n  \"action\": \"frontiers\",\n  \"account\": \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\",\n  \"count\": \"1\"\n}\n</code></pre> Response: <pre><code>{\n  \"frontiers\" : {\n    \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n  }\n}\n</code></pre></p>","title":"frontiers"},{"location":"commands/rpc-protocol/#keepalive","text":"<p>enable_control required Tells the node to send a keepalive packet to address:port </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"keepalive\",\n  \"address\": \"::ffff:192.169.0.1\",\n  \"port\": \"1024\"\n}\n</code></pre> Response: <pre><code>{\n  \"started\": \"1\"\n}\n</code></pre></p>","title":"keepalive"},{"location":"commands/rpc-protocol/#key_create","text":"<p>Generates an adhoc random keypair </p> <p>Request: <pre><code>{\n  \"action\": \"key_create\"\n}\n</code></pre> Response: <pre><code>{\n  \"private\": \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\",\n  \"public\": \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\",\n  \"account\": \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\"\n}\n</code></pre></p>","title":"key_create"},{"location":"commands/rpc-protocol/#key_expand","text":"<p>Derive public key and account number from private key </p> <p>Request: <pre><code>{\n  \"action\": \"key_expand\",\n  \"key\": \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\"\n}\n</code></pre> Response: <pre><code>{\n  \"private\": \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\",\n  \"public\": \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\",\n  \"account\": \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\"\n}\n</code></pre></p>","title":"key_expand"},{"location":"commands/rpc-protocol/#ledger","text":"<p>enable_control required, version 9.0+  Returns frontier, open block, change representative block, balance, last modified timestamp from local database &amp; block count starting at account up to count </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>   <p>Includes unconfirmed blocks</p> <p>This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network.</p>  <p>Request: <pre><code>{\n  \"action\": \"ledger\",\n  \"account\": \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\",\n  \"count\": \"1\"\n}\n</code></pre> Response: <pre><code>{\n  \"accounts\": {\n    \"nano_11119gbh8hb4hj1duf7fdtfyf5s75okzxdgupgpgm1bj78ex3kgy7frt3s9n\": {\n      \"frontier\": \"E71AF3E9DD86BBD8B4620EFA63E065B34D358CFC091ACB4E103B965F95783321\",\n      \"open_block\": \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\",\n      \"representative_block\": \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\",\n      \"balance\": \"0\",\n      \"modified_timestamp\": \"1511476234\",\n      \"block_count\": \"2\"\n    }\n  }\n}\n</code></pre> Optional \"representative\", \"weight\", \"receivable\" Booleans, false by default. Additionally returns representative, voting weight, receivable balance for each account   </p> <p>Request: <pre><code>{\n  \"action\": \"ledger\",\n  \"account\": \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\",\n  \"count\": \"1\",\n  \"representative\": \"true\",\n  \"weight\": \"true\",\n  \"receivable\": \"true\"\n}\n</code></pre> Response: <pre><code>{\n  \"accounts\": {\n    \"nano_11119gbh8hb4hj1duf7fdtfyf5s75okzxdgupgpgm1bj78ex3kgy7frt3s9n\": {\n      \"frontier\": \"E71AF3E9DD86BBD8B4620EFA63E065B34D358CFC091ACB4E103B965F95783321\",\n      \"open_block\": \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\",\n      \"representative_block\": \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\",\n      \"balance\": \"0\",\n      \"modified_timestamp\": \"1511476234\",\n      \"block_count\": \"2\",\n      \"representative\": \"nano_1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjtwnqposrs\",\n      \"weight\": \"0\",\n      \"pending\": \"0\",\n      \"receivable\": \"0\"\n    }   \n  }   \n}\n</code></pre> Optional \"modified_since\" version 11.0+  UNIX timestamp (number), 0 by default. Return only accounts modified in local database after specific timestamp   </p> <p>Optional \"sorting\" Boolean, false by default. Additional sorting accounts in descending order NOTE: The \"count\" option is ignored if \"sorting\" is specified</p> <p>Optional \"threshold\" version 19.0+ Number (128 bit, decimal), default 0. Return only accounts with balance above threshold. If receivable is also given, the number compared with the threshold is the sum of account balance and receivable balance.</p>","title":"ledger"},{"location":"commands/rpc-protocol/#node_id","text":"<p>enable_control required, version 17.0+ </p>  <p>Debug purposes only</p> <p>This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system.</p>  <p>Returns private key, public key and node ID number with checksum (similar to account representation) from the existing node ID created on startup. \"as_account\" field is deprecated version 20.0 will generate the node_id with <code>node_</code> prefix, earlier versions will generate with <code>nano_</code> prefix </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"node_id\"\n}\n</code></pre> Response: <pre><code>{\n  \"private\": \"2AD75C9DC20EA497E41722290C4DC966ECC4D6C75CAA4E447961F918FD73D8C7\",\n  \"public\": \"78B11E1777B8E7DF9090004376C3EDE008E84680A497C0805F68CA5928626E1C\",\n  \"as_account\": \"nano_1y7j5rdqhg99uyab1145gu3yur1ax35a3b6qr417yt8cd6n86uiw3d4whty3\",\n  \"node_id\": \"node_1y7j5rdqhg99uyab1145gu3yur1ax35a3b6qr417yt8cd6n86uiw3d4whty3\"\n}\n</code></pre></p>","title":"node_id"},{"location":"commands/rpc-protocol/#node_id_delete","text":"<p>enable_control required, version 17.0+</p>  <p>Debug purposes only</p> <p>This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system.</p>  <p>Removing node ID (restart required to take effect)</p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"node_id_delete\"\n}\n</code></pre> Response: <pre><code>{\n  \"deprecated\": \"1\"\n}\n</code></pre></p>","title":"node_id_delete"},{"location":"commands/rpc-protocol/#peers","text":"<p>Returns a list of pairs of online peer IPv6:port and its node protocol network version    </p> <p>Request: <pre><code>{\n  \"action\": \"peers\"\n}\n</code></pre></p> <p>Response version 8.0+: <pre><code>{\n  \"peers\": {\n    \"[::ffff:172.17.0.1]:32841\": \"16\"\n  }\n}\n</code></pre></p> <p>Response before version 8.0: <pre><code>{\n  \"peers\": [\n      \"[::ffff:172.17.0.1]:32841\"\n  ]\n}\n</code></pre> Optional \"peer_details\"</p> <p>version 18.0+  Boolean, false by default. Returns a list of peers IPv6:port with its node protocol network version and node ID. The node ID is random and is not a Nano address. As of Version V21+ <code>type</code> returns <code>tcp</code>, as <code>udp</code> was deprecated and is not longer used for peering with that node.</p> <p>version 20.0 will generate the node_id with <code>node_</code> prefix, earlier versions will generate with <code>nano_</code> prefix </p> <p>Request: <pre><code>{\n  \"action\": \"peers\",\n  \"peer_details\": \"true\"\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"peers\": {\n    \"[::ffff:172.17.0.1]:7075\": {\n      \"protocol_version\": \"18\",\n      \"node_id\": \"node_1y7j5rdqhg99uyab1145gu3yur1ax35a3b6qr417yt8cd6n86uiw3d4whty3\",\n      \"type\": \"tcp\"\n    }\n  }\n}\n</code></pre></p>","title":"peers"},{"location":"commands/rpc-protocol/#pending","text":"<p>Deprecated in V23.0+. Replaced by receivable</p>","title":"pending"},{"location":"commands/rpc-protocol/#pending_exists","text":"<p>Deprecated in V23.0+. Replaced by receivable_exists</p>","title":"pending_exists"},{"location":"commands/rpc-protocol/#process","text":"<p>Publish block to the network. Using the optional <code>json_block</code> is recommended since v19.0. In v20.0-v21.3, blocks are watched for confirmation by default (see optional <code>watch_work</code>).  If <code>enable_control</code> is not set to <code>true</code> on the node, then the optional <code>watch_work</code> must be set to <code>false</code>. In V22.0+ the work watcher has been removed.</p>  <p>Including <code>subtype</code> in <code>process</code> RPC calls highly recommended</p> <p>In order to avoid potential incorrect sends including the optional <code>subtype</code> parameter on all <code>process</code> RPC calls is highly recommended. In the next version of the RPC this parameter will be required.</p>  <p>Request: <pre><code>{\n  \"action\": \"process\",\n  \"json_block\": \"true\",\n  \"subtype\": \"send\",\n  \"block\": {\n    \"type\": \"state\",\n    \"account\": \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\",\n    \"previous\": \"6CDDA48608C7843A0AC1122BDD46D9E20E21190986B19EAC23E7F33F2E6A6766\",\n    \"representative\": \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\",\n    \"balance\": \"40200000001000000000000000000000000\",\n    \"link\": \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\",\n    \"link_as_account\": \"nano_33t5by1653nt196hfwm5q3wq7oxtaix97r7bhox5zn8eratrzoqsny49ftsd\",\n    \"signature\": \"A5DB164F6B81648F914E49CAB533900C389FAAD64FBB24F6902F9261312B29F730D07E9BCCD21D918301419B4E05B181637CF8419ED4DCBF8EF2539EB2467F07\",\n    \"work\": \"000bc55b014e807d\"\n  }\n}\n</code></pre> Response: <pre><code>{\n  \"hash\": \"E2FB233EF4554077A7BF1AA85851D5BF0B36965D2B0FB504B2BC778AB89917D3\"\n}\n</code></pre> Optional \"force\" version 13.1+ Boolean, false by default. Manually forcing fork resolution if processed block is not accepted as fork</p> <p>Optional \"subtype\" version 18.0+ String, empty by default. Additional check for state blocks subtype, i.e. prevent accidental sending to incorrect accounts instead of receiving receivable blocks. Options:</p> <ul> <li><code>send</code> - account balance is reduced</li> <li><code>receive</code> - account balance is increased</li> <li><code>open</code> - first block on account with account balance initially set higher than 0</li> <li><code>change</code> - account balance is unchanged, representative field value changed to valid public address</li> <li><code>epoch</code> - block signed with epoch signer private key (does not allow balance or representative changes)</li> </ul> <p>Optional \"json_block\" version 19.0+ Boolean, default \"false\". If \"true\", \"block\" must contain a JSON subtree instead of a JSON string.</p> <p>Optional \"watch_work\" added in version 20.0+ removed in version 22.0 Boolean, default \"true\". If \"true\", block will be placed on watch for confirmation, with equivalent functionality to in-wallet transactions using send, receive and account_representative_set, including republishing and rework if confirmation is delayed (default is 5 seconds, set by <code>work_watcher_period</code> config entry) and if active_difficulty is higher than the block's PoW difficulty.</p> <p>Optional \"async\" version 22.0+ Boolean, default \"false\". If \"true\", requests will add the blocks to the block processor queue and <code>{\"started\":\"1\"}</code> will be immediately returned, instead of waiting for block process completion to return. To know if the block was properly processed, monitor the WebSocket topic <code>new_unconfirmed_block</code> and a notification for that successful block will be sent.</p>","title":"process"},{"location":"commands/rpc-protocol/#receivable","text":"<p>since V23.0, use pending for V22.1 and below Returns a list of block hashes which have not yet been received by this account.</p> <p>Request: <pre><code>{\n  \"action\": \"receivable\",\n  \"account\": \"nano_1111111111111111111111111111111111111111111111111117353trpda\",\n  \"count\": \"1\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\": [ \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\" ]\n}\n</code></pre> Optional \"count\" Number. Determines limit of number of blocks to return.</p> <p>Optional \"threshold\" version 8.0+  Number (128 bit, decimal). Returns a list of receivable block hashes with amount more or equal to threshold </p> <p>Request: <pre><code>{\n  \"action\": \"receivable\",\n  \"account\": \"nano_1111111111111111111111111111111111111111111111111117353trpda\",\n  \"count\": \"1\",\n  \"threshold\": \"1000000000000000000000000\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\" : {\n    \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\": \"6000000000000000000000000000000\"\n  }\n}\n</code></pre> Optional \"source\" version 9.0+  Boolean, false by default. Returns a list of receivable block hashes with amount and source accounts   </p> <p>Request: <pre><code>{\n  \"action\": \"receivable\",\n  \"account\": \"nano_1111111111111111111111111111111111111111111111111117353trpda\",\n  \"count\": \"1\",\n  \"source\": \"true\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\" : {\n    \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\": {\n      \"amount\": \"6000000000000000000000000000000\",\n      \"source\": \"nano_3dcfozsmekr1tr9skf1oa5wbgmxt81qepfdnt7zicq5x3hk65fg4fqj58mbr\"\n    }\n  }\n}\n</code></pre> Optional \"include_active\"</p> <p>version 15.0+  Boolean, false by default. Include active blocks without finished confirmations </p> <p>Request: <pre><code>{\n  \"action\": \"receivable\",\n  \"account\": \"nano_1111111111111111111111111111111111111111111111111117353trpda\",\n  \"count\": \"1\",\n  \"include_active\": \"true\"\n}\n</code></pre></p> <p>Optional \"min_version\"</p> <p>version 15.0+  Boolean, false by default. Returns the minimum version (epoch) of a block which can pocket this receivable block.</p> <p>Optional \"sorting\"</p> <p>Boolean, false by default. Additionally sorts the blocks by their amounts in descending order.   </p> <p>version 22.0+  If used with \"count\" returns the absolute sorted values.</p> <p>version 19.0+  If used with \"count\" only sorts relative to the first receivable entries found up to count so not necessarily the ones with the largest receivable balance.   </p> <p>Optional \"include_only_confirmed\"</p> <p>version 19.0+ Boolean, true by default (version 22.0+), previously false by default. Only returns confirmed blocks but with the caveat that their confirmation height might not be up-to-date yet. If false, unconfirmed blocks will also be returned.</p>","title":"receivable"},{"location":"commands/rpc-protocol/#receivable_exists","text":"<p>since V23.0, use pending_exists for V22.1 and below Check whether block is receivable by hash </p> <p>Request: <pre><code>{\n  \"action\": \"receivable_exists\",\n  \"hash\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"exists\" : \"1\"\n}\n</code></pre></p> <p>Optional \"include_active\"</p> <p>version 15.0+  Boolean, false by default. Include active blocks without finished confirmations </p> <p>Request: <pre><code>{\n  \"action\": \"receivable_exists\",\n  \"hash\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"include_active\": \"true\"\n}\n</code></pre></p> <p>Optional \"include_only_confirmed\"</p> <p>version 19.0+ Boolean, true by default (version 22.0+), previously false by default. Only returns confirmed blocks but with the caveat that their confirmation height might not be up-to-date yet. If false, unconfirmed blocks will also be returned.</p>","title":"receivable_exists"},{"location":"commands/rpc-protocol/#representatives","text":"<p>Returns a list of pairs of representative and its voting weight  </p> <p>Request: <pre><code>{\n  \"action\": \"representatives\"\n}\n</code></pre> Response: <pre><code>{\n  \"representatives\": {\n    \"nano_1111111111111111111111111111111111111111111111111117353trpda\": \"3822372327060170000000000000000000000\",\n    \"nano_1111111111111111111111111111111111111111111111111awsq94gtecn\": \"30999999999999999999999999000000\",\n    \"nano_114nk4rwjctu6n6tr6g6ps61g1w3hdpjxfas4xj1tq6i8jyomc5d858xr1xi\": \"0\"\n  }\n}\n</code></pre> Optional \"count\"</p> <p>version 9.0+  Number. Returns a list of pairs of representative and its voting weight up to count</p> <p>Optional \"sorting\"</p> <p>version 9.0+  Boolean, false by default. Additional sorting representatives in descending order NOTE: The \"count\" option is ignored if \"sorting\" is specified  </p>","title":"representatives"},{"location":"commands/rpc-protocol/#representatives_online","text":"<p>version 18.0+  Returns a list of online representative accounts that have voted recently  </p> <p>Request: <pre><code>{\n  \"action\": \"representatives_online\"\n}\n</code></pre> Response: <pre><code>{\n  \"representatives\": [\n    \"nano_1111111111111111111111111111111111111111111111111117353trpda\",\n    \"nano_1111111111111111111111111111111111111111111111111awsq94gtecn\",\n    \"nano_114nk4rwjctu6n6tr6g6ps61g1w3hdpjxfas4xj1tq6i8jyomc5d858xr1xi\"\n  ]\n}\n</code></pre> versions 11.2\u201317.1  Returns a list of pairs of online representative accounts that have voted recently and empty strings Response: <pre><code>{\n  \"representatives\" : {\n    \"nano_1111111111111111111111111111111111111111111111111117353trpda\": \"\",\n    \"nano_1111111111111111111111111111111111111111111111111awsq94gtecn\": \"\",\n    \"nano_114nk4rwjctu6n6tr6g6ps61g1w3hdpjxfas4xj1tq6i8jyomc5d858xr1xi\": \"\"\n  }\n}\n</code></pre> Optional \"weight\"</p> <p>version 17.0+  Boolean, false by default. Returns voting weight for each representative. Response: <pre><code>{\n  \"representatives\": {\n    \"nano_114nk4rwjctu6n6tr6g6ps61g1w3hdpjxfas4xj1tq6i8jyomc5d858xr1xi\": {\n      \"weight\": \"150462654614686936429917024683496890\"\n    }\n  }\n}\n</code></pre></p> <p>Optional \"accounts\" Array of accounts. Returned list is filtered for only these accounts.</p> <p>Request: <pre><code>{\n  \"action\": \"representatives_online\",\n  \"accounts\": [\"nano_1q3hqecaw15cjt7thbtxu3pbzr1eihtzzpzxguoc37bj1wc5ffoh7w74gi6p\", \"nano_1111111111111111111111111111111111111111111111111117353trpda\"]\n}\n</code></pre> Response: <pre><code>{\n  \"representatives\": [\n    \"nano_1q3hqecaw15cjt7thbtxu3pbzr1eihtzzpzxguoc37bj1wc5ffoh7w74gi6p\"\n  ]\n}\n</code></pre></p>","title":"representatives_online"},{"location":"commands/rpc-protocol/#republish","text":"<p>Rebroadcast blocks starting at hash to the network    </p> <p>Request: <pre><code>{\n  \"action\": \"republish\",\n  \"hash\": \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\"\n}\n</code></pre> Response: <pre><code>{\n  \"success\": \"\",\n  \"blocks\": [\n    \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\",\n    \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\"\n  ]\n}\n</code></pre></p> <p>Optional \"sources\"</p> <p>version 8.0+  Boolean, false by default. Additionally rebroadcast source chain blocks for receive/open up to sources depth   </p> <p>Request: <pre><code>{\n  \"action\": \"republish\",\n  \"hash\": \"90D0C16AC92DD35814E84BFBCC739A039615D0A42A76EF44ADAEF1D99E9F8A35\",\n  \"count\": \"1\",\n  \"sources\": \"2\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\": [\n    \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\",\n    \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\",\n    \"90D0C16AC92DD35814E84BFBCC739A039615D0A42A76EF44ADAEF1D99E9F8A35\"\n  ]\n}\n</code></pre></p> <p>Optional \"destinations\"</p> <p>version 8.0+  Boolean, false by default. Additionally rebroadcast destination chain blocks from receive up to destinations depth   </p> <p>Request: <pre><code>{\n  \"action\": \"republish\",\n  \"hash\": \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\",\n  \"count\": \"1\",\n  \"destinations\": \"2\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\": [\n    \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\",\n    \"90D0C16AC92DD35814E84BFBCC739A039615D0A42A76EF44ADAEF1D99E9F8A35\",\n    \"18563C814A54535B7C12BF76A0E23291BA3769536634AB90AD0305776A533E8E\"\n  ]\n}\n</code></pre></p>","title":"republish"},{"location":"commands/rpc-protocol/#sign","text":"<p>version 18.0+ Signing provided block with private key or key of account from wallet. Using the optional <code>json_block</code> is recommended since v19.0.  </p> <p>Request with private key: <pre><code>{\n  \"action\": \"sign\",\n  \"json_block\": \"true\",\n  \"key\": \"1D3759BB2CA187A66875D3B8497624159A576FD315E07F702B99B92BC59FC14A\",\n  \"block\": {\n    \"type\": \"state\",\n    \"account\": \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\",\n    \"previous\": \"6CDDA48608C7843A0AC1122BDD46D9E20E21190986B19EAC23E7F33F2E6A6766\",\n    \"representative\": \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\",\n    \"balance\": \"40200000001000000000000000000000000\",\n    \"link\": \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\",\n    \"link_as_account\": \"nano_33t5by1653nt196hfwm5q3wq7oxtaix97r7bhox5zn8eratrzoqsny49ftsd\",\n    \"signature\": \"A5DB164F6B81648F914E49CAB533900C389FAAD64FBB24F6902F9261312B29F730D07E9BCCD21D918301419B4E05B181637CF8419ED4DCBF8EF2539EB2467F07\",\n    \"work\": \"000bc55b014e807d\"\n  }\n}\n</code></pre></p> <p>Request with account from wallet: <pre><code>{\n  \"action\": \"sign\",\n  \"json_block\": \"true\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"account\": \"nano_18ky5chy5ws89oi46ki4zjy6x5ezpmj98zg6icwke9bmuy99nosieyqf8c1h\",\n  \"block\": {\n    \"type\": \"state\",\n    \"account\": \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\",\n    \"previous\": \"6CDDA48608C7843A0AC1122BDD46D9E20E21190986B19EAC23E7F33F2E6A6766\",\n    \"representative\": \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\",\n    \"balance\": \"40200000001000000000000000000000000\",\n    \"link\": \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\",\n    \"link_as_account\": \"nano_33t5by1653nt196hfwm5q3wq7oxtaix97r7bhox5zn8eratrzoqsny49ftsd\",\n    \"signature\": \"A5DB164F6B81648F914E49CAB533900C389FAAD64FBB24F6902F9261312B29F730D07E9BCCD21D918301419B4E05B181637CF8419ED4DCBF8EF2539EB2467F07\",\n    \"work\": \"000bc55b014e807d\"\n  }\n}\n</code></pre> Response: <pre><code>{\n  \"signature\": \"2A71F3877033F5966735F260E906BFCB7FA82CDD543BCD1224F180F85A96FC26CB3F0E4180E662332A0DFE4EE6A0F798A71C401011E635604E532383EC08C70D\",\n  \"block\": {\n    \"type\": \"state\",\n    \"account\": \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\",\n    \"previous\": \"6CDDA48608C7843A0AC1122BDD46D9E20E21190986B19EAC23E7F33F2E6A6766\",\n    \"representative\": \"nano_3pczxuorp48td8645bs3m6c3xotxd3idskrenmi65rbrga5zmkemzhwkaznh\",\n    \"balance\": \"40200000001000000000000000000000000\",\n    \"link\": \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\",\n    \"link_as_account\": \"nano_33t5by1653nt196hfwm5q3wq7oxtaix97r7bhox5zn8eratrzoqsny49ftsd\",\n    \"signature\": \"2A71F3877033F5966735F260E906BFCB7FA82CDD543BCD1224F180F85A96FC26CB3F0E4180E662332A0DFE4EE6A0F798A71C401011E635604E532383EC08C70D\",\n    \"work\": \"000bc55b014e807d\"\n  }\n}\n</code></pre></p> <p>Optional \"json_block\"</p> <p>version 19.0+ Default \"false\". If \"true\", the input \"block\" must contain a JSON subtree instead of a JSON string. In addition, the response block will be a JSON subtree.</p> <p>Optional sign block hash Requires configuration changes. Set \"rpc.enable_sign_hash\" to \"true\" </p> <p>Request: <pre><code>{\n  \"action\": \"sign\",\n  \"hash\": \"E2FB233EF4554077A7BF1AA85851D5BF0B36965D2B0FB504B2BC778AB89917D3\"\n}\n</code></pre> Response: <pre><code>{\n  \"signature\": \"2A71F3877033F5966735F260E906BFCB7FA82CDD543BCD1224F180F85A96FC26CB3F0E4180E662332A0DFE4EE6A0F798A71C401011E635604E532383EC08C70D\"\n}\n</code></pre></p>","title":"sign"},{"location":"commands/rpc-protocol/#stats","text":"<p>version 12.2+ For configuration and other details, please see Statistics from RPC</p> <p>Request counters: <pre><code>{\n  \"action\": \"stats\",\n  \"type\": \"counters\"\n}\n</code></pre></p> <p>Counters response: <pre><code>{\n  \"type\": \"counters\",\n  \"created\": \"2018.03.29 01:46:36\",\n  \"entries\": [\n    {\n      \"time\": \"01:46:36\",\n      \"type\": \"traffic_tcp\",\n      \"detail\": \"all\",\n      \"dir\": \"in\",\n      \"value\": \"3122792\"\n    },\n    {\n      \"time\": \"01:46:36\",\n      \"type\": \"traffic_tcp\",\n      \"detail\": \"all\",\n      \"dir\": \"out\",\n      \"value\": \"203184\"\n    }\n    ...\n  ]\n}\n</code></pre></p> <p>version 18.0+ also returns \"stat_duration_seconds\": the number of seconds since startup or since the last \"stats_clear\" call</p> <p>Request samples: <pre><code>{\n  \"action\": \"stats\",\n  \"type\": \"samples\"\n}\n</code></pre></p> <p>Samples response: <pre><code>{\n  \"type\": \"samples\",\n  \"created\": \"2018.03.29 01:47:08\",\n  \"entries\": [\n    {\n      \"time\": \"01:47:04\",\n      \"type\": \"traffic_tcp\",\n      \"detail\": \"all\",\n      \"dir\": \"in\",\n      \"value\": \"59480\"\n    },\n    {\n      \"time\": \"01:47:05\",\n      \"type\": \"traffic_tcp\",\n      \"detail\": \"all\",\n      \"dir\": \"in\",\n      \"value\": \"44496\"\n    }\n    ...\n   ]\n}\n</code></pre> version 18.0+ NOTE: This call is for debug purposes only and is unstable as returned objects may be frequently changed.</p> <p>Request objects: <pre><code>{\n  \"action\": \"stats\",\n  \"type\": \"objects\"\n}\n</code></pre></p> <p>Objects response: <pre><code>{\n  \"node\": {\n    \"ledger\": {\n      \"bootstrap_weights\": {\n        \"count\": \"125\",\n        \"size\": \"7000\"\n      }\n    },\n    \"peers\": {\n      \"peers\": {\n        \"count\": \"38\",\n        \"size\": \"7296\"\n      },\n      \"attempts\": {\n        \"count\": \"95\",\n        \"size\": \"3800\"\n      },\n    },\n    ...\n  }\n}\n</code></pre></p> <p>version 22.0+ NOTE: This call is for debug purposes only and is unstable as returned objects may be frequently changed and will be different depending on the ledger backend.</p> <p>Request database: <pre><code>{\n  \"action\": \"stats\",\n  \"type\": \"database\"\n}\n</code></pre></p> <p>Database response: LMDB: <pre><code>{\n    \"branch_pages\": \"0\",\n    \"depth\": \"1\",\n    \"entries\": \"11\",\n    \"leaf_pages\": \"1\",\n    \"overflow_pages\": \"0\",\n    \"page_size\": \"4096\"\n}\n</code></pre> RocksDB: <pre><code>{\n    \"cur-size-all-mem-tables\": \"74063072\",\n    \"size-all-mem-tables\": \"487744504\",\n    \"estimate-table-readers-mem\": \"113431016\",\n    \"estimate-live-data-size\": \"17756425993\",\n    \"compaction-pending\": \"0\",\n    \"estimate-num-keys\": \"81835964\",\n    \"estimate-pending-compaction-bytes\": \"0\",\n    \"total-sst-files-size\": \"20350606013\",\n    \"block-cache-capacity\": \"318767104\",\n    \"block-cache-usage\": \"150310696\"\n}\n</code></pre></p>","title":"stats"},{"location":"commands/rpc-protocol/#stats_clear","text":"<p>version 18.0+</p> <p>Clears all collected statistics. The \"stat_duration_seconds\" value in the \"stats\" action is also reset.</p> <p>Request: <pre><code>{\n  \"action\": \"stats_clear\"\n}\n</code></pre> Response: <pre><code>{\n  \"success\": \"\"\n}\n</code></pre></p>","title":"stats_clear"},{"location":"commands/rpc-protocol/#stop","text":"<p>enable_control required Method to safely shutdown node  </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"stop\"\n}\n</code></pre> Response: <pre><code>{\n  \"success\": \"\"\n}\n</code></pre></p>","title":"stop"},{"location":"commands/rpc-protocol/#successors","text":"<p>Returns a list of block hashes in the account chain starting at block up to count (direction from open block up to frontier, from older blocks to newer). Will list all blocks up to frontier (latest block) of this chain when count is set to \"-1\". The requested block hash is included in the answer.    </p> <p>Request: <pre><code>{\n  \"action\": \"successors\",\n  \"block\": \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\",\n  \"count\": \"1\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\" : [\n    \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\"\n  ]\n}\n</code></pre> Optional \"offset\"</p> <p>version 18.0+  Number, 0 by default. Return the account chain block hashes offset by the specified number of blocks    </p> <p>Optional \"reverse\"</p> <p>version 18.0+  Boolean, false by default. Returns a consecutive list of block hashes in the account chain starting at block back to count (direction from frontier back to open block, from newer blocks to older). Equal to chain </p>","title":"successors"},{"location":"commands/rpc-protocol/#telemetry","text":"<p>version 21.0+ Return metrics from other nodes on the network. By default, returns a summarized view of the whole network. See below for details on obtaining local telemetry data. Networking - node telemetry contains more detailed information on the protocol implementation of telemetry. Request: <pre><code>{\n  \"action\": \"telemetry\"\n}\n</code></pre> Response: <pre><code>{\n    \"block_count\": \"5777903\",\n    \"cemented_count\": \"688819\",\n    \"unchecked_count\": \"443468\",\n    \"account_count\": \"620750\",\n    \"bandwidth_cap\": \"1572864\",\n    \"peer_count\": \"32\",\n    \"protocol_version\": \"18\",\n    \"uptime\": \"556896\",\n    \"genesis_block\": \"F824C697633FAB78B703D75189B7A7E18DA438A2ED5FFE7495F02F681CD56D41\",\n    \"major_version\": \"21\",\n    \"minor_version\": \"0\",\n    \"patch_version\": \"0\",\n    \"pre_release_version\": \"0\",\n    \"maker\": \"0\",\n    \"timestamp\": \"1587055945990\",\n    \"active_difficulty\": \"fffffff800000000\"\n}\n</code></pre></p> <p>This contains a summarized view of the network with 10% of lower/upper bound results removed to reduce the effect of outliers. Returned values are calculated as follows:</p>    Field Name Response details     block_count average count of blocks in ledger (including unconfirmed)   cemented_count average count of blocks cemented in ledger (only confirmed)   unchecked_count average count of unchecked blocks. This should only be considered an estimate as nodes running RocksDB may not return exact counts.   account_count average count of accounts in ledger   bandwidth_cap <code>0</code> = unlimited; the mode is chosen if there is more than 1 common result otherwise the results are averaged (excluding <code>0</code>)   peer_count average count of peers nodes are connected to   *_version mode (most common) of (protocol, major, minor, patch, pre_release) versions   uptime average number of seconds since the UTC epoch at the point where the response is sent from the peer   genesis_block mode (most common) of genesis block hashes   maker mode (most common), meant for third party node software implementing the protocol so that it can be distinguished, <code>0</code> = Nano Foundation, <code>1</code> = Nano Foundation pruned node   timestamp number of milliseconds since the UTC epoch at the point where the response is sent from the peer   active_difficulty V22.0+ returns minimum network difficulty due to deprecated active difficulty measurements up to V21.3 returns average of the current network difficulty, see active_difficulty \"network_current\"    <p>This only returns values which have been cached by the ongoing polling of peer metric data. Each response is cached for 60 seconds on the main network and 15 seconds on beta; a few additional seconds are added on for response delays.</p> <p>Optional \"raw\" When setting raw to true metrics from all nodes are displayed. It additionally contains signature, node_id, address and port from each peer.</p> <p>Request: <pre><code>{\n  \"action\": \"telemetry\",\n  \"raw\" : \"true\"\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"metrics\": [\n    {\n      \"block_count\": \"5777903\",\n      ...\n      \"node_id\": \"node_1cmi8difuruopgzpnb4ybrnnj5rproxwuwe5mad7ucbsekakiwn37qqg1zo5\",\n      \"signature\": \"5F8DEE5F895D53E122FDEB4B1B4118A41F9DDB818C6B299B09DF59131AF9F201BB7057769423F6B0C868B57509177B54D5D2C731405FE607527F5E2B6B2E290F\",\n      \"address\": \"::ffff:152.89.106.89\",\n      \"port\": \"54000\"\n    },\n    {\n      \"block_count\": \"5777902\",\n      ...    \n      \"node_id\": \"node_3ipxdjrha3rfg9h3spiz5jkprw8kdj7bph9fir51kf6pmryzznsyhakqznk3\",\n      \"signature\": \"D691B855D9EC70EA6320DE609EB379EB706845433E034AD22721E8F91BF3A26156F40CCB2E98653F1E63D4CE5F10F530A835DE1B154D1213464E3B9BB9BE4908\",\n      \"address\": \"::ffff:95.216.205.215\",\n      \"port\": \"54006\"\n    }\n    ...\n  ]\n}\n</code></pre></p> <p>Optional \"address\" &amp; \"port\" Get metrics from a specific peer. It accepts both ipv4 and ipv6 addresses <pre><code>{\n  \"action\": \"telemetry\",\n  \"address\": \"246.125.123.456\",\n  \"port\": \"7075\"\n}\n</code></pre></p>  <p>Requesting telemetry data from the local node</p> <p>Metrics for the local node can be requested using the peering port and any loopback address 127.0.0.1, ::1 or [::1]</p>","title":"telemetry"},{"location":"commands/rpc-protocol/#validate_account_number","text":"<p>Check whether account is a valid account number using checksum  </p> <p>Request: <pre><code>{\n  \"action\": \"validate_account_number\",\n  \"account\": \"nano_1111111111111111111111111111111111111111111111111117353trpda\"\n}\n</code></pre> Response: <pre><code>{\n  \"valid\" : \"1\"\n}\n</code></pre></p>","title":"validate_account_number"},{"location":"commands/rpc-protocol/#version","text":"<p>Returns version information for RPC, Store, Protocol (network), Node (Major &amp; Minor version). Since version 20.0 also returns the Network label and identifier (hash of the genesis open block), and Build Info. Since version 21.0 also returns Database backend information. RPC Version always returns \"1\" as of 01/11/2018 </p> <p>Request: <pre><code>{\n  \"action\": \"version\"\n}\n</code></pre> Response: <pre><code>{\n  \"rpc_version\": \"1\",\n  \"store_version\": \"14\",\n  \"protocol_version\": \"17\",\n  \"node_vendor\": \"Nano 20.0\",\n  \"store_vendor\": \"LMDB 0.9.23\", // since V21.0\n  \"network\": \"live\", // since v20.0\n  \"network_identifier\": \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\", // since v20.0\n  \"build_info\": \"Build Info &lt;git hash&gt; \\\"&lt;compiler&gt; version \\\" \\\"&lt;compiler version string&gt;\\\" \\\"BOOST &lt;boost version&gt;\\\" BUILT \\\"&lt;build date&gt;\\\"\" // since v20.0\n}\n</code></pre></p>","title":"version"},{"location":"commands/rpc-protocol/#unchecked","text":"<p>version 8.0+  Returns a list of pairs of unchecked block hashes and their json representation up to count. Using the optional <code>json_block</code> is recommended since v20.0.</p> <p>Request: <pre><code>{\n  \"action\": \"unchecked\",\n  \"json_block\": \"true\",\n  \"count\": \"1\",\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\": {\n    \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\": {\n      \"type\": \"state\",\n      \"account\": \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\",\n      \"previous\": \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\",\n      \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n      \"balance\": \"5606157000000000000000000000000000000\",\n      \"link\": \"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\",\n      \"link_as_account\": \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\",\n      \"signature\": \"82D41BC16F313E4B2243D14DFFA2FB04679C540C2095FEE7EAE0F2F26880AD56DD48D87A7CC5DD760C5B2D76EE2C205506AA557BF00B60D8DEE312EC7343A501\",\n      \"work\": \"8a142e07a10996d5\"\n    }\n  }\n}\n</code></pre></p>","title":"unchecked"},{"location":"commands/rpc-protocol/#unchecked_clear","text":"<p>enable_control required, version 8.0+  Clear unchecked synchronizing blocks   </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n    \"action\": \"unchecked_clear\"\n}\n</code></pre> Response: <pre><code>{\n    \"success\": \"\"\n}\n</code></pre></p>","title":"unchecked_clear"},{"location":"commands/rpc-protocol/#unchecked_get","text":"<p>version 8.0+ Retrieves a json representation of unchecked synchronizing block by hash. Using the optional <code>json_block</code> is recommended since v19.0.  </p> <p>Request: <pre><code>{\n  \"action\": \"unchecked_get\",\n  \"json_block\": \"true\",\n  \"hash\": \"19BF0C268C2D9AED1A8C02E40961B67EA56B1681DE274CD0C50F3DD972F0655C\"\n}\n</code></pre> Response: <pre><code>{\n  \"modified_timestamp\": \"1565856525\",\n  \"contents\": {\n    \"type\": \"state\",\n    \"account\": \"nano_1hmqzugsmsn4jxtzo5yrm4rsysftkh9343363hctgrjch1984d8ey9zoyqex\",\n    \"previous\": \"009C587914611E83EE7F75BD9C000C430C720D0364D032E84F37678D7D012911\",\n    \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n    \"balance\": \"189012679592109992600249228\",\n    \"link\": \"0000000000000000000000000000000000000000000000000000000000000000\",\n    \"link_as_account\": \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\",\n    \"signature\": \"845C8660750895843C013CE33E31B80EF0A7A69E52DDAF74A5F1BDFAA9A52E4D9EA2C3BE1AB0BD5790FCC1AD9B7A3D2F4B44EECE4279A8184D414A30A1B4620F\",\n    \"work\": \"0dfb32653e189699\"\n  }\n}\n</code></pre> Optional \"json_block\"</p> <p>version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string.</p>","title":"unchecked_get"},{"location":"commands/rpc-protocol/#unchecked_keys","text":"<p>version 8.0+  Retrieves unchecked database keys, blocks hashes &amp; a json representations of unchecked receivable blocks starting from key up to count. Using the optional <code>json_block</code> is recommended since v19.0.   </p>  Known issue with RocksDB: RPC <code>unchecked_keys</code> not working properly <p>Issue: The RPC <code>unchecked_keys</code> is returning <code>0</code> for all calls when used with the RocksDB backend. This known issue will be resolved in a future release.</p> <p>Solution: Until the issue is resolved any integrations using this command should remain on the existing LMDB backend</p>  <p>Request: <pre><code>{\n  \"action\": \"unchecked_keys\",\n  \"json_block\": \"true\",\n  \"key\": \"19BF0C268C2D9AED1A8C02E40961B67EA56B1681DE274CD0C50F3DD972F0655C\",\n  \"count\": \"1\"\n}\n</code></pre> Response: <pre><code>{\n  \"unchecked\": [\n    {\n      \"key\": \"19BF0C268C2D9AED1A8C02E40961B67EA56B1681DE274CD0C50F3DD972F0655C\",\n      \"hash\": \"A1A8558CBABD3F7C1D70F8CB882355F2EF688E7F30F5FDBD0204CAE157885056\",\n      \"modified_timestamp\": \"1565856744\",\n      \"contents\": {\n        \"type\": \"state\",\n        \"account\": \"nano_1hmqzugsmsn4jxtzo5yrm4rsysftkh9343363hctgrjch1984d8ey9zoyqex\",\n        \"previous\": \"19BF0C268C2D9AED1A8C02E40961B67EA56B1681DE274CD0C50F3DD972F0655C\",\n        \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n        \"balance\": \"189012679592109992600249226\",\n        \"link\": \"0000000000000000000000000000000000000000000000000000000000000000\",\n        \"link_as_account\": \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\",\n        \"signature\": \"FF5D49925AD3C8705E6EEDD993E8C4120E6107D7F1CB53B287773448DEA0B1D32918E67804248FC83609F0D93401D833DFA33127F21B6CD02F75D6E31A00450A\",\n        \"work\": \"8193ddf00947e694\"\n      }\n    }\n  ]\n}\n</code></pre></p> <p>Optional \"json_block\"</p> <p>version 19.0+ Default \"false\". If \"true\", \"contents\" will contain a JSON subtree instead of a JSON string.</p>","title":"unchecked_keys"},{"location":"commands/rpc-protocol/#unopened","text":"<p>enable_control required, version 19.0+ </p> <p>Returns the total receivable balance for unopened accounts in the local database, starting at account (optional) up to count (optional), sorted by account number. Notes: By default excludes the burn account.   </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"unopened\",\n  \"account\": \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\",\n  \"count\": \"1\"\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"accounts\": {\n    \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\": \"207034077034226183413773082289554618448\"\n  }\n}\n</code></pre></p> <p>Optional \"threshold\" Number (128 bit, decimal), default 0. Return only accounts with total receivable balance above threshold.</p>","title":"unopened"},{"location":"commands/rpc-protocol/#uptime","text":"<p>version 18.0+  Return node uptime in seconds  </p> <p>Request: <pre><code>{\n  \"action\": \"uptime\"\n}\n</code></pre> Response: <pre><code>{\n    \"seconds\": \"6000\"\n}\n</code></pre></p>","title":"uptime"},{"location":"commands/rpc-protocol/#work_cancel","text":"<p>enable_control required Stop generating work for block  </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"work_cancel\",\n  \"hash\": \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\"\n}\n</code></pre> Response: <pre><code>{\n  \"success\": \"\"\n}\n</code></pre></p>","title":"work_cancel"},{"location":"commands/rpc-protocol/#work_generate","text":"<p>enable_control required Generates work for block. hash is the frontier of the account or in the case of an open block, the public key representation of the account which can be found with account_key.  </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"work_generate\",\n  \"hash\": \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\"\n}\n</code></pre> Response: <pre><code>{\n  \"work\": \"2b3d689bbcb21dca\",\n  \"difficulty\": \"fffffff93c41ec94\", // of the resulting work\n  \"multiplier\": \"1.182623871097636\", // since v19.0, calculated from default base difficulty\n  \"hash\": \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\" // since v20.0\n}\n</code></pre></p> <p>Optional \"use_peers\"</p> <p>version 14.0+ Boolean, false by default. If the optional <code>use_peers</code> parameter is set to <code>true</code>, then the node will query its work peers (if it has any). Without this parameter, the node will only generate work locally.</p> <p>Optional \"difficulty\"</p>  <p>Difficulty no longer useful</p> <p>With version 22.0+ the difficulty is no longer used for prioritization so targeting higher difficulty thresholds on work generation is not useful. However, this can still be used for targeting a lower difficulty for receive blocks. This option may be removed in a future release.</p>  <p>version 19.0+ Difficulty value (16 hexadecimal digits string, 64 bit). Uses difficulty value to generate work. Defaults to the network base difficulty.</p> <p>Optional \"multiplier\"</p>  <p>Multiplier no longer useful</p> <p>With version 22.0+ the difficulty is no longer used for prioritization so targeting higher multipliers on work generation is not useful. This option will be removed in a future release.</p>  <p>version 20.0+ Multiplier from base difficulty (positive number). Uses equivalent difficulty as multiplier from base difficulty to generate work. Note: overrides the <code>difficulty</code> parameter.  </p> <p>Optional \"account\"</p> <p>version 20.0+ A valid Nano account. If provided and <code>use_peers</code> is set to <code>true</code>, this information will be relayed to work peers.</p> <p>Optional \"version\"</p> <p>version 21.0+ Work version string. Currently \"work_1\" is the default and only valid option.</p> <p>Optional \"block\"</p> <p>version 21.0+ A valid Nano block (string or JSON). Using the optional <code>json_block</code> is recommended. If provided and <code>difficulty</code> or <code>multiplier</code> are both not given, RPC processor tries to calculate the appropriate difficulty threshold based on ledger data. Note: block should be the one where the resulting work value will be used, not the previous block.</p> <p>Optional \"json_block\"</p> <p>version 21.0+ Default \"false\". If \"true\", <code>block</code> in the request should contain a JSON subtree instead of a JSON string.</p>","title":"work_generate"},{"location":"commands/rpc-protocol/#work_peer_add","text":"<p>enable_control required, version 8.0+  Add specific IP address and port as work peer for node until restart   </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"work_peer_add\",\n  \"address\": \"::ffff:172.17.0.1\",\n  \"port\": \"7076\"\n}\n</code></pre> Response: <pre><code>{\n  \"success\": \"\"\n}\n</code></pre></p>","title":"work_peer_add"},{"location":"commands/rpc-protocol/#work_peers","text":"<p>enable_control required, version 8.0+ </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"work_peers\"\n}\n</code></pre> Response: <pre><code>{\n  \"work_peers\": [\n    \"::ffff:172.17.0.1:7076\"\n  ]\n}\n</code></pre></p>","title":"work_peers"},{"location":"commands/rpc-protocol/#work_peers_clear","text":"<p>enable_control required, version 8.0+  Clear work peers node list until restart   </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"work_peers_clear\"\n}\n</code></pre> Response: <pre><code>{\n  \"success\": \"\"\n}\n</code></pre></p>","title":"work_peers_clear"},{"location":"commands/rpc-protocol/#work_validate","text":"<p>Check whether work is valid for block. Provides two values: valid_all is <code>true</code> if the work is valid at the current network difficulty (work can be used for any block). valid_receive is <code>true</code> if the work is valid for use in a receive block.</p> <p>Read the details below when using this RPC in V21.</p>  <p>Semantics change in V21.0</p> <p>In V21.0, when the optional difficulty is not given, valid is no longer included in the response.</p> <p>Use the new response fields \"valid_all\" and \"valid_receive\" taking into account the subtype of the block using this work value:</p> <ul> <li>valid_all validates at the current network difficulty. As soon as the node processes the first epoch_2 block, this difficulty is increased.</li> <li>valid_receive is completely accurate only once the epoch_2 upgrade is finished. Until the upgrade is finished, it is only accurate if the account where this work will be used is already upgraded. The upgrade status of an account can be obtained from account_info. The account is upgraded if \"account_version\" is <code>\"2\"</code>.</li> </ul>  <p>Request: <pre><code>{\n  \"action\": \"work_validate\",\n  \"work\": \"2bf29ef00786a6bc\",\n  \"hash\": \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\"\n}\n</code></pre> Response since v21.0: <pre><code>{\n  \"valid_all\": \"1\",\n  \"valid_receive\": \"1\",\n  \"difficulty\": \"fffffff93c41ec94\",\n  \"multiplier\": \"1.182623871097636\" // calculated from the default base difficulty\n}\n</code></pre></p>  Response up to v20.0 <pre><code>{\n  \"valid\": \"1\",\n  \"difficulty\": \"fffffff93c41ec94\", // since v19.0\n  \"multiplier\": \"9.4609\" // since v19.0\n}\n</code></pre>  <p>Optional \"difficulty\"</p> <p>version 19.0+ Difficulty value (16 hexadecimal digits string, 64 bit). Uses difficulty value to validate work. Defaults to the network base difficulty. Response includes extra field valid signifying validity at the given difficulty.  </p> <p>Request with given \"difficulty\" <pre><code>{\n  \"action\": \"work_validate\",\n  \"difficulty\": \"ffffffffffffffff\",\n  \"work\": \"2bf29ef00786a6bc\",\n  \"hash\": \"718CC2121C3E641059BC1C2CFC45666C99E8AE922F7A807B7D07B62C995D79E2\"\n}\n</code></pre> Response with given \"difficulty: <pre><code>{\n  \"valid\": \"0\",\n  \"valid_all\": \"1\", // since v21.0\n  \"valid_receive\": \"1\", // since v21.0\n  \"difficulty\": \"fffffff93c41ec94\",\n  \"multiplier\": \"1.182623871097636\"\n}\n</code></pre></p> <p>Optional \"multiplier\"</p> <p>version 20.0+ Multiplier from base difficulty (positive number). Uses equivalent difficulty as multiplier from base difficulty to validate work. Note: overrides the <code>difficulty</code> parameter.  </p> <p>Optional \"version\"</p> <p>version 21.0+ Work version string. Currently \"work_1\" is the default and only valid option.</p>","title":"work_validate"},{"location":"commands/rpc-protocol/#wallet-rpcs","text":"<p>For development and testing only</p> <p>Below are RPC commands that interact with the built-in, QT-based node wallet. This wallet is only recommended for development and testing. For production integrations, setting up custom External Management processes is required.</p>","title":"Wallet RPCs"},{"location":"commands/rpc-protocol/#account_create","text":"<p>enable_control required Creates a new account, insert next deterministic key in wallet </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"account_create\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"account\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n}\n</code></pre> Optional \"index\"</p> <p>version 18.0+ unset by default. Indicates which index to create account for starting with 0  </p> <p>Request: <pre><code>{\n  \"action\": \"account_create\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"index\": \"1\"\n}\n</code></pre></p> <p>Optional \"work\"</p> <p>version 9.0+ Boolean, true by default. Setting false disables work generation after creating account  </p> <p>Request: <pre><code>{\n  \"action\": \"account_create\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"work\": \"false\"\n}\n</code></pre></p>","title":"account_create"},{"location":"commands/rpc-protocol/#account_list","text":"<p>Lists all the accounts inside wallet </p> <p>Request: <pre><code>{\n  \"action\": \"account_list\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"accounts\": [\n    \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n  ]\n}\n</code></pre></p>","title":"account_list"},{"location":"commands/rpc-protocol/#account_move","text":"<p>enable_control required Moves accounts from source to wallet </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"account_move\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"source\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"accounts\": [\n    \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n  ]\n}\n</code></pre> Response: <pre><code>{\n  \"moved\" : \"1\"\n}\n</code></pre></p>","title":"account_move"},{"location":"commands/rpc-protocol/#account_remove","text":"<p>enable_control required Remove account from wallet </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"account_remove\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"account\": \"nano_39a73oy5ungrhxy5z5oao1xso4zo7dmgpjd4u74xcrx3r1w6rtazuouw6qfi\"\n}\n</code></pre> Response: <pre><code>{\n  \"removed\": \"1\"\n}\n</code></pre></p>","title":"account_remove"},{"location":"commands/rpc-protocol/#account_representative_set","text":"<p>enable_control required Sets the representative for account in wallet </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"account_representative_set\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"account\": \"nano_39a73oy5ungrhxy5z5oao1xso4zo7dmgpjd4u74xcrx3r1w6rtazuouw6qfi\",\n  \"representative\": \"nano_16u1uufyoig8777y6r8iqjtrw8sg8maqrm36zzcm95jmbd9i9aj5i8abr8u5\"\n}\n</code></pre> Response: <pre><code>{\n  \"block\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Optional \"work\"</p> <p>version 9.0+ Work value (16 hexadecimal digits string, 64 bit). Uses work value for block from external source and disables work precaching for this account. Not using this field re-enables work precaching.  </p>","title":"account_representative_set"},{"location":"commands/rpc-protocol/#accounts_create","text":"<p>enable_control required, version 9.0+ Creates new accounts, insert next deterministic keys in wallet up to count </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"accounts_create\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"count\": \"2\"\n}\n</code></pre> Response: <pre><code>{\n  \"accounts\": [\n    \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n    \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3s00000000\"\n  ]\n}\n</code></pre> Optional enabling work generation version 11.2+ Boolean, false by default. Enables work generation after creating accounts  </p> <p>Request: <pre><code>{\n  \"action\": \"accounts_create\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"count\": \"2\",\n  \"work\": \"true\"\n}\n</code></pre> Note: Before version 11.2 work generation was enabled by default, if you want to disable work generation for previous versions, use \"work\": \"false\"</p>","title":"accounts_create"},{"location":"commands/rpc-protocol/#block_create-optional-wallet","text":"<p>See block_create Node RPC command above</p>","title":"block_create (optional wallet)"},{"location":"commands/rpc-protocol/#password_change","text":"<p>enable_control required Changes the password for wallet to password </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"password_change\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"password\": \"test\"\n}\n</code></pre> Response: <pre><code>{\n  \"changed\" : \"1\"\n}\n</code></pre></p>","title":"password_change"},{"location":"commands/rpc-protocol/#password_enter","text":"<p>Enters the password in to wallet to unlock it  </p> <p>Request: <pre><code>{\n  \"action\": \"password_enter\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"password\": \"test\"\n}\n</code></pre> Response: <pre><code>{\n  \"valid\": \"1\"\n}\n</code></pre></p>","title":"password_enter"},{"location":"commands/rpc-protocol/#password_valid","text":"<p>Checks whether the password entered for wallet is valid  </p> <p>Request: <pre><code>{\n  \"action\": \"password_valid\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"valid\" : \"1\"\n}\n</code></pre></p>","title":"password_valid"},{"location":"commands/rpc-protocol/#receive","text":"<p>enable_control required Receive receivable block for account in wallet. If receiving the block opens the account, sets the account representative to a wallet representative. Before v21, the representative is set to the account itself.  </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"receive\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"account\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n  \"block\": \"53EAA25CE28FA0E6D55EA9704B32604A736966255948594D55CBB05267CECD48\"\n}\n</code></pre> Response: <pre><code>{\n  \"block\": \"EE5286AB32F580AB65FD84A69E107C69FBEB571DEC4D99297E19E3FA5529547B\"\n}\n</code></pre> Optional \"work\"</p> <p>version 9.0+ Work value (16 hexadecimal digits string, 64 bit). Uses work value for block from external source and disables work precaching for this account. Not using this field re-enables work precaching.  </p>","title":"receive"},{"location":"commands/rpc-protocol/#receive_minimum","text":"<p>enable_control required, version 8.0+  Returns receive minimum for node wallet  </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"receive_minimum\"\n}\n</code></pre> Response: <pre><code>{\n  \"amount\": \"1000000000000000000000000\"\n}\n</code></pre></p>","title":"receive_minimum"},{"location":"commands/rpc-protocol/#receive_minimum_set","text":"<p>enable_control required, version 8.0+  Set amount as new receive minimum for node wallet until restart  </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"receive_minimum_set\",\n  \"amount\": \"1000000000000000000000000000000\"\n}\n</code></pre> Response: <pre><code>{\n  \"success\": \"\"\n}\n</code></pre></p>","title":"receive_minimum_set"},{"location":"commands/rpc-protocol/#search_pending","text":"<p>enable_control required Tells the node to look for receivable blocks for any account in wallet </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"search_pending\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"started\": \"1\"\n}\n</code></pre></p>","title":"search_pending"},{"location":"commands/rpc-protocol/#search_pending_all","text":"<p>enable_control required, version 8.0+ Tells the node to look for receivable blocks for any account in all available wallets  </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"search_pending_all\"\n}\n</code></pre> Response: <pre><code>{\n  \"success\": \"\"  \n}\n</code></pre></p>","title":"search_pending_all"},{"location":"commands/rpc-protocol/#send","text":"<p>enable_control required Send amount from source in wallet to destination </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>   <p>Use of <code>id</code> option is highly recommended</p> <p>Integrations using the node wallet must ensure idempotency for transactions and this can be done externally if preferred. Using the <code>id</code> field provides this option internally and is highly recommended for all node wallet uses.</p>  <p>Request: <pre><code>{\n  \"action\": \"send\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"source\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n  \"destination\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n  \"amount\": \"1000000\",\n  \"id\": \"your-unique-id\"\n}\n</code></pre> Response: <pre><code>{\n  \"block\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Proof of Work is precomputed for one transaction in the background when you are using the node wallet to track accounts.  If it has been a while since your last transaction it will send instantly, the next one will need to wait for Proof of Work to be generated.</p> <p>If the request times out, then the send may or may not have gone through. If you want to the ability to retry a failed send, all send calls must specify the id parameter as follows</p> <p>Highly recommended \"id\"</p> <p>version 10.0+ </p> <p>You can (and should) specify a unique id for each spend to provide idempotency. That means that if you call <code>send</code> two times with the same id, the second request won't send any additional Nano, and will return the first block instead. The id can be any string. This may be a required parameter in the future.</p> <p>If you accidentally reuse an id, the send will not go through (it will be seen as a duplicate request), so make sure your ids are unique! They must be unique per node, and are not segregated per wallet.</p> <p>Using the same id for requests with different parameters (wallet, source, destination, and amount) is undefined behavior and may result in an error in the future.</p> <p>Request: <pre><code>{\n  \"action\": \"send\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"source\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n  \"destination\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n  \"amount\": \"1000000\",\n  \"id\": \"7081e2b8fec9146e\"\n}\n</code></pre> Response: <pre><code>{\n  \"block\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre></p> <p>Sending the request again will yield the same block, and will not affect the ledger.</p> <p>Optional \"work\"</p> <p>version 9.0+ Work value (16 hexadecimal digits string, 64 bit). Uses work value for block from external source and disables work precaching for this account. Not using this field re-enables work precaching.  </p> <p>Request: <pre><code>{\n  \"action\": \"send\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"source\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n  \"destination\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n  \"amount\": \"1000000\",\n  \"work\": \"2bf29ef00786a6bc\"\n}\n</code></pre></p>","title":"send"},{"location":"commands/rpc-protocol/#sign-optional-wallet","text":"<p>See sign Node RPC command above</p>","title":"sign (optional wallet)"},{"location":"commands/rpc-protocol/#wallet_add","text":"<p>enable_control required Add an adhoc private key key to wallet </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"wallet_add\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"key\": \"34F0A37AAD20F4A260F0A5B3CB3D7FB50673212263E58A380BC10474BB039CE4\"\n}\n</code></pre> Response: <pre><code>{\n  \"account\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n}\n</code></pre> Optional disabling work generation</p> <p>version 9.0+ Boolean, false by default. Disables work generation after adding account  </p> <p>Request: <pre><code>{\n  \"action\": \"wallet_add\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"key\": \"34F0A37AAD20F4A260F0A5B3CB3D7FB50673212263E58A380BC10474BB039CE4\",\n  \"work\": \"false\"\n}\n</code></pre></p>","title":"wallet_add"},{"location":"commands/rpc-protocol/#wallet_add_watch","text":"<p>enable_control required, version 11.0+ Add watch-only accounts to wallet </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"wallet_add_watch\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"accounts\": [\n    \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n    \"nano_111111111111111111111111111111111111111111111111111000000000\"\n  ]\n}\n</code></pre> Response: <pre><code>{\n  \"success\" : \"\"\n}\n</code></pre></p>","title":"wallet_add_watch"},{"location":"commands/rpc-protocol/#wallet_balances","text":"<p>Returns how many raw is owned and how many have not yet been received by all accounts in wallet </p>  <p>Includes unconfirmed blocks</p> <p>This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network.</p>   <p>The term <code>pending</code> is being deprecated in favor of <code>receivable</code>. For compatibility reasons both terms are still available for many calls and in responses. For more details see: https://docs.nano.org/releases/release-v23-0/#pendingreceivable-term-rpc-updates.</p>  <p>Request: <pre><code>{\n  \"action\": \"wallet_balances\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"balances\" : {\n    \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\": {\n      \"balance\": \"10000\",\n      \"pending\": \"10000\",\n      \"receivable\": \"10000\"\n    }\n  }\n}\n</code></pre> Optional \"threshold\"</p> <p>version 9.0+  Number (128 bit, decimal). Returns wallet accounts balances more or equal to threshold </p>","title":"wallet_balances"},{"location":"commands/rpc-protocol/#wallet_change_seed","text":"<p>enable_control required Changes seed for wallet to seed.  Notes: Clear all deterministic accounts in wallet! To restore account from new seed use RPC accounts_create. <code>last_restored_account</code> and <code>restored_count</code> fields in response returned since version 19.0+ </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"wallet_change_seed\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"seed\": \"74F2B37AAD20F4A260F0A5B3CB3D7FB51673212263E58A380BC10474BB039CEE\"\n}\n</code></pre> Response: <pre><code>{\n  \"success\" : \"\",\n  \"last_restored_account\": \"nano_1mhdfre3zczr86mp44jd3xft1g1jg66jwkjtjqixmh6eajfexxti7nxcot9c\",\n  \"restored_count\": \"1\"\n}\n</code></pre></p> <p>Optional \"count\"</p> <p>version 18.0+  Number, 0 by default. Manually set count of accounts to restore from seed    </p>","title":"wallet_change_seed"},{"location":"commands/rpc-protocol/#wallet_contains","text":"<p>Check whether wallet contains account </p> <p>Request: <pre><code>{\n  \"action\": \"wallet_contains\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"account\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n}\n</code></pre> Response: <pre><code>{\n  \"exists\": \"1\"\n}\n</code></pre></p>","title":"wallet_contains"},{"location":"commands/rpc-protocol/#wallet_create","text":"<p>enable_control required Creates a new random wallet id  </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"wallet_create\"\n}\n</code></pre> Response: <pre><code>{\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Optional \"seed\"</p> <p>version 18.0+  Seed value (64 hexadecimal digits string, 256 bit). Changes seed for a new wallet to seed, returning last restored account from given seed &amp; restored count  </p>","title":"wallet_create"},{"location":"commands/rpc-protocol/#wallet_destroy","text":"<p>enable_control required Destroys wallet and all contained accounts  </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"wallet_destroy\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"destroyed\": \"1\"\n}\n</code></pre></p>","title":"wallet_destroy"},{"location":"commands/rpc-protocol/#wallet_export","text":"<p>Return a json representation of wallet </p> <p>Request: <pre><code>{\n  \"action\": \"wallet_export\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"json\" : \"{\\\"0000000000000000000000000000000000000000000000000000000000000000\\\": \\\"0000000000000000000000000000000000000000000000000000000000000001\\\"}\"\n}\n</code></pre></p>","title":"wallet_export"},{"location":"commands/rpc-protocol/#wallet_frontiers","text":"<p>Returns a list of pairs of account and block hash representing the head block starting for accounts from wallet </p> <p>Request: <pre><code>{\n  \"action\": \"wallet_frontiers\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"frontiers\": {\n    \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n  }\n}\n</code></pre></p>","title":"wallet_frontiers"},{"location":"commands/rpc-protocol/#wallet_history","text":"<p>version 18.0+  Reports send/receive information for accounts in wallet. Change blocks are skipped, open blocks will appear as receive. Response will start with most recent blocks according to local ledger.</p>  <p>Includes unconfirmed blocks</p> <p>This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network.</p>  <p>Request: <pre><code>{\n  \"action\": \"wallet_history\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"history\":\n  [\n    {\n      \"type\": \"send\",\n      \"account\": \"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\",\n      \"amount\": \"30000000000000000000000000000000000\",\n      \"block_account\": \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\",\n      \"hash\": \"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\",\n      \"local_timestamp\": \"1527698508\"\n    },\n    {\n      \"type\": \"send\",\n      \"account\": \"nano_38ztgpejb7yrm7rr586nenkn597s3a1sqiy3m3uyqjicht7kzuhnihdk6zpz\",\n      \"amount\": \"40000000000000000000000000000000000\",\n      \"block_account\": \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\",\n      \"hash\": \"CE898C131AAEE25E05362F247760F8A3ACF34A9796A5AE0D9204E86B0637965E\",\n      \"local_timestamp\": \"1527698492\"\n    }\n  ]\n}\n</code></pre> Optional \"modified_since\"</p> <p>UNIX timestamp (number), 0 by default. Return only accounts modified in local database after specific timestamp   </p>","title":"wallet_history"},{"location":"commands/rpc-protocol/#wallet_info","text":"<p>version 15.0+  Given a wallet id, from all of the accounts in the wallet, returns:</p> <ul> <li>Sum of their balance amounts</li> <li>Total number of accounts as accounts_count</li> <li>Number of deterministic accounts as deterministic_count</li> <li>Number of adhoc (non-deterministic) accounts as adhoc_count</li> <li>Index of last account derived from the walet seed as deterministic_index (equal to deterministic accounts number if no accounts were removed)</li> <li>Sum of all frontier block heights as accounts_block_count</li> <li>Sum of confirmed block heights as accounts_cemented_block_count</li> </ul>  <p>Includes unconfirmed blocks</p> <p>This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network.</p>   <p>The term <code>pending</code> is being deprecated in favor of <code>receivable</code>. For compatibility reasons both terms are still available for many calls and in responses. For more details see: https://docs.nano.org/releases/release-v23-0/#pendingreceivable-term-rpc-updates.</p>  <p>Request: <pre><code>{\n  \"action\": \"wallet_info\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"balance\": \"10000\",\n  \"pending\": \"10000\",\n  \"receivable\": \"10000\",\n  \"accounts_count\": \"3\",\n  \"adhoc_count\": \"1\",\n  \"deterministic_count\": \"2\",\n  \"deterministic_index\": \"2\",\n  \"accounts_block_count\": \"14\",\n  \"accounts_cemented_block_count\": \"13\"\n}\n</code></pre></p>","title":"wallet_info"},{"location":"commands/rpc-protocol/#wallet_ledger","text":"<p>enable_control required, version 11.0+  Returns frontier, open block, change representative block, balance, last modified timestamp from local database &amp; block count for accounts from wallet </p>  <p>Includes unconfirmed blocks</p> <p>This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network.</p>   <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>   <p>The term <code>pending</code> is being deprecated in favor of <code>receivable</code>. For compatibility reasons both terms are still available for many calls and in responses. For more details see: https://docs.nano.org/releases/release-v23-0/#pendingreceivable-term-rpc-updates.</p>  <p>Request: <pre><code>{\n  \"action\": \"wallet_ledger\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"accounts\": {\n    \"nano_11119gbh8hb4hj1duf7fdtfyf5s75okzxdgupgpgm1bj78ex3kgy7frt3s9n\": {\n      \"frontier\": \"E71AF3E9DD86BBD8B4620EFA63E065B34D358CFC091ACB4E103B965F95783321\",\n      \"open_block\": \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\",\n      \"representative_block\": \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\",\n      \"balance\": \"0\",\n      \"modified_timestamp\": \"1511476234\",\n      \"block_count\": \"2\"\n    }\n  }\n}\n</code></pre> Optional \"representative\", \"weight\", \"receivable\"</p> <p>Booleans, false by default. Additionally returns representative, voting weight, receivable balance for each account   </p> <p>Request: <pre><code>{\n  \"action\": \"wallet_ledger\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"representative\": \"true\",\n  \"weight\": \"true\",\n  \"receivable\": \"true\"\n}\n</code></pre> Response: <pre><code>{\n  \"accounts\": {\n    \"nano_11119gbh8hb4hj1duf7fdtfyf5s75okzxdgupgpgm1bj78ex3kgy7frt3s9n\": {\n      \"frontier\": \"E71AF3E9DD86BBD8B4620EFA63E065B34D358CFC091ACB4E103B965F95783321\",\n      \"open_block\": \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\",\n      \"representative_block\": \"643B77F1ECEFBDBE1CC909872964C1DBBE23A6149BD3CEF2B50B76044659B60F\",\n      \"balance\": \"0\",\n      \"modified_timestamp\": \"1511476234\",\n      \"block_count\": \"2\",\n      \"representative\": \"nano_1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjtwnqposrs\",\n      \"weight\": \"0\",\n      \"pending\": \"0\",\n      \"receivable\": \"0\"\n    }\n  }\n}\n</code></pre> Optional \"modified_since\"</p> <p>UNIX timestamp (number), 0 by default. Return only accounts modified in local database after specific timestamp   </p>","title":"wallet_ledger"},{"location":"commands/rpc-protocol/#wallet_lock","text":"<p>enable_control required, version 9.0+ Locks wallet </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"wallet_lock\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"locked\": \"1\"\n}\n</code></pre></p>","title":"wallet_lock"},{"location":"commands/rpc-protocol/#wallet_locked","text":"<p>Checks whether wallet is locked  </p> <p>Request: <pre><code>{\n  \"action\": \"wallet_locked\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"locked\": \"0\"\n}\n</code></pre></p>","title":"wallet_locked"},{"location":"commands/rpc-protocol/#wallet_pending","text":"<p>enable_control required  Returns a list of block hashes which have not yet been received by accounts in this wallet </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"wallet_pending\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"count\": \"1\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\": {\n    \"nano_1111111111111111111111111111111111111111111111111117353trpda\": [\"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\"],\n    \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\": [\"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\"]\n  }\n}\n</code></pre> Optional \"threshold\"</p> <p>Number (128 bit, decimal). Returns a list of receivable block hashes with amount more or equal to threshold </p> <p>Request: <pre><code>{\n  \"action\": \"wallet_pending\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"count\": \"1\",\n  \"threshold\": \"1000000000000000000000000\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\": {\n    \"nano_1111111111111111111111111111111111111111111111111117353trpda\": {\n      \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\": \"6000000000000000000000000000000\"\n    },\n    \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\": {\n      \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\": \"106370018000000000000000000000000\"\n    }\n  }\n}\n</code></pre> Optional \"source\"</p> <p>version 9.0+  Boolean, false by default. Returns a list of receivable block hashes with amount and source accounts   </p> <p>Request: <pre><code>{\n  \"action\": \"wallet_pending\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"count\": \"1\",\n  \"source\": \"true\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\": {\n    \"nano_1111111111111111111111111111111111111111111111111117353trpda\": {\n      \"142A538F36833D1CC78B94E11C766F75818F8B940771335C6C1B8AB880C5BB1D\": {\n        \"amount\": \"6000000000000000000000000000000\",\n        \"source\": \"nano_3dcfozsmekr1tr9skf1oa5wbgmxt81qepfdnt7zicq5x3hk65fg4fqj58mbr\"\n      }\n    },\n    \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\": {\n      \"4C1FEEF0BEA7F50BE35489A1233FE002B212DEA554B55B1B470D78BD8F210C74\": {\n        \"amount\": \"106370018000000000000000000000000\",\n        \"source\": \"nano_13ezf4od79h1tgj9aiu4djzcmmguendtjfuhwfukhuucboua8cpoihmh8byo\"\n      }\n    }\n  }\n}\n</code></pre> Optional \"include_active\"</p> <p>version 15.0+  Boolean, false by default. Include active blocks without finished confirmations </p> <p>Request: <pre><code>{\n  \"action\": \"wallet_pending\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"count\": \"1\",\n  \"include_active\": \"true\"\n}\n</code></pre></p> <p>Optional \"min_version\"</p> <p>version 15.0+  Boolean, false by default. Returns the minimum version (epoch) of a block which can pocket this receivable block.</p> <p>Optional \"include_only_confirmed\"</p> <p>version 19.0+ Boolean, true by default (version 22.0+), previously false by default. Only returns confirmed blocks but with the caveat that their confirmation height might not be up-to-date yet. If false, unconfirmed blocks will also be returned.</p>","title":"wallet_pending"},{"location":"commands/rpc-protocol/#wallet_representative","text":"<p>Returns the default representative for wallet </p> <p>Request: <pre><code>{\n  \"action\": \"wallet_representative\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"representative\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n}\n</code></pre></p>","title":"wallet_representative"},{"location":"commands/rpc-protocol/#wallet_representative_set","text":"<p>enable_control required Sets the default representative for wallet (used only for new accounts, already existing accounts use already set representatives) </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"wallet_representative_set\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"representative\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n}\n</code></pre> Response: <pre><code>{\n  \"set\": \"1\"\n}\n</code></pre></p> <p>Optional \"update_existing_accounts\"</p> <p>version 18.0+  Boolean, false by default. Change representative for existing accounts in wallet. May require a lot of time to complete for large wallets due to work generation for change type state blocks  </p>","title":"wallet_representative_set"},{"location":"commands/rpc-protocol/#wallet_republish","text":"<p>enable_control required, version 8.0+  Rebroadcast blocks for accounts from wallet starting at frontier down to count to the network     </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"wallet_republish\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"count\": \"2\"\n}\n</code></pre> Response: <pre><code>{\n  \"blocks\": [\n    \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\",\n    \"A170D51B94E00371ACE76E35AC81DC9405D5D04D4CEBC399AEACE07AE05DD293\",\n    \"90D0C16AC92DD35814E84BFBCC739A039615D0A42A76EF44ADAEF1D99E9F8A35\"\n  ]       \n}\n</code></pre></p>","title":"wallet_republish"},{"location":"commands/rpc-protocol/#wallet_work_get","text":"<p>enable_control required, version 8.0+  Returns a list of pairs of account and work from wallet </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"wallet_work_get\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"works\": {\n    \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\": \"432e5cf728c90f4f\"\n  }\n}\n</code></pre></p>","title":"wallet_work_get"},{"location":"commands/rpc-protocol/#work_get","text":"<p>enable_control required, version 8.0+  Retrieves work for account in wallet </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"work_get\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"account\": \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\"\n}\n</code></pre> Response: <pre><code>{\n  \"work\": \"432e5cf728c90f4f\"\n}\n</code></pre></p>","title":"work_get"},{"location":"commands/rpc-protocol/#work_set","text":"<p>enable_control required, version 8.0+  Set work for account in wallet </p>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>  <p>Request: <pre><code>{\n  \"action\": \"work_set\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"account\": \"nano_1111111111111111111111111111111111111111111111111111hifc8npp\",\n  \"work\": \"0000000000000000\"\n}\n</code></pre> Response: <pre><code>{\n    \"success\": \"\"\n}\n</code></pre></p>","title":"work_set"},{"location":"commands/rpc-protocol/#unit-conversion-rpcs","text":"","title":"Unit Conversion RPCs"},{"location":"commands/rpc-protocol/#nano_to_raw","text":"<p>Convert <code>nano</code> amount (10^30 raw) into <code>raw</code> (10^0) </p> <p>Request: <pre><code>{\n  \"action\": \"nano_to_raw\",\n  \"amount\": \"1\"\n}\n</code></pre> Response: <pre><code>{\n  \"amount\": \"1000000000000000000000000000000\"\n}\n</code></pre></p>","title":"nano_to_raw"},{"location":"commands/rpc-protocol/#raw_to_nano","text":"<p>Convert <code>raw</code> amount (10^0) into <code>nano</code> (10^30 raw)</p> <p>Request: <pre><code>{\n  \"action\": \"raw_to_nano\",\n  \"amount\": \"1000000000000000000000000000000\"\n}\n</code></pre> Response: <pre><code>{\n  \"amount\": \"1\"\n}\n</code></pre></p>","title":"raw_to_nano"},{"location":"commands/rpc-protocol/#deprecated-rpcs","text":"","title":"Deprecated RPCs"},{"location":"commands/rpc-protocol/#active_difficulty","text":"<p>added in version 19.0+ deprecated in version 22.0</p> <p>Returns the difficulty values (16 hexadecimal digits string, 64 bit) and related multiplier from base difficulty.</p>    Field Name Response Details     <code>multiplier</code> Multiplier of the <code>network_current</code> from the base difficulty of <code>network_minimum</code> for comparison. Note that in V22.0+ this will always be 1 (see below for details).   <code>network_minimum</code> Minimum difficulty required for the network for all block types   <code>network_current</code> V22.0+ same minimum difficulty above due to the deprecation of active difficulty calculations used for prioritization in previous versions; up to V21.3 10 second trended average of adjusted difficulty seen on prioritized transactions, refreshed every 500ms   <code>network_receive_minimum</code> Lower difficulty threshold exclusively for receive blocks   <code>network_receive_current</code> V22.0+ same minimum receive difficulty above due to the deprecation of active difficulty calculations used for prioritization in previous versions; up to V21.3 10 second trended average of adjusted difficulty seen on prioritized receive transactions, refreshed every 500ms     <p>Constant values returned</p> <p>Due to the deprecation of active difficulty calculations as of V22.0, this RPC call will return constant values as seen below. These values can be used as difficulty thresholds for the respective block types, but this RPC call should not be used for retrieving these values going forward.</p>  <p>Request: <pre><code>{\n  \"action\": \"active_difficulty\"\n}\n</code></pre></p> <p>Response: <pre><code>{\n    \"deprecated\": \"1\",\n    \"network_minimum\": \"fffffff800000000\",\n    \"network_receive_minimum\": \"fffffe0000000000\", // since V21.2\n    \"network_current\": \"fffffff800000000\",\n    \"network_receive_current\": \"fffffe0000000000\", // since V21.2\n    \"multiplier\": \"1\"\n}\n</code></pre></p> <p>Optional \"include_trend\"</p> <p>Boolean, false by default. Also returns the trend of difficulty seen on the network as a list of multipliers. Sampling occurs every 500ms. The list is ordered such that the first value is the most recent sample. Note: Before v20, the sampling period was between 16 and 36 seconds.</p> <p>Request: <pre><code>{\n  \"action\": \"active_difficulty\",\n  \"include_trend\": \"true\"\n}\n</code></pre></p> <p>Response: <pre><code>{\n  ...,\n  \"difficulty_trend\": [\n    \"1.156096135149775\",\n    \"1.190133894573061\",\n    \"1.135567138563921\",\n    \"1.000000000000000\",\n    \"...\",\n    \"1.000000000000000\"\n  ]\n}\n</code></pre></p>","title":"active_difficulty"},{"location":"commands/rpc-protocol/#history","text":"<p>Deprecated: please use <code>account_history</code> instead. It provides a <code>head</code> option which is identical to the history <code>hash</code> option.</p>","title":"history"},{"location":"commands/rpc-protocol/#krai_from_raw","text":"<p>Divide a raw amount down by the krai ratio.  </p> <p>Request: <pre><code>{\n  \"action\": \"krai_from_raw\",\n  \"amount\": \"1000000000000000000000000000\"\n}\n</code></pre> Response: <pre><code>{\n  \"amount\": \"1\"\n}\n</code></pre></p>","title":"krai_from_raw"},{"location":"commands/rpc-protocol/#krai_to_raw","text":"<p>Multiply an krai amount by the krai ratio.  </p> <p>Request: <pre><code>{\n  \"action\": \"krai_to_raw\",\n  \"amount\": \"1\"\n}\n</code></pre> Response: <pre><code>{\n  \"amount\": \"1000000000000000000000000000\"\n}\n</code></pre></p>","title":"krai_to_raw"},{"location":"commands/rpc-protocol/#mrai_from_raw","text":"<p>Divide a raw amount down by the Mrai ratio.  </p> <p>Request: <pre><code>{\n  \"action\": \"mrai_from_raw\",\n  \"amount\": \"1000000000000000000000000000000\"\n}\n</code></pre> Response: <pre><code>{\n  \"amount\": \"1\"\n}\n</code></pre></p>","title":"mrai_from_raw"},{"location":"commands/rpc-protocol/#mrai_to_raw","text":"<p>Multiply an Mrai amount by the Mrai ratio.  </p> <p>Request: <pre><code>{\n  \"action\": \"mrai_to_raw\",\n  \"amount\": \"1\"\n}\n</code></pre> Response: <pre><code>{\n  \"amount\": \"1000000000000000000000000000000\"\n}\n</code></pre></p>","title":"mrai_to_raw"},{"location":"commands/rpc-protocol/#rai_from_raw","text":"<p>Divide a raw amount down by the rai ratio.  </p> <p>Request: <pre><code>{\n  \"action\": \"rai_from_raw\",\n  \"amount\": \"1000000000000000000000000\"\n}\n</code></pre> Response: <pre><code>{\n  \"amount\": \"1\"\n}\n</code></pre></p>","title":"rai_from_raw"},{"location":"commands/rpc-protocol/#rai_to_raw","text":"<p>Multiply an rai amount by the rai ratio.  </p> <p>Request: <pre><code>{\n  \"action\": \"rai_to_raw\",\n  \"amount\": \"1\"\n}\n</code></pre> Response: <pre><code>{\n  \"amount\": \"1000000000000000000000000\"\n}\n</code></pre></p>","title":"rai_to_raw"},{"location":"commands/rpc-protocol/#removed-rpcs","text":"","title":"Removed RPCs"},{"location":"commands/rpc-protocol/#removed-in-v22","text":"","title":"Removed in v22"},{"location":"commands/rpc-protocol/#block_count_type","text":"<p>Reports the number of blocks in the ledger by type (send, receive, open, change, state with version)   </p> <p>Request: <pre><code>{\n  \"action\": \"block_count_type\"\n}\n</code></pre> Response: <pre><code>{\n  \"send\": \"5016664\",\n  \"receive\": \"4081228\",\n  \"open\": \"546457\",\n  \"change\": \"24193\",\n  \"state_v0\": \"4216537\",\n  \"state_v1\": \"10653709\",\n  \"state\": \"14870246\"\n}\n</code></pre></p>","title":"block_count_type"},{"location":"commands/rpc-protocol/#payment_begin","text":"<p>Begin a new payment session. Searches wallet for an account that's marked as available and has a 0 balance. If one is found, the account number is returned and is marked as unavailable. If no account is found, a new account is created, placed in the wallet, and returned.  </p> <p>Request: <pre><code>{\n  \"action\": \"payment_begin\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"account\" : \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\"\n}\n</code></pre></p>","title":"payment_begin"},{"location":"commands/rpc-protocol/#payment_end","text":"<p>End a payment session.  Marks the account as available for use in a payment session. </p> <p>Request: <pre><code>{\n  \"action\": \"payment_end\",\n  \"account\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n  \"wallet\": \"FFFD1BAEC8EC20814BBB9059B393051AAA8380F9B5A2E6B2489A277D81789EEE\"\n}\n</code></pre> Response: <pre><code>{\n}\n</code></pre></p>","title":"payment_end"},{"location":"commands/rpc-protocol/#payment_init","text":"<p>Marks all accounts in wallet as available for being used as a payment session.  </p> <p>Request: <pre><code>{\n  \"action\": \"payment_init\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> Response: <pre><code>{\n  \"status\": \"Ready\"\n}\n</code></pre></p>","title":"payment_init"},{"location":"commands/rpc-protocol/#payment_wait","text":"<p>Wait for payment of 'amount' to arrive in 'account' or until 'timeout' milliseconds have elapsed.  </p> <p>Request: <pre><code>{\n  \"action\": \"payment_wait\",\n  \"account\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n  \"amount\": \"1\",\n  \"timeout\": \"1000\"\n}\n</code></pre> Response: <pre><code>{\n  \"deprecated\": \"1\",\n  \"status\" : \"success\"\n}\n</code></pre></p>","title":"payment_wait"},{"location":"core-development/code-standards/","text":"","title":"Code standards"},{"location":"core-development/code-standards/#formatting","text":"<p>clang-format is used to enforce most of the formatting rules, such as:</p> <ul> <li>Tabs for indentation.</li> <li>Open braces go on new lines.</li> <li>Space before open parenthesis.</li> <li>Space after comma.</li> </ul> <p>Running <code>ci/clang-format-do.sh</code> on *nix systems is required before pushing your code to ensure that the formatting is good. If you want to do formatting from the IDE, chances are there's a plugin available. Visual Studio for instance provides a way to automatically format on saving. The definition file <code>.clang-format</code> is located in the project root directory. For CMake changes, running <code>cmake-format-do.sh</code> is required as well.</p> <p>Make sure you set up your editor to use tabs. Use tabs for indentation, and spaces for alignment 1. That way, you can use any tab size you want in your favorite editor, but the code will still look good for people with different settings.</p>","title":"Formatting"},{"location":"core-development/code-standards/#general-guidelines","text":"<ul> <li>Use <code>auto</code> type inference for local variables if it's clear from the context what the type will be. Use your best judgement, sometimes adding explicit types can increase readability 2</li> <li>Handle exceptions, including IO exceptions for file and network operations.</li> <li>Be liberal with <code>debug_assert</code>. Use asserts to check invariants, not potential runtime errors, which should be handled gracefully. <code>debug_assert</code> has an advantage over normal <code>assert</code> as it will always print out the stacktrace of the current thread when it hits. Debug asserts are for detecting bugs, not error handling. There is also <code>release_assert</code> which is similar to <code>debug_assert</code> but also hits in a release build. When there is unexpected behaviour and no suitable way to recover it can be used to halt program execution.</li> <li>Be liberal with <code>logger.always_log</code> or <code>logger.try_log</code> statements, except in performance critical paths.</li> <li>Add comments to explain complex and subtle situations, but avoid comments that reiterates what the code already says.</li> <li>Use RAII and C++11 smart pointers to manage memory and other resources.</li> </ul>","title":"General guidelines"},{"location":"core-development/code-standards/#performance-and-scalabiliy-considerations","text":"<ul> <li>When making changes, think about performance and scalability. Pick good data structures and think about algorithmic complexity. <ul> <li>Nested loops yield quadratic behavior - is there an alternative? A typical example is removing an inner lookup loop with an unordered set/map to improve lookup performance to O(1).</li> </ul> </li> <li>Make sure your change doesn't conflict with the scalability characteristics described in the white paper.</li> </ul>","title":"Performance and scalabiliy considerations"},{"location":"core-development/code-standards/#security","text":"<p>Your code will be reviewed with security in mind, but please do your part before creating a pull request:</p> <ul> <li> <p>Familiarize yourself with best practices for writing secure C++ code. In particular:</p> <ul> <li>Consult https://wiki.sei.cmu.edu/confluence/display/cplusplus</li> <li>Avoid using ANSI C functions. Many of these are prone to buffer overruns.</li> <li>Avoid using C strings and direct buffer manipulation.</li> </ul> </li> <li> <p>Use static and dynamic analysis tools, such as valgrind, XCode instrumentation, linters and sanitizers. These tools are also great for debugging crashes and performance problems.</p> </li> </ul>   <ol> <li> <p>https://dmitryfrank.com/articles/indent_with_tabs_align_with_spaces \u21a9</p> </li> <li> <p>http://www.acodersjourney.com/2016/02/c-11-auto/ \u21a9</p> </li> </ol>","title":"Security"},{"location":"core-development/collaboration-process/","text":"","title":"Collaboration Process"},{"location":"core-development/collaboration-process/#code-process","text":"<p>Fork and do all your work on a branch</p> <p>Nano prefers the standard GitHub workflow. You create a fork of the nanocurrency/nano-node repository (or other repositories as needed), make changes on new branches for features/fixes, and push these up to be added as Pull Requests. </p> <p>Create pull requests</p> <p>Before:</p> <ul> <li>Branch out of the develop branch. The master branch is only updated on new releases.</li> <li>Review your code locally. Have you followed the Code Standards closely?</li> <li>Run tests: <code>core_test</code>,<code>qt_test</code>,<code>rpc_test</code> (see running tests for more details). Did you consider adding a test case for your feature?</li> <li>Run ASAN, TSAN and Valgrind to detect memory, threading or other bugs</li> <li>Run clang formatting script and resolve any raised issues: <code>ci/clang-format-do.sh</code></li> <li>Commit and push your fork branch</li> </ul> <p>After:</p> <ul> <li>Create pull request on the upstream repository:<ul> <li>Make sure you add a description that clearly describes the purpose of the PR.</li> <li>If the PR solves one or more issues, please reference these in the description.</li> </ul> </li> <li>Check that CI completes successfully - this can take up to a few hours depending on current CI queues. If any failures exist, fix the problem and push an update.</li> <li>Respond to comments and reviews in a timely fashion.</li> </ul> <p>Resolve conflicts</p> <p>If time passes between your pull request (PR) submission and the team accepting it, merge conflicts may occur due to activity on develop, such as merging other PR's before yours. In order for your PR to be accepted, you must resolve these conflicts.</p> <p>The preferred process is to rebase your changes, resolve any conflicts, and push your changes again. 12</p> <ul> <li>Check out your branch</li> <li><code>git fetch upstream</code></li> <li><code>git rebase upstream/develop</code></li> <li>Resolve conflicts in your favorite editor</li> <li><code>git add {filename}</code></li> <li><code>git rebase --continue</code></li> <li>Commit and push your branch</li> </ul> <p>Consider squashing or amending commits</p> <p>In the review process, you're likely to get feedback. You'll commit and push more changes, get more feedback, etc. </p> <p>This can lead to a messy git history, and can make stuff like bisecting harder.</p> <p>Once your PR is OK'ed, please squash the commits into a one.3</p> <p>Note that you can also update the last commit with <code>git commit --amend</code>. Say your last commit had a typo. Instead of committing and having to squash it later, simply commit with amend and push the branch.</p>","title":"Code Process"},{"location":"core-development/collaboration-process/#finding-issues-or-features-to-work-on","text":"<ul> <li>Issues are available on GitHub, with the most urgent being in the latest milestone for release</li> <li>Start with issues labeled as <code>good first issue</code> or connect with the NF core developers on Discord or the forum for ideas on how to help</li> <li>If you find an issue you'd like to help with, comment and tag a Nano Foundation team member who can evaluate and assign it to you</li> </ul>","title":"Finding issues or features to work on"},{"location":"core-development/collaboration-process/#submitting-issues-and-feature-requests","text":"<p>Standard GitHub templates exist for submitting any found issues or feature requests. If you plan on working on a bug or feature that doesn't already have a GitHub Issue associated with it, please submit it first so the team is aware. See https://github.com/nanocurrency/nano-node/issues/new/choose for templates.</p>","title":"Submitting issues and feature requests"},{"location":"core-development/collaboration-process/#discussion-channels","text":"<p>Various channels exist for discussing code changes with the Nano Foundation and community.</p> <p>GitHub</p> <p>To help persist useful information about a particular issue or feature, it is best to discuss within the related GitHub Issue or Pull Request. Members of the nano community and Nano Foundation actively follow and will engage when available.</p> <p>Discord for chat</p> <p>For live chat, join the server at https://chat.nano.org and check out the <code>#protocol</code> and <code>#development</code> channels. The various channels under the <code>TESTING</code> section can also be helpful to follow.</p> <p>Forum</p> <p>Another area for technical and code related discussions is the forum. There are categories for <code>Protocol Design</code> and <code>Development</code> that are useful in discussing ideas. This can be a great place for getting feedback on ideas and exploring further before finalizing fixes and features in GitHub.</p>","title":"Discussion channels"},{"location":"core-development/collaboration-process/#proposals","text":"<p>There currently is no formal process for proposals on the nano network. This is an area actively being investigated and if requirements for submissions change, this area will be updated. For now, if you wish to propose an new idea, it is recommended to discuss on the forum first to gather feedback and use the GitHub Issues on the concept is solidifed/validated.</p>   <ol> <li> <p>https://help.github.com/articles/resolving-merge-conflicts-after-a-git-rebase/ \u21a9</p> </li> <li> <p>https://help.github.com/articles/resolving-a-merge-conflict-using-the-command-line/ \u21a9</p> </li> <li> <p>https://github.com/todotxt/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit \u21a9</p> </li> </ol>","title":"Proposals"},{"location":"core-development/overview/","text":"<p>Welcome and thanks for your interest in core development of the nano! The following resources contain information and guides for getting involved with the development of the node and protocol.</p>","title":"Core Development"},{"location":"core-development/overview/#getting-started","text":"<p>It is recommended to have an understanding of how the nano protocol is designed to work so the code can be more easily read and evaluated.</p> <ul> <li>Start by reviewing the living whitepaper</li> <li>Read through (or try out) the running a node guides</li> <li>Understand the basics and maybe even some advanced details about integrations</li> <li>Learn how to build the node yourself</li> <li>Participate in the community through Discord and the Forum</li> <li>Start perusing the code in the repositories below and don't be afraid to ask questions</li> </ul>","title":"Getting started"},{"location":"core-development/overview/#code-repositories","text":"<p>The Nano Foundation manages the <code>nanocurrency</code> GitHub Organization account which includes various repositories for nano tools and implementations. Below is a partial list of the most common repositories referenced.</p>    Name Language Purpose     nanocurrency/nano-node C++ Primary node implementation used on the nano network   nanocurrency/nano-work-server Rust Standalone server for generating work values for blocks   nanocurrency/protocol Kaitai Struct Specification for nano network message protocol   nanocurrency/nanodb-specification Kaitai Struct Specification for database tables and fields used by the <code>nano-node</code> implementation   nanocurrency/nano-docs Markdown MKDocs based documentation this docs.nano.org site is built from    <p>Most of the content in the following documentation is focused around the nanocurrency/nano-node repository, as that is where most development activity occurs. But there are tons of related projects creating useful tools, libraries, services and more for the nano ecosystem (see some options in GitHub).</p>","title":"Code repositories"},{"location":"core-development/overview/#security-vulnerability-reporting","text":"<p>Submit vulnerabilities privately</p> <p>Do NOT discuss potential security vulnerabilities on the issue tracker, public forums or open discussion channels. Submit sensitive issues privately to the Nano Foundation for review.</p>  <p>If you discover a bug you believe to pose a security risk to the Nano network, please contact security@nano.org with a proof of concept with full details of the bug including:</p> <ul> <li>Repository of the bug</li> <li>High-level summary</li> <li>Detailed description</li> <li>Steps to reproduce</li> <li>Supporting material/references</li> <li>The potential security impact of the bug</li> </ul> <p>It is strongly recommended to encrypt the email using GPG and the pubkeys for this purpose can be found on the SECURITY file in the node repository. The Nano Foundation will work to determine potential impacts and coordinate resolution in a node release.</p>","title":"Security vulnerability reporting"},{"location":"core-development/overview/#nano-foundation-core-developers","text":"<p>In addition to contributions from the wider nano community, the Nano Foundation manages a team of core developers who contribute to the protocol and primary node implementation. For a list of code contributors, see the GitHub Insights page.</p>","title":"Nano Foundation core developers"},{"location":"core-development/understanding-the-code/","text":"<p>This guide is designed to give an overall structure of the core nano protocol codebase to help new developers get a better understanding of the different areas and how they interoperate. Due to the rapid changing nature of the protocol it\u2019s possible some of the features are moved to different places or have changed entirely. Working on the protocol requires a very multi-disciplined and wide area of knowledge, none of it is particularly mandatory to get started but a good C++ understanding will help prevent being too overwhelmed initially:  </p> <p>Items required include:</p> <ul> <li>Windows/MacOS/Linux</li> <li>C++17 compiler</li> <li>Boost</li> <li>Git</li> <li>CMake</li> </ul> <p>Useful experience includes modern C++ knowledge (up to C++17) including multithreading primitives (mutex, condition variables, atomics) &amp; templates, Boost (asio &amp; beast), RocksDB, LMDB, FlatBuffers, JSON-RPC, IPC, networking communication (ip/tcp, message passing, broadcasting algorithms), QT, signal handling, PKI cryptography, git &amp; cross-platform development.</p> <p>The main Nano projects are located inside the <code>/nano</code> subdirectory.  </p>","title":"Understanding the code"},{"location":"core-development/understanding-the-code/#executable-binaries","text":"<p>All executables have <code>nano_</code> prefix and projects have a <code>main</code> function inside <code>entry.cpp</code></p> <p>nano_node \u2013 The standard way to start a node. There are 2 source files in here, <code>entry.cpp</code> and <code>daemon.cpp</code>. <code>nano_daemon::daemon::run()</code> is always called so is a good place to put a breakpoint if there are any issues during node operation (especially errors when launching initially).</p> <p>nano_rpc \u2013 This executable does not need to be run explicitly unless out of process RPC is selected. https://docs.nano.org/integration-guides/advanced/?h=+nano_rpc#running-nano-as-a-service Because this project is quite small it is all done inside the <code>entry.cpp</code> file and is probably an easier starting point template should anything else need to be moved out of process in the future.</p> <p>nano_wallet \u2013 This essentially does the same as <code>nano_node</code> but doesn\u2019t support all CLI commands and has a graphical user interface for the wallet.</p>","title":"Executable binaries"},{"location":"core-development/understanding-the-code/#tests","text":"<p>The googletest (gtest) framework is used to validate a variety of functionality in the node, we do not currently use gmock in the codebase.  </p>","title":"Tests"},{"location":"core-development/understanding-the-code/#running-tests","text":"<p>The dev network is forced for locally run tests, this lowers work and other settings to make it simpler to test. Build with <code>cmake -DNANO_TEST=ON ..</code> See docs.nano.org for more information. There may be intermittent failures, if so add them here https://github.com/nanocurrency/nano-node/issues/1121 and fix if possible.</p>","title":"Running tests"},{"location":"core-development/understanding-the-code/#executables","text":"<p>core_test \u2013 This is where the majority of tests should go. If there is any new functionality added or something has changed, it more often than not should have a test here! Any new core areas should have their own separate test file to encapsulate the logic.   </p> <p>ipc_flatbuffers_test \u2013 This actually doesn\u2019t use the <code>gtest</code> library and has its own main file which just contains a simple example of using flatbuffers.  </p> <p>load_test \u2013 This creates a dynamic number of nodes, sends blocks from 1 of the nodes (primary) and waits until all other nodes have the same number of blocks. This does not normally need to be modified but is run as part CI at the end.  </p> <p>rpc_test \u2013 All RPC tests go here. There is some boilerplate to follow which creates an <code>ipc_server</code> for the node which mimics out of process rpc commands communicating with it. Care must be taken when creating write transactions as they are not allowed on io-threads (https://github.com/nanocurrency/nano-node/pull/1264). To make sure this is adhered to when calling the RPC commands, there is an RAII object <code>scoped_io_thread_name_change</code> which changes the current thread (normally the main one) to be <code>io</code>, and restores it when the object goes out of scope. For instance <pre><code>...\nscoped_thread_name_io.reset ();\nnode.process (state_block);\nscoped_thread_name_io.renew ();\n</code></pre> slow_test \u2013 Any core tests which are not suitable for CI because they take a long time (&gt; a few seconds) should go here. There is a desire to make this file run once per night, but until then should be periodically run by developers.</p>","title":"Executables"},{"location":"core-development/understanding-the-code/#worksig-verification-modifying-for-tests","text":"<p>A common mistake is to request work for the hash of the block to be added, but it should happen on the root (previous one). The work difficulty is different for the live/beta/dev networks and are set using the <code>work_thresholds</code> class. During any local testing, where a lot of blocks are processed, work generation and signature verification can take the majority of the time. To speed this up it can make sense to manually lower the work difficulty even further and change the sig verification to always return <code>true</code>.</p>","title":"Work/Sig verification modifying for tests"},{"location":"core-development/understanding-the-code/#helpers","text":"<p>test_common \u2013 This is a helper library which contains test specific (not node related) things which can be used by all test projects. This project should not have a <code>node</code> dependency. Anything which does should be put into <code>nano/node/testing.cpp</code>.</p>","title":"Helpers"},{"location":"core-development/understanding-the-code/#fuzzer","text":"<p>The fuzzer uses libfuzzer which inputs arbitrary data continuously trying to find catch edge cases missed in traditional testing on specific examples. This is not currently supported on Windows. The executables are found in fuzzer_test/*. The node must be built with the CMake option <code>-DNANO_FUZZER_TEST=ON</code>, this does not require that <code>NANO_TEST</code> be set. Currently there are 3 executables built: fuzz_bignum, fuzz_buffer, fuzz_endpoint_parsing.</p> <p>Notes: There aren\u2019t currently tests for specific CLIs so it\u2019s recommended to abstract the functionality so that it can be tested in <code>core_test</code>.</p>","title":"Fuzzer"},{"location":"core-development/understanding-the-code/#testing-implementation-details","text":"<p>Sometimes it is necessary to be able to change something about a class only for a test. Rather than make this the class interface public just for tests, the specific tests can be added as friends to the class, this is done like so for a test named like so TEST (node, example); <pre><code>class my_class\n{\nprivate:\n   int private_member; // the Test (node, example); test can access this member\n   friend class node_example_Test;\n};\n</code></pre> The test itself needs to be wrapped with the nano { } namespace for this to work correctly, if the class itself is in the nano namespace which is normally the case.</p>","title":"Testing implementation details"},{"location":"core-development/understanding-the-code/#additional-pre-release-testing","text":"<ul> <li>Run tests with TSAN/ASAN/Valgrind. All errors should be fixed before launch unless these are determined to be test related or false positives. We currently have some errors with using coroutines. There are blacklist files for the sanitizers which remove some errors caused by lmdb &amp; rocksdb.</li> </ul>","title":"Additional pre-release testing"},{"location":"core-development/understanding-the-code/#bootstrapping","text":"<p>There are 2 bootstrapping methods, legacy and lazy. See https://medium.com/nanocurrency/nano-explainer-lazy-bootstrapping-6f091e1eae8c for more information.  <code>node/bootstrap/boostrap_attempt.hpp</code> contains the base class definition for bootstrap attempts.</p>","title":"Bootstrapping"},{"location":"core-development/understanding-the-code/#legacy","text":"<p><code>node/bootstrap/boostrap_legacy.cpp</code></p> <p>Legacy bootstrapping works by requesting frontiers periodically (every 5 minutes) from a random selection of peers, this is done in <code>nano::node::ongoing_bootstrap ()</code>. <code>bootstrap_frontier.cpp</code> contains the frontier req client and server. A <code>frontier_req</code> message is send from <code>frontier_req_client</code> to get a list of frontiers from a peer\u2019s <code>frontier_req_server</code> starting at <code>frontier_req.start</code> which is done as <code>accounts_begin (transaction, current + 1);</code>. The accounts are sorted by their hash.</p>","title":"Legacy"},{"location":"core-development/understanding-the-code/#lazy","text":"<p><code>node/bootstrap/boostrap_lazy.hpp</code> </p> <p>TODO</p>","title":"Lazy"},{"location":"core-development/understanding-the-code/#wallet-lazy","text":"<p>TODO</p>","title":"Wallet lazy"},{"location":"core-development/understanding-the-code/#how-messages-are-handled","text":"<p><code>node/bootstrap/bootstrap_server.cpp</code> </p> <p>When a message is received through the bootstrap server, its header is first checked inside <code>nano::bootstrap_server::receive_header_action ()</code>. The message is deserialized and added in <code>add_request ()</code> to the <code>std::queue&lt;std::unique_ptr&lt;nano::message&gt;&gt; requests</code> collection which holds a queue of messages. <code>run_next ()</code> is then called (and will be called after the request is finished if there are more messages to process), this runs the message through a <code>request_response_visitor</code> object which creates a <code>tcp_message_item</code> and adds it to the <code>tcp_message_manager</code> to be processed. The newest set of messages added were for telemetry. If new messages need adding that can be used as a guide: https://github.com/nanocurrency/nano-node/pull/2446</p>","title":"How messages are handled"},{"location":"core-development/understanding-the-code/#workers-thread-pool","text":"<p>The class definition for <code>thread_pool</code> is defined inside <code>nano/lib/threading.cpp</code>, which allows tasks to be added to a queue for execution as well as executed at a specific time. Previously there were worker/alarm classes, which were combined in https://github.com/nanocurrency/nano-node/pull/2871. Its primary purpose was to schedule write transactions off the io threads. It is generally recommended to push other tasks onto the io threads though to avoid bottlenecking these threads.</p>","title":"Workers (thread pool)"},{"location":"core-development/understanding-the-code/#database","text":"<p>There are 2 logical areas where a persistent file is needed: the ledger and wallets. For this 2 NoSQL databases which store binary data are used, namely LMDB &amp; RocksDB. The ledger database is comprised of a few files:</p> <ul> <li><code>nano/secure/blockstore.hpp</code>: interface</li> <li><code>nano/secure/blockstore_partial.hpp</code>: partial implementation of the interface, it allows CRTP for derived classes</li> <li><code>nano/node/lmdb/</code>: anything specific to LMDB goes here</li> <li><code>nano/node/rocksdb/</code>: anything specific to RocksDB goes here</li> </ul> <p>The wallets database uses the wallets_store which only has an LMDB backend.</p>","title":"Database"},{"location":"core-development/understanding-the-code/#database-upgrades","text":"<p><code>nano::mdb_store::do_upgrades ()</code> is where LMDB database upgrades are done. For instance <code>void nano::mdb_store::upgrade_v18_to_v19 ()</code> combines all block databases into a single one. Raw mdb functions are normally required as <code>blockstore::block_get ()</code> and other functions normally can\u2019t be used because they are updated to the latest db spec. There are currently no rocksdb upgrades but this will follow a similar approach when required. A corresponding test should be added, https://github.com/nanocurrency/nano-node/pull/2429/files is a simple example of adding an upgrade. There are sometimes multiple upgrades during a release if a beta build goes out and a subsequent upgrade is desired. Previously a ledger reset was done and the version was re-used but this was deemed too inconvenient.</p>","title":"Database upgrades"},{"location":"core-development/understanding-the-code/#write_database_queue","text":"<p>This was introduced to reduce LMDB write lock contention between the block processor and the confirmation height processor. As during bootstrapping or high TPS the block processor can hold onto the lock up to 5s (by default), before the lock is held by the blockprocessor it signals that it is about to get the LMDB lock, the confirmation height processor can make use of this information and continue processing where it would otherwise be stalled. Ongoing pruning also makes use of this.</p>","title":"write_database_queue"},{"location":"core-development/understanding-the-code/#block-processing","text":"<p>There are 4 types of legacy blocks: open, receive, send &amp; change. There are the state blocks which encompass traits from the legacy subtypes as well as support epochs. In various places an <code>epoch_link</code> is checked, this indicates that the link field is set to one of the epoch accounts (for v1 state blocks), or possibly self for v2 state blocks upgrade blocks. No new legacy blocks can be created (there are about 10million), but they still need to be handled in any algorithm which deals with blocks because users can still be bootstrap from scratch. When a node is first launched without a ledger <code>block_store_partial::init ()</code> is called, this creates the genesis block. Blocks are then bootstrapped.</p>","title":"Block processing"},{"location":"core-development/understanding-the-code/#ledger","text":"<p><code>nano/secure/ledger.cpp</code> is where blocks are added and deleted to the ledger database.</p> <p>The ledger cache is used when it may be expensive to try and determine the count of something in the ledger. It was originally used for the cemented count, because this is determined by adding the confirmation height from all accounts. This does mean that any external write operations from LMDB (such as CLI command <code>--confirmation_height_clear</code>) will cause this number to get out of sync. This is not possible with RocksDB backend because it does not allow multi-process write transactions.</p>","title":"Ledger"},{"location":"core-development/understanding-the-code/#node-initialization","text":"<p>The biggest bottleneck for node start-up is caused by setting up the ledger cache. This requires scanning all accounts &amp; conf height databases. A multi-threaded process (added in https://github.com/nanocurrency/nano-node/pull/2876) splits the account space into equal partitions (as accounts should be randomly distributed) and does sequential sorted reads in each partition; this is the most efficient way to search through any of the databases. Point/Random reads are very slow in comparison.</p>","title":"Node initialization"},{"location":"core-development/understanding-the-code/#keeping-build-times-low","text":"<p><code>nano/node/node.hpp</code> is the largest build bottleneck, it can increase build times of files by up to 10 seconds on some systems! Some boost files tend to be large too, they offer forward declaration headers such as <code>&lt;boost/property_tree/ptree_fwd.hpp&gt;</code> &amp; <code>&lt;boost/stacktrace/stacktrace_fwd.hpp&gt;</code> worth checking if they exist for any you are using in header files.</p>","title":"Keeping build times low"},{"location":"core-development/understanding-the-code/#node_initialized_latch","text":"<p>Some classes use <code>node_initialized_latch.wait ();</code> The latch was added in https://github.com/nanocurrency/nano-node/pull/2042 this is to prevent some of the issues in the node constructor initializer list where the <code>node</code> object is passed and a child constructor is wants to use a node member which is not yet initialized. This makes it resume operation once the latch is incremented at the beginning of the <code>node</code> constructor.</p>","title":"node_initialized_latch"},{"location":"core-development/understanding-the-code/#initial-output","text":"<p>When the node is run it prints out some information about the database used, compiler etc. An example of appending to the output is here: https://github.com/nanocurrency/nano-node/pull/2807</p>","title":"Initial output"},{"location":"core-development/understanding-the-code/#cmake","text":"<p>CMake is used as the build system, and git submodules for any third party dependencies (except boost which must be installed separately by the developer). In <code>CMakeLists.txt</code> header files (.hpp) are above source files (.cpp), no particular reason but consistency is important.</p>","title":"CMake"},{"location":"core-development/understanding-the-code/#developer-build-options","text":"<p><code>-DNANO_TIMED_LOCKS=10</code> </p> <p>Added: https://github.com/nanocurrency/nano-node/pull/2267. In <code>nano/lib/locks.hpp(.cpp)</code>, <code>std::mutex</code>, <code>std::condition_variable</code>, <code>std::unique_lock</code> &amp; <code>std::lock_guard</code> are wrapped in custom classes (with the same interface) which adds some extra timing functionality to check if a mutex was help for a time longer than <code>NANO_TIMED_LOCKS</code> in milliseconds. This is useful to see if mutex contention is a cause of any performance loss. To pinpoint a specific mutex https://github.com/nanocurrency/nano-node/pull/2765 added <code>NANO_TIMED_LOCKS_FILTER=confirmation_height_processor</code>. The full list of mutexes is available in <code>nano/lib/locks.cpp</code> - <code>mutex_identifier()</code> .</p>","title":"Developer build options"},{"location":"core-development/understanding-the-code/#apis","text":"","title":"APIs"},{"location":"core-development/understanding-the-code/#cli","text":"<p>There are 2 places that CLI commands can be added for use with <code>nano_node</code>, <code>nano/node/cli.cpp</code> &amp; <code>nano/nano_node/entry.cpp</code>. The <code>nano/node/cli.cpp</code> CLI commands are also shared with <code>nano_wallet</code> so this is the place to put shared logic which can be used by both. CLI commands prefixed with <code>debug_*</code> shouldn\u2019t really be used by end users unless they are diagnosing issues. Sometimes it can be useful to compare the RPC output with CLI, and rpc results such as <code>block_count</code> will return cached results.</p>","title":"CLI"},{"location":"core-development/understanding-the-code/#ipc","text":"<p>When using the <code>nano_rpc</code> as a separate process (either child or manually starting it), there needs to be a way of communicating between processes. IPC supports tcp and unix domain sockets, <code>nano_rpc</code> only supports tcp as it can be run on a different computer. IPC 2.0 adds flatbuffer support (https://github.com/nanocurrency/nano-node/pull/2487) which can be used for the new RPC 2.0 (TBA).</p>","title":"IPC"},{"location":"core-development/understanding-the-code/#websockets","text":"<p>Websockets were introduced in https://github.com/nanocurrency/nano-node/pull/1840. Previously a HTTP callback had to be used, but websockets provides a more efficient 2 way communication protocol. Websocket events are available for various topics. For an example of adding a websocket topic look at: https://github.com/nanocurrency/nano-node/pull/2634. <code>observers.notify (message_a.data, endpoint);</code> is what ultimately invokes the websocket server to send a message which is deserialized inside <code>nano::websocket::message_builder</code>.</p>","title":"Websockets"},{"location":"core-development/understanding-the-code/#signal-handling","text":"<p>There are 2 sets of signal handlers registered (both are only set when the <code>nano_node</code> is run as a daemon. <code>SIGSEGV</code> &amp; <code>SIGABRT</code> are set at the beginning which will create dump files if there is a segmentation fault during program execution (added in https://github.com/nanocurrency/nano-node/pull/1921/). <code>SIGINT</code> &amp; <code>SIGTERM</code> signals catch non-kill intentional closing of the executable, such as pressing ctrl+c (added in https://github.com/nanocurrency/nano-node/pull/2018). This shuts down the node allows any running write transactions to finish. Only async signal safe functions should be used in signal handlers, this limits it to very specific functions.</p>","title":"Signal handling"},{"location":"core-development/understanding-the-code/#memory-allocators","text":"<p>A lot of our heap usage is from deserializing block/votes off the wire and ledger database. To solve this we use a memory pool allocator which reuses memory in a freelist: https://github.com/nanocurrency/nano-node/pull/2047</p> <p>In <code>nano/lib/memory.hpp</code> a <code>nano::make_shared</code> function is defined which checks if the global variable <code>use_memory_pool</code> is set (initialized during node startup reading the config <code>node.use_memory_pools</code>, which defaults to true). The memory is never reclaimed, this is a performance optimization.</p>","title":"Memory allocators"},{"location":"core-development/understanding-the-code/#libraries-and-submodules","text":"","title":"Libraries and submodules"},{"location":"core-development/understanding-the-code/#boost","text":"<p>We use the Boost library where possible, such as coroutine, filesystem, endian converter, lexical_cast, multi_index_container etc.. if there is a static/dynamic Boost library which is not used, there are generally no issues in adding it. Just make sure the build scripts and documentation are updated.</p> <p>nano/boost Use <code>nano/boost/asio</code> <code>nano/boost/beast</code> for includes, this wraps up various includes and prevents warnings being shown (particularly on Windows builds).</p>","title":"Boost"},{"location":"core-development/understanding-the-code/#nanocrypto_lib","text":"<p>This is a small library which has no dependency to anything in the nano core, which is needed as it is included by the ed25519 library as well. More info here: https://github.com/nanocurrency/nano-node/pull/1870</p>","title":"<code>nano/crypto_lib/</code>"},{"location":"core-development/understanding-the-code/#testcommon","text":"<p>Any functionality which is shared between test projects and may also use gtest library. There is also <code>nano/node/testing.cpp</code> which has no gtest dependency because it is also used in CLI commands too.</p>","title":"<code>test/common/</code>"},{"location":"core-development/understanding-the-code/#nanolib-vs-nanosecure","text":"<p>The<code>nano/lib</code> library was originally intended to be used by other programs wanting some of the nano functionality, but those specific external C functions were removed and it has now become the place to put all commonly used code. As such anything which doesn\u2019t depend on the node should go here, and the <code>secure</code> library is now mostly for ledger specific things.</p>","title":"<code>nano/lib</code> vs. <code>nano/secure</code>"},{"location":"core-development/understanding-the-code/#git-submodules","text":"<p>We have a variety of submodules https://docs.nano.org/node-implementation/contributing/?h=+submodule#about-the-code-base third party dependencies are to be kept as minimal as possible in order to keep build times lean, but if there is a suitable one it can be added a submodule.</p>","title":"git submodules"},{"location":"core-development/understanding-the-code/#assertions","text":"<p><code>debug_assert</code> is essentially the same as the traditional C++ assert but also outputs a stacktrace. Added in https://github.com/nanocurrency/nano-node/pull/2568. This should be used to check programmer logic.</p> <p><code>debug_assert (!mutex.try_lock ());</code> When functions require that a mutex is required before being called we often check that the mutex is locked. Although this is technically undefined behaviour to be called by a thread which already owns the mutex we have been using this idiom for years and found no issues with the major compilers.</p> <p><code>release_assert</code> this is an assert which is triggered in both release/debug build, it also outputs a stacktrace. This was added https://github.com/nanocurrency/nano-node/pull/1114. This should be used if some invariant doesn\u2019t hold and there is no suitable way to recover from this. Such as reading something from the ledger which is meant to exist but doesn\u2019t, can indicate ledger corruption.</p>","title":"Assertions"},{"location":"core-development/understanding-the-code/#votingconsensus","text":"<p>To confirm a block a sufficient number of votes which are taken from <code>confirm_ack</code> messages are tallied up. If the tally is above the delta inside <code>nano::election::have_quorum ()</code> it returns true and the block is considered confirmed. <code>confirm_ack</code> messages can either contain the whole block or a hash (vote by hash). <code>confirm_req</code> message header as well as <code>confirm_ack</code> indicate what the type of the contents is in the header, either <code>not_a_block</code> which means dealing with block hashes or the block type. <code>nano/node/common.cpp</code> contains these messages (among others) and (de)serializing functions.</p>","title":"Voting/Consensus"},{"location":"core-development/understanding-the-code/#voting","text":"<p>The vote generator <code>nano::vote_generator::vote_generator</code> is responsible for collecting hashes that need a vote generated, combining them into a single <code>vote by hash</code> message, signing the package with the representative key and publishing the votes to the network.  A maximum of <code>nano::network::confirm_ack_hashes_max</code> hashes can be combined into a single vote <code>confirm_ack</code> message, this provides a decent tradeoff between optimizing vote signatures and reducing bandwidth.  While the process is running it waits for <code>config.vote_generator_delay</code> time in order to pack more hashes into a single vote message.  If there are more than <code>config.vote_generator_threshold</code> after waiting then it will wait for one additional <code>config.vote_generator_delay</code> before broadcasting the message.  This allows for fast vote publishing at lower rates while enabling more hashes to be combined together at higher rates.</p>","title":"voting"},{"location":"core-development/understanding-the-code/#vote_processor","text":"<p>Votes are signed by the representative and the vote processor schedules checking these votes through the <code>signature_checker</code> inside <code>nano::vote_processor::verify_votes ()</code>.  Once a vote signature has been verified, the hashes within the vote packet are passed to active_elections where they are either added to an active election or added to the inactive votes cache if an election does not exist.</p>","title":"vote_processor"},{"location":"core-development/understanding-the-code/#active_transactions","text":"<p>The active transactions class handles election management and prioritization.  When a block is processed and <code>nano::active_transactions::insert</code> called, a new election is started for the block hash if one does not already exist.  In addition to starting elections there is a 500ms <code>request_loop</code> that handles election management.  This process assists with moving elections through the different transition states as well as moving elections to a prioritized status if there is a backlog of elections.  During the requst loop the current network difficulty is updated through <code>update_active_multiplier</code> which takes the top <code>prioritized_cutoff</code> number of active elections that have not been confirmed and samples their difficulty multiplier.</p> <p>Finally, the active transactions class also handles frontiers that have not been confirmed.  Most commonly this is from bootstrapping, where the frontier of an account is added to the active elections and vote requests are sent to other nodes to confirm the frontier and thereby the rest of the account and ancestors through confirmation height processing.</p>","title":"active_transactions"},{"location":"core-development/understanding-the-code/#confirmation_solicitor","text":"<p>During the <code>request_loop</code> of the active transactions process, any election that is in the <code>active</code> state for more than 5 seconds will request votes from Principle Representative nodes that it has not seen a vote from yet.  These requests are added to the <code>confirmation_solicitor</code> which aggregates the hashes up to <code>nano::network::confirm_req_hashes_max</code> into a single <code>confirm_req</code> message and publishes it to select PR nodes that have not voted.  This helps fill any gaps in network communication failures where a vote may have been dropped which helps reach quorum on the highest priority elections.</p>","title":"confirmation_solicitor"},{"location":"core-development/understanding-the-code/#request_aggregator","text":"<p>The request aggregator is responsible for collecting vote requests <code>confirm_req</code> messages from other nodes and finding the optimal responses.  A local vote cache is used for recently generated votes, if the block hash in the request exists in the cache then a cached vote is returned, if the hash does not exist then the hash is added to the vote generator and a new vote is generated and published to the requesting node.  The request aggregator also handles publishing forks if the request is for a competing fork.  If the local node has a different winning hash it will publish a vote for the winning hash instead of the requested hash in addition to sending the requesting node the winning block as well.</p>","title":"request_aggregator"},{"location":"core-development/understanding-the-code/#election","text":"<p>An election is created when a new block is processed.  The primary purpose of the election class is to tally the vote weight and ensure consensus between any competing forks. In order to efficiently move an election through the process it can have several states.  Initially <code>passive</code> where it is waiting for votes from other nodes, then after 5 seconds if it has not been confirmed it will transition to <code>active</code> where vote requests to other nodes are made.  After <code>active_request_count_min</code> rounds of requesting votes are complete if the election is still not confirmed it moves to <code>broadcasting</code> where it will publish the block to PR nodes that have not voted in an attempt to ensure the block has been propagated throughout the network.  Under low load the <code>active</code> and <code>broadcasting</code> states are rarely used as all elections are complete within the <code>passive</code> window.</p> <p>Every vote that is added to the election triggers a check for whether quorum has been reached on the election.  Quorum requires that the winning hash has <code>node.online_reps.delta</code> more weight than any competing forks.  If quorum is reached the election is marked confirmed, transitions to the <code>confirmed</code> state and is added to the confirmation height procesor which updates the ledger.</p> <p>After an election is confirmed it can stay in the active elections container up to <code>confirmed_duration_factor</code> in order to continue to process votes and republish votes to other nodes, after which is it is removed.</p> <p>If an election lasts longer than 5 minutes and has not been confirmed it is transitioned to <code>expired_unconfirmed</code> and removed from the queue.  This most often happens during high saturation when the active elections container reaches capacity.</p>","title":"election"},{"location":"core-development/understanding-the-code/#confirmation-height-processor","text":"<p>When a block is confirmed <code>void nano::node::process_confirmed ()</code> the block is added to the confirmation height processor. This begins the process of cementing it and all of its dependents, once this occurs these blocks can never be rolled back. There are 2 confirmation height algorithms bounded and unbounded. Originally only the unbounded one existed, this would store the block hash for the original block confirmed, all its previous blocks, and recurse the bottom most receive block to the source and repeat the process. If this hit something like the binance chain or (any long chain) it could use a lot of memory (unbounded amount). So this brought about the bounded confirmation height processor algorithm which starts at the very bottom of the account chains but does the same recursion when a receive block is hit. This limits the amount of block hashes needing to be stored in memory to be able to cement the bottom most blocks. Checkpoints are used if there are a lot of accounts which need to be traversed to reach which exceeds the maximum amount of memory . It does mean in certain cases the same iteration will need to be done more than once but this should be a rare case only during initial cementing.  </p> <p>Once the uncemented count (block count \u2013 cemented count) is less than 16K the unbounded processor is used. As mentioned above this instead starts from the top (original confirmed block) and works downwards and saves all the blocks hit (not just hash) which means they don\u2019t need to be re-read during writing  later. This does use a lot more memory though which is why this is limited to a certain number of blocks, once the unbounded cutoff is exceeded the bounded processor resumes.  </p> <p>Both algorithms operate with a read transaction first which reduces write lock held time as it can do a lot of iterating. This does mean that there can be some inconsistency by the time the writing is done, but this shouldn\u2019t be an issue because once a block is confirmed by the network it will stay confirmed by <code>debug_assert</code> checks are added to catch any programming mistakes. While it is more effort to maintain 2 algorithms the unbounded one largely existed before so it made sense to re-use it, given the performance improvements in almost cemented ledgers.</p>","title":"Confirmation height processor"},{"location":"core-development/understanding-the-code/#frontiers-confirmation","text":"<p><code>nano/node/frontiers_confirmation.cpp</code> contains code which starts at the beginning of the accounts database (<code>nano::blockstore_partial::accounts_begin</code>) and iterates in ascending order and prioritises accounts based on the number of uncemented blocks (stores up to 100k) and requests confirmation for a limited number of these accounts. When the cemented count is above the hardcoded bootstrap weights this is limited to the number of optimistic elections which is 50 in this case so it is expected to be quite slow in this case. Accounts in wallets are also checked.</p>","title":"Frontiers confirmation"},{"location":"core-development/understanding-the-code/#telemetry","text":"<p>nano/node/telemetry.cpp contains the logic for telemetry processing. This sets up an ongoing telemetry request round (every 60 seconds on the live network) where a telemetry_req message is sent to every peer. There is an <code>alarm</code> timeout of about 10 seconds in which we require the response (telemetry_ack) to be received otherwise it is rejected. Any calls to get_metrics_* return a cached result. To add a new definition to the telemetry_ack message this can be used as a guide which added the <code>active_multiplier</code>: https://github.com/nanocurrency/nano-node/pull/2728 <code>telemetry_ack</code> messages are signed and are backwards compatible with older nodes (from v22 onwards). Those nodes will verify the whole message including any extra unknown data which is appended at the end is just ignored. To prevent ddosing by <code>telemetry_req</code> messages, nodes ignore messages received within that 60second (on live) boundary. This is done in <code>void nano::bootstrap_server::receive_header_action ()</code></p>","title":"Telemetry"},{"location":"core-development/understanding-the-code/#stats","text":"","title":"Stats"},{"location":"core-development/understanding-the-code/#counters","text":"<p>The <code>stats</code> object is used to keep a count of events that have happened, this is a useful idiom for checking values in tests and is aggregated in the stats-&gt;counts RPC. There are main stat types and then details for that type. A simple example of adding new details and incrementing the stats can be seen here: https://github.com/nanocurrency/nano-node/pull/2515 Adding a type for a stat is a similar procedure just using the <code>nano::stat::type</code> enumerator.</p>","title":"Counters"},{"location":"core-development/understanding-the-code/#objects","text":"<p>Most classes which have a member variable of container of multiple items (map, vector, list etc..) should have a function with a prototype of: <code>std::unique_ptr&lt;container_info_component&gt; collect_container_info (my_class &amp; my_class, std::string const &amp; name);</code> And then call this in an owning object which should itself be called recursively until it reaches the <code>node</code> object <code>collect_container_info</code>. They are typically not made as part of the class itself because it\u2019s a very specialised function which is only called as part of the stats-&gt;object RPC, like so: <code>{\"action\":\"stats\",\"type\":\"objects\"}</code></p>","title":"Objects"},{"location":"core-development/understanding-the-code/#pruning","text":"<p>Pruning occurs periodically inside <code>nano::node::ongoing_ledger_pruning ()</code>. Pruning currently requires a full ledger to be bootstrapped and when an account frontier is confirmed it can then be pruned. The hashes of the pruned blocks are put into the pruned database so that we know to ignore any of these old blocks should the node bootstrap them again. Pending blocks cannot be pruned currently.</p>","title":"Pruning"},{"location":"core-development/understanding-the-code/#config-files","text":"<p>TOML config files are used, previously we used json files but TOML config files have the benefit of providing comments inside. There are no versions or upgrades done here, instead any defaults not explicitly overridden in the toml file get updated implicitly. There are few config files:</p>","title":"Config files"},{"location":"core-development/understanding-the-code/#config-nodetoml","text":"<p>This is actually called <code>daemonconfig.cpp</code> in the code base, but it wraps a <code>node_config</code> object.</p>","title":"config-node.toml"},{"location":"core-development/understanding-the-code/#other-config-files","text":"<p><code>config-rpc.toml</code> &amp; <code>config-wallet.toml</code> contain settings which can be modified by the user to override the defaults. The most common ones are enabling rpc/websocket &amp; rocksdb.</p> <p>The <code>nano/node/node_rpc_config.cpp</code> are the rpc settings for the node.</p>","title":"Other config files"},{"location":"core-development/understanding-the-code/#key-resources","text":"<p>nanodb-specification &amp; protocol repositories</p> <p>There are 2 repositories which use kaitai specifications which should be updated (normally near the end of the release) if there are any changes to the https://github.com/nanocurrency/nanodb-specification or https://github.com/nanocurrency/protocol message</p> <p>nano-docs</p> <p>All RPC/CLI changes should have a documentation update specifying the version that they work. There is a documentation label in the nano-node repository which is useful as a reminder that they should be added, documentation updates are often overlooked.</p> <p>nano.community</p> <p>A great community built resource for developers is https://nano.community/getting-started-devs/getting-started where broad details of the design are outlined along with code-level insights.</p>","title":"Key resources"},{"location":"core-development/understanding-the-code/#other-notes","text":"<p>All threads should have a name set</p> <p>An easy example to follow is https://github.com/nanocurrency/nano-node/pull/2987/files This is so that debuggers/viewers which show threads can pick up the name to make it easier to navigate. It\u2019s been known not to work in the Visual Studio Concurrency visualizer.</p> <p>(de)serializing</p> <p>Where possible we try and store primitives in big-endian. As most systems are little-endian this means using <code>boost::endian::native_to_big</code> on primitives when serializing and <code>boost::endian::big_to_native</code> when deserializing.</p> <p>Signature checker</p> <p>This is used by both blocks/votes and creates (total threads / 2) to perform signature verification of set batches; this is the biggest compute resource. Being able to lower this would be very beneficial, such as out of process sig verification and/or via GPU.</p> <p>peers</p> <p>Peers are written to disk periodically. This was added in https://github.com/nanocurrency/nano-node/pull/1608  If the node has not been run in a long time (1 week), the peers list is cleared and the preconfigured peers list is used, this was added in https://github.com/nanocurrency/nano-node/pull/2506</p> <ul> <li>Do not use the <code>node</code> object or include <code>node.hpp</code> in new core source files unless necessary, instead include the dependencies that it requires. We are still in the process of removing this idiom from other files because it adds circular dependencies, potentially ordering bugs and increases the build time.</li> <li> <p>Take care not to have nested <code>tx_begin_write ()</code>, it is quite easy to forget about this in tests, it will just cause a deadlock. To solve it, limit the scope:</p> <ul> <li>Pass <code>std::shared_ptr</code> parameters by reference where possible, https://github.com/nanocurrency/nano-node/pull/3029</li> <li>Be cautious with random DB reads, they are much slower than sequential reads. This PR sped up the delegators by a factor of 100 RPC by removing the block_get call needed in the loop. https://github.com/nanocurrency/nano-node/pull/2283 <pre><code>{ // Limit scope\nauto transaction = store-&gt;tx_begin_write ();\nblock_put (store.tx_begin_write (), block);\n}\n\u2026\nauto transaction = store-&gt;tx_begin_write ();\n</code></pre> or if it\u2019s a single write can create a temporary just for that use: <code>block_put (store.tx_begin_write (), block);</code> Be cautious with callback lifetimes with asynchronous callbacks, such as the worker, alarm and asio. The following issue was because of them: <pre><code>int x = 4;\nworker.push_back ([&amp;x]() { \n  std::cout &lt;&lt; x; // x might not be valid by the time this is called, should have been a copy.\n});\n</code></pre></li> </ul> </li> <li> <p>Currently using C++17 with Boost 1.70, at the time of writing C++20 is still not fully implemented by any of the major standards compliant compilers. It may be considered for inclusion no earlier than 2022 at which point Linux LTS versions should support it through the default repositories.</p> </li> <li>There are known exceptions triggered when <code>consume_future</code> is called do not be alarmed when seeing this.</li> </ul>","title":"Other notes"},{"location":"core-development/understanding-the-code/#areas-of-future-improvement","text":"<ul> <li>A lot of tests still use legacy blocks, any new ones should use state blocks.</li> <li>Minimise heap allocation. This can lead to fragmentation which affects long running processes.</li> <li><code>slow_test</code> is not run as part of CI</li> </ul>","title":"Areas of future improvement"},{"location":"core-development/understanding-the-code/#faqs","text":"<ul> <li> <p>Where are blocks added to the ledger? <code>nano::ledger::process ()</code></p> </li> <li> <p>Where are rpc calls handled? <code>nano/node/json_handler.cpp</code></p> </li> <li> <p>Where is the genesis block created? <code>nano::blockstore_partial::init ()</code> </p> </li> <li> <p>How to stop the node effectively? <code>rpc-&gt;stop ();</code></p> </li> <li> <p>How to use RocksDB in tests? Set the environment variable: <code>TEST_USE_ROCKSDB=1</code></p> </li> </ul>","title":"FAQs"},{"location":"integration-guides/","text":"<p>If you're looking for details about how to integrate your application or service with Nano, you've come to the right place! There are a variety of ways to do integrations and this documentation is focused on situations requiring custom development. If you are looking for a more plug-and-play option to accept Nano payments or donations, we recommend heading to https://nano.org/accept-nano for some simpler options.</p>","title":"Integrating with Nano"},{"location":"integration-guides/#what-is-needed-to-integrate","text":"<p>The most basic integration with Nano will require:</p> <ol> <li>Access to make RPC calls to a Nano node</li> <li>A method of doing work generation for any blocks created</li> <li>Some form of a wallet to manage the private/public keys for your accounts</li> </ol> <p>But before jumping in to setup, there are a few best practices and concepts you should be familiar with first:</p>","title":"What is needed to integrate?"},{"location":"integration-guides/#how-transactions-work-and-block-specs","text":"<p>Transactions function differently in Nano compared to other blockchains due to the block lattice design. The What is Nano? page gives a quick explanation on how send and receive transactions are related in Nano. As you get into your integration, it is best to be familiar with the block specifications in order to understand how different block subtypes are built and relate to each other.</p>","title":"How transactions work and block specs"},{"location":"integration-guides/#account-key-seed-and-wallet-ids","text":"<p>Knowing how private and public keys are related to seeds and accounts is critical to building a safe and secure integration. With the internal node wallet, there is also a unique wallet ID that adds further security and must be considered if using that wallet for development/testing (see the wallets section below for details). Review the Account, Key, Seed and Wallet IDs section for some additional details.</p> <p>If you need to generate or manage seeds or mnemonic phrases, see the seeds section for some key information about options as they may differ from other existing projects and standards.</p>","title":"Account, Key, Seed and Wallet IDs"},{"location":"integration-guides/#units","text":"<p>There are two main units used: nano and raw. The ratio is: $$ 1 nano = 10^{30} raw $$</p> <p>All QR code setups and RPC calls use raw for the amounts, while any human interaction with units is done at the Nano level.</p>","title":"Units"},{"location":"integration-guides/#other-concepts","text":"<p>The above concepts capture a minimum understanding to begin your integration journey, and although additional resources will be called out further in the various guides, don't be afraid to check out other resources throughout the documentation here.</p>","title":"Other concepts"},{"location":"integration-guides/#accessing-rpc-calls","text":"<p>Most integrations send and receive funds by making RPC calls to a Nano node. This requires either access to a public API or running your own node on one of the available networks. Depending on your goals, both are valid approaches with many options and levels of engagement.</p>","title":"Accessing RPC calls"},{"location":"integration-guides/#running-your-own-node","text":"<p>Running a node involves installing, configuring and maintaining software on a server, preferably on a stable cloud service for the best performance and uptime. This approach gives you more control at the cost of additional effort.</p> <p>If going this route, we encourage use of the existing test network for initial integrations. Head over to the Running a node guide and make your way through the overview and security pages before stepping through the node setup guide. Make sure you have \"Test network\" selected in all the example commands.</p>  <p>Production integration node should be non-voting</p> <p>When moving to production with a node on the main network, we recommend running dedicated, non-voting node for your integration. If you are interested in running a representative node to help further decentralize the network consensus, please setup a separate node for this purpose to ensure both operate as effectively as possible. See the Voting as a Representative guide for further details.</p>","title":"Running your own node"},{"location":"integration-guides/#public-apis","text":"<p>Access to public APIs for the main network is also available via third-party vendors and community members. These are only available for the main network and are great for quickly testing out a proof-of-concept or prototype using small amounts. If using for production applications caution should be taken when evaluating SLAs and uptime in general.</p> <ul> <li>Community supported public APIs list available at publicnodes.somenano.com</li> <li>NOWNodes offers free and paid access to Nano node RPC calls (does not include work generation) with some service quality standards</li> </ul>","title":"Public APIs"},{"location":"integration-guides/#wallet","text":"<p>In order to manage private and public keys, accounts, seeds, etc. you will need wallet software. A few potential options are included below, with more user-focused and backend options listed at nanowallets.guide.</p>","title":"Wallet"},{"location":"integration-guides/#node-internal-wallet","text":"<p>Node wallet not for production use</p> <p>The node wallet is not supported for use in production environments. Use third-party or custom key management for production applications.</p>  <p>The official binaries, builds and Docker containers for the Nano node published by the Nano Foundation have an internal wallet available for use in development and testing. This is Qt based wallet with both a GUI and related RPC commands. The following features are available via the GUI:</p> <ul> <li>Import wallet and adhoc keys</li> <li>Export seed (automatically generated on startup)</li> <li>Change representatives</li> <li>Send and automatically receive</li> <li>Automatic work generation for transactions (via CPU by default)</li> <li>Manual options for block creation, block processing and initiation of bootstrapping</li> <li>Various advanced options for viewing the ledger, peers, blocks, accounts and statistics</li> </ul> <p>This wallet requires running the node, so after getting your node setup you can follow the wallet setup guide to get started. If building the node yourself, see the Qt wallet notes on the build options guide for how to build the <code>nano_wallet</code> binary in addition to the node.</p>","title":"Node internal wallet"},{"location":"integration-guides/#pippin","text":"<p>This community built wallet is a production-ready, high performance developer wallet that is setup to be a drop-in replacement for the internal node wallet. Built in Python and optimized for fast response times, this is a good option to explore for any integration. With an open source license, you are encouraged to contribute to its development as well.</p> <p></p>","title":"Pippin"},{"location":"integration-guides/#nault","text":"<p>This community built wallet is more end-user focused with a robust GUI full of various options. It can be useful in development and testing as it supports setting the custom backend to your own node and can function as a basic account/block explorer. If you use this wallet, it also has an open source license so contributions are encouraged.</p> <p></p>","title":"Nault"},{"location":"integration-guides/#additional-tools","text":"<p>There are plenty of additional libraries and tools worth exploring to help with your integration. Head over the the Developer Tools page on nano.org for a list of commonly used options. Other resources can be explored at the community built nanolinks.info site.</p>","title":"Additional tools"},{"location":"integration-guides/#next-steps","text":"<p>If you've made it this far you may have a node running with a wallet setup and have started playing around on the test network. The next steps from here are understanding more about how to handle the various operations most integration require, such as:</p> <ul> <li>Managing public and private keys: see Key Management, sending and receiving transactions and handling work generation.</li> <li>Creating and sending transactions:</li> <li>External wallet (such as Pippin): see External Management - Creating transactions</li> <li>Internal node wallet: see Internal Management</li> <li>Tracking block confirmations: see Block Confirmation Tracking guide</li> <li>Performing efficient work generation: see Work Generation guide</li> <li>Optional WebSocket integration: see WebSockets guide</li> </ul>","title":"Next steps"},{"location":"integration-guides/advanced/","text":"","title":"Advanced Integrations"},{"location":"integration-guides/advanced/#cold-wallets","text":"<p>When security of funds is critical, it is a best practice to split your balance between multiple wallets:</p> <ol> <li>One or more hot wallets to handle daily user deposits/withdraws.</li> <li>One or more cold wallets to securely store Nano in an offline environment.</li> </ol>  <p>Important</p> <p>A cold wallet manages private keys that have never been on a network-enabled computer.</p>  <p>This guide extends the concepts covered in External Private Key Management.  It is advised that you read that section before continuing.</p>  <p>Note</p> <p>Operations done on the hot, online, insecure computer will be prefaced with <code>(HOT)</code>. Operations done on the cold, offline, secure computer will be prefaced with <code>(COLD)</code>.</p> <p>Both the hot and cold computers need to have the nano_node software installed. The hot nano_node needs to be synced with the network; the cold nano_node by definition should not be synced as it never connects to the internet.</p>    <p>Cold Wallet Workflow</p> <p>The typical work flow for a cold wallet is as follows:</p> <ol> <li><code>(HOT)</code> Gather account and transaction data.</li> <li>Transfer this data using an offline method (e.g. via USB stick) to the <code>(COLD)</code> secure offline computer.</li> <li><code>(COLD)</code> Verify Head Block hash.</li> <li><code>(COLD)</code> Generate and Sign new transaction data.</li> <li>Transfer the signed transaction back to the <code>(HOT)</code> insecure online-computer.</li> <li><code>(HOT)</code> Publish the signed transaction to the Nano Network.</li> </ol>   sequenceDiagram   participant Network   participant HOT   participant COLD   HOT-&gt;&gt;Network: Get Data   Network-&gt;&gt;HOT: Data Response   HOT--&gt;&gt;COLD: Offline Transfer   COLD--&gt;&gt;COLD: Verify   COLD--&gt;&gt;COLD: Generate &amp; Sign   COLD--&gt;&gt;HOT: Return Signed   HOT-&gt;&gt;Network: Publish Signed   Note over COLD,HOT: Cold/Hot Wallet transfers are done &lt;br /&gt;offline using USB Stick or similar.","title":"Cold Wallets"},{"location":"integration-guides/advanced/#private-key-management","text":"<p>The process for external private key management in a cold wallet is very similar to external private key management for a hot wallet. The primary difference is that all signing commands (and thus information containing your private key) are isolated to a clean computer with no network connection.</p>","title":"Private Key Management"},{"location":"integration-guides/advanced/#hot-account-information","text":"<p>Get account information by the <code>account_info</code> RPC Command:</p>","title":"(HOT) Account Information"},{"location":"integration-guides/advanced/#request-example","text":"<pre><code>curl -d '{\n  \"action\": \"account_info\",\n  \"representative\": \"true\",\n  \"account\": \"nano_3qb1qckpady6njewfotrdrcgakrgbfh7ytqfrd9r8txsx7d91b9pu6z1ixrg\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/advanced/#success-response","text":"<pre><code>{\n  \"frontier\": \"DC8EC06D1F32F97BD69BF59E3297563BD23779F72176A4FF553CFF52309C337E\",\n  \"open_block\": \"2E1F5AD4BD2C840FD9DC3929ECE9EE6D0B4A8C870E45EDA11048DE91EC409165\",\n  \"representative_block\": \"DC8EC06D1F32F97BD69BF59E3297563BD23779F72176A4FF553CFF52309C337E\",\n  \"balance\": \"8900000000000000000000000\",\n  \"modified_timestamp\": \"1524812177\",\n  \"block_count\": \"105\",\n  \"representative\": \"nano_3rropjiqfxpmrrkooej4qtmm1pueu36f9ghinpho4esfdor8785a455d16nf\"\n}\n</code></pre>","title":"Success Response"},{"location":"integration-guides/advanced/#hot-balance-validation-part-1","text":"<p>We should always assume the <code>(HOT)</code> computer has been compromised, so cannot trust the balance returned by <code>account_info</code>. We must obtain the headblock's transaction data and independently confirm the block's hash on our <code>(COLD)</code> offline computer. On the <code>(HOT)</code> online computer, this information can be obtained by the <code>block_info</code> RPC Command.</p>","title":"(HOT) Balance Validation (Part 1)"},{"location":"integration-guides/advanced/#request-format","text":"<pre><code>curl -d '{\n  \"action\": \"block_info\",\n  \"hash\": \"{{HEADBLOCK}}\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Format"},{"location":"integration-guides/advanced/#request-example_1","text":"<pre><code>curl -d '{\n  \"action\": \"block_info\",\n  \"hash\": \"DC8EC06D1F32F97BD69BF59E3297563BD23779F72176A4FF553CFF52309C337E\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/advanced/#success-response_1","text":"<pre><code>{\n    \"block_account\": \"nano_3qb1qckpady6njewfotrdrcgakrgbfh7ytqfrd9r8txsx7d91b9pu6z1ixrg\",\n    \"amount\": \"100000000000000000000000\",\n    \"balance\": \"8900000000000000000000000\",\n    \"height\": \"105\",\n    \"local_timestamp\": \"0\",\n    \"contents\": \"{\\n\n      \\\"type\\\": \\\"state\\\",\\n\n      \\\"account\\\": \\\"nano_3qb1qckpady6njewfotrdrcgakrgbfh7ytqfrd9r8txsx7d91b9pu6z1ixrg\\\",\\n\n      \\\"previous\\\": \\\"829C33C4E1F41F24F50AB6AF8D0893F484E7078F0FA05F8F56CB69223E8EEE77\\\",\\n\n      \\\"representative\\\": \\\"nano_3rropjiqfxpmrrkooej4qtmm1pueu36f9ghinpho4esfdor8785a455d16nf\\\",\\n\n      \\\"balance\\\": \\\"8900000000000000000000000\\\",\\n\n      \\\"link\\\": \\\"616349D5A5EBA49A73324EF29044B65E13644EC182FFC1ACA4371F897EFF22AA\\\",\\n\n      \\\"link_as_account\\\": \\\"nano_1rd5b9ctdtx6mbsm6mqkk34deqimej9e51qzr8pcafrzj7zhyaockuye93sk\\\",\\n\n      \\\"signature\\\": \\\"5058A5A1D371CE367D88DB232D398B33DF15FF95D84206986848F4165FFD9FB009B99D9DC6E90D2A3D96C639C7772497C6D6FFB8A67143AE9BB07DC49EB72401\\\",\\n\n      \\\"work\\\": \\\"5621a5a58ef8964a\\\"\\n\n    }\\n\"\n}\n</code></pre>  <p>Info</p> <p>Below are a few important points to remember:</p> <ul> <li>Contents are returned as a stringified JSON object.</li> <li>The type of the block is <code>\"state\"</code>. This guide only covers on how to trustlessly process <code>\"state\"</code> blocks on an offline computer.</li> </ul>  <p>Transfer the response over to the <code>(COLD)</code> computer.</p>","title":"Success Response"},{"location":"integration-guides/advanced/#cold-balance-validation-part-2","text":"<p>On the <code>(COLD)</code> computer, we need to verify the block hash using the <code>block_hash</code> RPC Command.. This allows us to create a safe transaction referencing the reported head block's balance.</p>","title":"(COLD) Balance Validation (Part 2)"},{"location":"integration-guides/advanced/#request-format_1","text":"<pre><code>curl -d '{\n  \"action\": \"block_hash\",\n  \"block\": \"&lt;CONTENTS&gt;\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Format"},{"location":"integration-guides/advanced/#request-example_2","text":"<pre><code>curl -d '{\n  \"action\": \"block_hash\", \"block\": \"{\\n\n    \\\"type\\\": \\\"state\\\",\\n\n    \\\"account\\\": \\\"nano_3qb1qckpady6njewfotrdrcgakrgbfh7ytqfrd9r8txsx7d91b9pu6z1ixrg\\\",\\n\n    \\\"previous\\\": \\\"829C33C4E1F41F24F50AB6AF8D0893F484E7078F0FA05F8F56CB69223E8EEE77\\\",\\n\n    \\\"representative\\\": \\\"nano_3rropjiqfxpmrrkooej4qtmm1pueu36f9ghinpho4esfdor8785a455d16nf\\\",\\n\n    \\\"balance\\\": \\\"8900000000000000000000000\\\",\\n\n    \\\"link\\\": \\\"616349D5A5EBA49A73324EF29044B65E13644EC182FFC1ACA4371F897EFF22AA\\\",\\n\n    \\\"link_as_account\\\": \\\"nano_1rd5b9ctdtx6mbsm6mqkk34deqimej9e51qzr8pcafrzj7zhyaockuye93sk\\\",\\n\n    \\\"signature\\\": \\\"5058A5A1D371CE367D88DB232D398B33DF15FF95D84206986848F4165FFD9FB009B99D9DC6E90D2A3D96C639C7772497C6D6FFB8A67143AE9BB07DC49EB72401\\\",\\n\n    \\\"work\\\": \\\"5621a5a58ef8964a\\\"\\n\n  }\\n\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/advanced/#success-response_2","text":"<pre><code>{ \n  \"hash\": \"DC8EC06D1F32F97BD69BF59E3297563BD23779F72176A4FF553CFF52309C337E\"\n}\n</code></pre> <p>Using the responded hash on the <code>(COLD)</code> computer guarentees that the transaction we are about to create on the <code>(COLD)</code> computer will have a safe, expected outcome.</p>  <p>Important</p> <p>Lets consider the following scenarios where malicious software on the <code>(HOT)</code> computer modifies data:</p> <ul> <li>You are creating a send transaction.</li> <li>Malicious software alters the <code>balance</code> field of the head block to be lower than it actually is in an attempt to get you to send too much Nano to the destination address.</li> <li>This alters the block's hash, but the malicious software could report the honest headblock's hash.</li> </ul> <p>By independently computing the headblock's hash on the <code>(COLD)</code> computer, the generated transaction would be rejected by the network since the <code>previous</code> field references a non-existent block which is certainly not the headblock of your account.</p>  <p>Use the responded hash for the <code>previous</code> field in your new transaction. When computing final account balance, compute it relative to the <code>balance</code> field of the headblock on the <code>(COLD)</code> computer. Complete the rest of the block creation as described in section External Private Key Management.</p> <p>Once the block is created and signed on the <code>(COLD)</code> computer, transfer the contents over to the <code>(HOT)</code> computer. From the <code>(HOT)</code> computer, run the <code>process</code> RPC command to broadcast the signed transaction to the network.</p>","title":"Success Response"},{"location":"integration-guides/advanced/#http-callback","text":"<p>WebSockets recommended</p> <p>The node supports WebSockets and these are recommended over the HTTP callbacks whenever possible.</p>  <p>Send JSON POST requests with every confirmed block to callback server configured for the node.</p>  <p>Multiple notifications for blocks</p> <p>Depending on the node setup and sync status, multiple confirmation notifications for the same block hash may be sent by a single tracking mechanism. In order to prevent potential issues, integrations must track these block hashes externally to the node and prevent any unwanted actions based on multiple notifications.</p>  <p>Configuration</p> <p>For details on configuring the HTTP callback within a node, see the HTTP callback section of Running a Node Configuration.</p> <p>Example Callback</p> <pre><code>{  \n    \"account\": \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\",  \n    \"hash\": \"B785D56473DE6330AC9A2071F19BD44BCAF1DE5C200A826B4BBCC85E588620FB\",  \n    \"block\": \"{\\n    \n             \\\"type\\\": \\\"state\\\",\\n\n             \\\"account\\\": \\\"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\\\",\\n    \n             \\\"previous\\\": \\\"82D68AE43E3E04CBBF9ED150999A347C2ABBE74B38D6E506C18DF7B1994E06C2\\\",\\n    \n             \\\"representative\\\": \\\"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\\\",\\n    \n             \\\"balance\\\": \\\"5256159500000000000000000000000000000\\\",\\n    \n             \\\"link\\\": \\\"8B95FEB05496327471F4729F0B0919E1994F9116FD213F44C76F696B7ECD386A\\\",\\n    \n             \\\"link_as_account\\\": \\\"nano_34woztr7b7jkgjrzawnz3e6jmresbyajfzb39x4eguubffzetg5c96f3s16p\\\",\\n    \n             \\\"signature\\\": \\\"FBE5CC5491B54FE9CD8C48312A7A6D3945835FD97F4526571E9BED50E407A27ED8FB0E4AA0BF67E2831B8DB32A74E686A62BF4EC162E8FBB6E665196135C050B\\\",\\n    \n            \\\"work\\\": \\\"824ca671ce7067ac\\\"\\n    \n         }\\n\",  \n    \"amount\": \"2500000000000000000000000000000\"  \n}\n</code></pre> <p>Send state blocks have special fields \"is_send\" &amp; \"subtype\"  <pre><code>{  \n    \"account\": \"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\",  \n    \"hash\": \"82D68AE43E3E04CBBF9ED150999A347C2ABBE74B38D6E506C18DF7B1994E06C2\",  \n    \"block\": \"{\\n    \n             \\\"type\\\": \\\"state\\\",\\n\n             \\\"account\\\": \\\"nano_1ipx847tk8o46pwxt5qjdbncjqcbwcc1rrmqnkztrfjy5k7z4imsrata9est\\\",\\n    \n             \\\"previous\\\": \\\"BE716FE4E21E0DC923ED67543601090A17547474CBA6D6F4B3FD6C113775860F\\\",\\n    \n             \\\"representative\\\": \\\"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\\\",\\n    \n             \\\"balance\\\": \\\"5256157000000000000000000000000000000\\\",\\n    \n             \\\"link\\\": \\\"5D1AA8A45F8736519D707FCB375976A7F9AF795091021D7E9C7548D6F45DD8D5\\\",\\n    \n             \\\"link_as_account\\\": \\\"nano_1qato4k7z3spc8gq1zyd8xeqfbzsoxwo36a45ozbrxcatut7up8ohyardu1z\\\",\\n    \n             \\\"signature\\\": \\\"5AF10D3DDD0E3D7A0EF18670560D194C35A519943150650BBBE0CBDB2A47A1E41817DA69112F996A9898E11F1D79EF51C041BD57C1686B81E7F9DFCCFFBAB000\\\",\\n    \n            \\\"work\\\": \\\"13ae0ea3e2af9004\\\"\\n    \n         }\\n\",  \n    \"amount\": \"90000000000000000000000000000000000\",   \n    \"is_send\": \"true\",  \n    \"subtype\": \"send\"  \n}\n</code></pre></p>  <p>Warning</p> <p>It is recommended to fetch the block using the hash provided in the callback rather than trust this data is valid, and check that data instead, since a malicious 3rd party can also make a fake callback request to your endpoint.</p>","title":"HTTP callback"},{"location":"integration-guides/advanced/#running-nano-as-a-service","text":"<p>There are 3 different ways to enable RPC for the node:</p> <p>In process</p> <ul> <li><code>rpc.enable</code> = true</li> <li><code>rpc.child_process.enable</code> = false (default, V19.0+)</li> </ul> <p>Child process V19.0+ only</p> <ul> <li><code>rpc.enable</code> = true</li> <li><code>rpc.child_process.enable</code> = true</li> <li><code>rpc.child_process.rpc_path</code> = [path to nano_rpc]</li> <li><code>ipc.tcp.enable</code> = true</li> <li><code>ipc.tcp.port</code> = <code>process.ipc_port</code> of <code>config-rpc.toml</code></li> </ul> <p>Out of node process V19.0+ only</p> <ul> <li><code>rpc.enable</code> = false</li> <li><code>rpc.child_process.enable</code> = false</li> <li><code>node.ipc.tcp.enable</code> = true</li> <li><code>node.ipc.tcp.port</code> == <code>process.ipc_port</code> of <code>config-rpc.toml</code></li> </ul> <p>The choice depends on the setup and security that you want. The easiest way is to use RPC in_process according to configuration</p> <p>Launch nano_node in test mode </p> <pre><code>./nano_node --daemon --network=test\n</code></pre> <p>Check if RPC is enabled with curl (use different terminal or session) </p> <pre><code>curl -d '{\n  \"action\": \"block_count\"\n}' http://127.0.0.1:7076\n</code></pre>  <p>Tip</p> <p>On some systems it may be necessary to replace <code>127.0.0.1</code> with IPv6 equivalent of <code>[::1]</code> when mapping Docker ports</p>  <p>To stop node, use </p> <pre><code>curl -d '{\n  \"action\": \"stop\"\n}' http://127.0.0.1:7076\n</code></pre> <p>Launch nano_node as a service with systemd </p> <pre><code>sudo touch /etc/systemd/system/nano_node.service   \nsudo chmod 664 /etc/systemd/system/nano_node.service   \nsudo nano /etc/systemd/system/nano_node.service\n</code></pre> <p>Paste your specific user, group, path settings (example) </p> <pre><code>[Unit]\nDescription=Nano node service\nAfter=network.target\n\n[Service]\nExecStart=/path_to_nano_node/nano_node --daemon\nRestart=on-failure\nUser=username\nGroup=groupname\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Start nano_node service</p> <pre><code>sudo service nano_node start\n</code></pre> <p>Enable at startup </p> <pre><code>sudo systemctl enable nano_node\n</code></pre>  <p>Tip</p> <p>To manage node, use RPC commands or CLI</p>","title":"Running Nano as a service"},{"location":"integration-guides/advanced/#known-issues","text":"<p>Error initiating bootstrap ... Too many open files</p> <p>This issue has been seen on some versions of macOS and Linux. The node will detect when the file descriptor limit is considered too low and log a warning similar to:</p> <pre><code>WARNING: The file descriptor limit on this system may be too low (512) \nand should be increased to at least 16384.\n</code></pre> <p>To resolve this on Linux increase max open files limit by editing <code>/etc/security/limits.conf</code> and adding or updating:   <pre><code>    *               soft    nofile          65535    \n    *               hard    nofile          65535    \n    root            soft    nofile          65535    \n    root            hard    nofile          65535    \n</code></pre> Then restart session &amp; <code>nano_node</code> service. Check changes with <code>ulimit -n</code>.</p> <p>For macOS the version impacts the steps necessary, but some people had success with the recipe in https://superuser.com/a/1171028.</p> <p>Increasing max open file descriptors on a Droplet w/Ubuntu</p> <p>Add <code>session required pam_limits.so</code> to these two files:</p> <pre><code>/etc/pam.d/common-session\n/etc/pam.d/common-session-noninteractive\n</code></pre> <p>Next, edit <code>/etc/security/limits.conf</code></p> <p>... and add the following lines:</p> <pre><code>* soft nofile 20000\n* hard nofile 30000\nroot hard nofile 16384\nroot soft nofile 16384\n</code></pre> <p>The last two lines can be skipped if you're not running the node as root.</p> <p>Log out and back in or reboot and see if <code>ulimit -n</code> picked it up</p> <p>On some systems, you may need to change systemd files, etc.</p> <p>Docker</p> <p>Once the host is updated, pass <code>--ulimit nofile=16384:16384</code></p>","title":"Known issues"},{"location":"integration-guides/block-confirmation-tracking/","text":"<p>Guide based on node V19.0</p> <p>The recommendations below are based on node V19.0 and node versions earlier may not have all these options available. All integrations should upgrade their nodes to make use of easier block confirmation procedures detailed here.</p>  <p>A primary function of any integration is to track confirmation of blocks on the network and the node provides both proactive notifications and options to request confirmation status on individual blocks. This combination allows building of robust systems for monitoring the status of any blocks of interest. </p>  <p>Notifications and fallback requests both recommended</p> <p>Due to notification methods not guaranteeing delivery of every block confirmed, it is recommended that manual requests for confirmation status be implemented as a fallback option. Both these types of methods are outlined below.</p>","title":"Block Confirmation Tracking"},{"location":"integration-guides/block-confirmation-tracking/#receiving-notifications-of-confirmation","text":"<p>The recommended method for receiving notifications is via WebSockets through the confirmation <code>topic</code>. This method involves sending a subscribe command to start receiving notifications every time a block is confirmed by the network. It is recommended that the <code>confirmation_type</code> filtering options are not used for this purpose, to make it less likely to miss a notification.</p> <p>Setup process</p> <ol> <li>Update your WebSocket configuration</li> <li>Connect to the WebSocket at the configured endpoint</li> <li>Send a subscription request for all confirmations including the ack option and validate the subscription request was successful</li> <li>Listen for block confirmation notifications from the WebSocket</li> </ol> <p>As confirmations are received they can be parsed and handled as necessary. All operations handling notifications from the node on block confirmation should be idempotent as multiple notifications for the same block hash can occur.</p>  <p>Multiple notifications for blocks</p> <p>Depending on the node setup and sync status, multiple confirmation notifications for the same block hash may be sent by a single tracking mechanism. In order to prevent potential issues, integrations must track these block hashes externally to the node and prevent any unwanted actions based on multiple notifications.</p>","title":"Receiving notifications of confirmation"},{"location":"integration-guides/block-confirmation-tracking/#requesting-block-confirmation-status","text":"<p>In the event confirmation notifications are not received from the WebSocket in an expected timeframe, the block_info RPC can be called on a specific block hash. The <code>confirmed</code> field will indicate whether the block has been confirmed. Typical confirmation times on the main network during low-traffic periods are within a few seconds, so a delay of 5 seconds before requesting block information is recommended.</p> <p>If confirmation has still not been seen on the block, the block_confirm RPC can be called. This will cause the following:</p> <ul> <li>If the block is confirmed, it will trigger a notification through the WebSocket and HTTP Callbacks, and the block hash will also appear in the confirmation_history RPC (recommended for debug purposes only).</li> <li>If the block is not in active elections, it will start an election which should result in confirmation and related notifications.</li> <li>If the block is already in active elections, it will not have an effect and confirmation should eventually occur along with related notifications.</li> </ul> <p>Once block_confirm is called, a notification of confirmation through the WebSocket should be expected and if not received, then calling block_info RPC to check for confirmation again can be done. Escalation of potential delays in confirmation can be done after this point in external systems as necessary.</p>","title":"Requesting block confirmation status"},{"location":"integration-guides/block-confirmation-tracking/#account-frontier-confirmation-status","text":"<p>For some systems the starting point for checking block status may be the account, such as when a user views their account. The following process is recommended when the account is known and the confirmation status of the frontier block is desired.</p> <ol> <li>Call account_info RPC to get current frontier hash</li> <li>Call block_info for the frontier hash and check if <code>confirmed</code> = <code>true</code></li> </ol> <p>If the block is not confirmed, you can follow a similar process outlined in the Requesting block confirmation status section above for requesting block confirmation and re-checking confirmation status before escalating in external systems.</p>","title":"Account frontier confirmation status"},{"location":"integration-guides/build-options/","text":"<p>Only Official Builds Supported</p> <ul> <li>The fastest and most recommended method of installation is through Docker management</li> <li>Only official release builds are recommended and supported for use on the main network</li> <li>Builds created from git should be done using the available release tags (<code>V21.2</code> etc.)</li> </ul>","title":"Build Options"},{"location":"integration-guides/build-options/#official-release-builds","text":"<p>Throughout the development cycle and after releases official builds of the node for Docker, Linux, macOS and Windows are generated and published for test, beta and main networks.</p> Main networkTest networkBeta network      OS Download link/command Verification     Universal Linux https://repo.nano.org/live/binaries/nano-node-V23.0-Linux.tar.bz2 SHA256 Checksum   Debian https://repo.nano.org/live/binaries/nano-node-V23.0-Linux.deb SHA256 Checksum   macOS https://repo.nano.org/live/binaries/nano-node-V23.0-Darwin.dmg SHA256 Checksum   Windows (exe) https://repo.nano.org/live/binaries/nano-node-V23.0-win64.exe SHA256 Checksum   Windows (zip) https://repo.nano.org/live/binaries/nano-node-V23.0-win64.zip SHA256 Checksum   Docker <code>docker pull nanocurrency/nano:V23.0</code>See Pulling the Docker Image for more details.    RHEL/CentOS rpm <code>sudo rpm -iUvh https://repo.nano.org/live/binaries/nanocurrency-23.0-26.el7.x86_64.rpm</code>This installs <code>nano_node</code> and <code>nano_rpc</code> to <code>/usr/bin</code>. SHA256 Checksum         OS Download link/command     Universal Linux https://repo.nano.org/test/binaries/nano-node-V23.0-Linux.tar.bz2   Debian https://repo.nano.org/test/binaries/nano-node-V23.0-Linux.deb   macOS https://repo.nano.org/test/binaries/nano-node-V23.0-Darwin.dmg   Windows (exe) https://repo.nano.org/test/binaries/nano-node-V23.0-win64.exe   Windows (zip) https://repo.nano.org/test/binaries/nano-node-V23.0-win64.zip   Docker <code>docker pull nanocurrency/nano-test:V23.0</code>   RHEL/CentOS rpm Not available for the test network      <p>Join the nano Discord server and head to the <code>#beta-announcements</code> channel for the latest build details.</p>","title":"Official release builds"},{"location":"integration-guides/build-options/#nano-directory","text":"","title":"Nano Directory"},{"location":"integration-guides/build-options/#contents","text":"<p>The Nano directory contains:</p> <ul> <li>Node wallet files (<code>wallets.ldb</code>, <code>wallets.ldb-lock</code>)</li> <li>Configuration files</li> <li>Log files</li> <li>Ledger files (<code>data.ldb</code> and <code>data.ldb-lock</code> for default LMDB, or <code>rocksdb</code> directory with files for optional RocksDB backend)</li> <li>Directory for wallet backups (<code>backup</code>)</li> </ul>  <p>Protect wallet and backup files</p> <p>The built-in node wallet is for use in development and testing only. Those using it should take care in protecting access to the <code>wallets.ldb</code> file and backup files, whether encrypted or not, for added security.</p>","title":"Contents"},{"location":"integration-guides/build-options/#locations","text":"Main networkTest networkBeta network      OS/Build Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\Nano\\</code>   macOS <code>/Users/&lt;user&gt;/Library/Nano/</code>   Linux <code>/home/&lt;user&gt;/Nano/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/Nano</code>         OS Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\NanoTest\\</code>   macOS <code>/Users/&lt;user&gt;/Library/NanoTest/</code>   Linux <code>/home/&lt;user&gt;/NanoTest/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/NanoTest</code>         OS Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\NanoBeta\\</code>   macOS <code>/Users/&lt;user&gt;/Library/NanoBeta/</code>   Linux <code>/home/&lt;user&gt;/NanoBeta/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/NanoBeta</code>        Moving directory locations <p>Some users desire to change the blockchain download location. A solution is available for the no gui nano_node (see https://github.com/nanocurrency/nano-node/issues/79), but no concrete solution is available for the GUI client. However, a workaround can be acheived via the use of symbolic links. Below is a short tutorial for Windows builds:</p> <ol> <li>Rename/delete the Nano directory in your <code>appdata</code> Local directory (if you haven't run the wallet yet, skip this step). This is necessary because the command to create a symbolic link in windows will fail if the the input directory already exists.</li> <li>Decide on where you want to store the blockchain and create a symbolic link. The command is (in an administrative command-prompt): <code>mklink /d \"C:\\Users\\&lt;user&gt;\\AppData\\Local\\Nano\\\" \"E:\\Some\\Other\\Directory\"</code>. This command creates a symbolic link for a directory (<code>/d</code>) that 'redirects' all requests for files/directories in the <code>Local\\Nano</code> directory to the <code>Other\\Directory</code>. This means that a file created in the input directory will actually be in the output directory (on the other disk).</li> <li>Verify it works. Create a file in your Nano directory in your appdata, and you should see it appear in the directory you linked it to (and vice-versa). If you have old wallets or a partially-downloaded blockchain, copy them back into the local directory. Start the wallet.</li> </ol>","title":"Locations"},{"location":"integration-guides/build-options/#requirements-setup","text":"<p>Unsupported configuration</p> <ul> <li>This documentation is intended only for developers of the Nano Node software, and will not result in a supported configuration.  End-users are advised to use releases.</li> <li>The fastest and most recommended method of installation is through Docker.</li> <li>Running node as a service.</li> <li>To manage a node, use RPC commands or the CLI.</li> </ul>","title":"Requirements &amp; setup"},{"location":"integration-guides/build-options/#boost","text":"<p>The node build commands further down include bootstrapping Boost, but pre-built binaries can be used for Windows as well, or you can optionally build from the downloaded source instead as follows:</p> <ul> <li>Download Boost 1.70+</li> <li>Extract to [boost.src]</li> <li>From inside [boost.src] run:</li> </ul> *nixmacOSWindows   <pre><code>./bootstrap.sh --with-libraries=context,coroutine,filesystem,log,program_options,system,thread\n./b2 --prefix=[boost] --build-dir=[boost.build] link=static install\n</code></pre>   <pre><code>./bootstrap.sh --with-libraries=context,coroutine,filesystem,log,program_options,system,thread\n./b2 --prefix=[boost] --build-dir=[boost.build] link=static install\n</code></pre>   <pre><code>./bootstrap.sh --with-libraries=context,coroutine,filesystem,log,program_options,system,thread\n./b2 --prefix=[boost] --build-dir=[boost.build] address-model=64 link=static install\n</code></pre>    <p>If using this option, remove <code>bash util/build_prep/bootstrap_boost.sh -m</code> from the build command below.</p>","title":"Boost"},{"location":"integration-guides/build-options/#qt-wallet","text":"<p>If building the Qt-based <code>nano_wallet</code>, first download Qt 5.9.5+ open source edition and extract to [qt.src]. In [qt.build] execute:</p> *nixmacOSWindows   <pre><code>[qt.src]/configure -shared -opensource -nomake examples -nomake tests -confirm-license  -prefix [qt]\nmake\nmake install\n</code></pre>   <pre><code>[qt.src]/configure -shared -opensource -nomake examples -nomake tests -confirm-license  -prefix [qt]\nmake\nmake install\n</code></pre>   <pre><code>[qt.src]/configure -shared -opensource -nomake examples -nomake tests -confirm-license  -prefix [qt]\nnmake\nnmake install\n</code></pre>","title":"Qt wallet"},{"location":"integration-guides/build-options/#node","text":"*nixmacOSWindows   <p>Required build tools</p> <ul> <li>CMake &gt;= 3.8</li> <li>Clang &gt;= 5 or GCC &gt;= 7</li> </ul> DebianUbuntuCentOSArch Linux   <p>Version</p> <ul> <li>Debian 8 Jessie (Debian 8 requires Cmake 3.8+)</li> <li>Debian 9 Stretch</li> </ul> <p>Install dependencies</p> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get upgrade\nsudo apt-get install git cmake g++ curl wget\n</code></pre>   <p>Version</p> <ul> <li>Ubuntu 18.04 LTS Server</li> <li>Ubuntu 18.10+</li> </ul> <p>Install dependencies</p> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get upgrade\nsudo apt-get install git cmake g++ curl wget\n</code></pre>   <p>Version</p> <ul> <li>CentOS 7</li> </ul> <p>Install dependencies</p> <pre><code>sudo yum check-update\nsudo yum install git libstdc++-static curl wget\n</code></pre> <p>Configure repository with modern GCC <pre><code>sudo yum install centos-release-scl\nsudo yum install devtoolset-7-gcc*\nscl enable devtoolset-7 bash\n</code></pre></p> <p>Modern Cmake <pre><code>wget https://cmake.org/files/v3.12/cmake-3.12.1.tar.gz\ntar zxvf cmake-3.12.1.tar.gz &amp;&amp; cd cmake-3.12.1\n./bootstrap --prefix=/usr/local\nmake -j$(nproc)\nsudo make install\ncd ..\n</code></pre></p>   <p>Install dependencies</p> <pre><code>pacman -Syu\npacman -S base-devel git gcc cmake curl wget\n</code></pre>      <p>Required build tools</p> <ul> <li>CMake &gt;= 3.8</li> <li>XCode &gt;= 9</li> </ul>   <p>Required build tools</p> <ul> <li>CMake &gt;= 3.8</li> <li>NSIS package builder</li> <li>Visual Studio 2017 Community (or higher edition, if you have a valid license. eg. Professional or Enterprise)<ul> <li>Select Desktop development with C++</li> <li>Select the latest Windows 10 SDK</li> </ul> </li> </ul>","title":"Node"},{"location":"integration-guides/build-options/#build-commands","text":"","title":"Build commands"},{"location":"integration-guides/build-options/#node_1","text":"<p>The process below will create a release build of the node for the main network. See network options below for details on building for the test or beta networks.</p> *nixmacOSWindows   <pre><code>git clone --branch V22.1 --recursive https://github.com/nanocurrency/nano-node.git nano_build\ncd nano_build\nexport BOOST_ROOT=`pwd`/../boost_build\nbash util/build_prep/bootstrap_boost.sh -m\ncmake -G \"Unix Makefiles\" .\nmake nano_node\ncp nano_node ../nano_node &amp;&amp; cd .. &amp;&amp; ./nano_node --diagnostics\n</code></pre>   <pre><code>git clone --branch V22.1 --recursive https://github.com/nanocurrency/nano-node.git nano_build\ncd nano_build\nexport BOOST_ROOT=`pwd`/../boost_build\nbash util/build_prep/bootstrap_boost.sh -m\ncmake -G \"Unix Makefiles\" .\nmake nano_node\ncp nano_node ../nano_node &amp;&amp; cd .. &amp;&amp; ./nano_node --diagnostics\n</code></pre>   <p>Setup</p> <p>Download Source</p> <p>Using git_bash: <pre><code>git clone --branch V22.1 --recursive https://github.com/nanocurrency/nano-node\ncd nano-node\n</code></pre></p> <p>Create a <code>build</code> directory inside nano-node (makes for easier cleaning of build)</p> <p>Using git_bash: <pre><code>mkdir build\ncd build\n</code></pre> * Note: all subsequent commands should be run within this \"build\" directory.</p> <p>Get redistributables</p> <p>Using Powershell: <pre><code>Invoke-WebRequest -Uri https://aka.ms/vs/15/release/vc_redist.x64.exe -OutFile .\\vc_redist.x64.exe\n</code></pre></p> <p>Generate the build configuration.</p> <p>Using 64 Native Tools Command Prompt:</p> <ul> <li>Ensure the Qt, Boost, and Windows SDK paths match your installation.</li> </ul> <pre><code>cmake -DNANO_GUI=ON -DQt5_DIR=\"C:\\Qt\\5.9.5\\msvc2017_64\\lib\\cmake\\Qt5\" -DNANO_SIMD_OPTIMIZATIONS=TRUE -DBoost_COMPILER=\"-vc141\" -DBOOST_ROOT=\"C:/local/boost_1_70_0\" -DBOOST_LIBRARYDIR=\"C:/local/boost_1_70_0/lib64-msvc-14.1\" -G \"Visual Studio 15 2017 Win64\" -DIPHLPAPI_LIBRARY=\"C:/Program Files (x86)/Windows Kits/10/Lib/10.0.17763.0/um/x64/iphlpapi.lib\" -DWINSOCK2_LIBRARY=\"C:/Program Files (x86)/Windows Kits/10/Lib/10.0.17763.0/um/x64/WS2_32.lib\" ..\\.\n</code></pre> <p>Build</p> <ul> <li>Open <code>nano-node.sln</code> in Visual Studio</li> <li>Build the configuration specified in the previous step</li> <li>Alternative using 64 Native Tools Command Prompt:</li> </ul> <pre><code>cmake --build . --target ALL_BUILD --config %CONFIGURATION% -- /m:%NUMBER_OF_PROCESSORS%\n</code></pre> <p>Package up binaries</p> <p>Using 64 Native Tools Command Prompt:</p> <ul> <li>Replace %CONFIGURATION% with the build configuration specified in previous step</li> <li>Replace %GENERATOR% with NSIS (if installed) or ZIP</li> </ul> <pre><code>cpack -G %GENERATOR% -C %CONFIGURATION%\n</code></pre>","title":"Node"},{"location":"integration-guides/build-options/#qt-wallet_1","text":"<p>This is only required when the Qt wallet with GUI is needed.</p> <p><code>make nano_wallet</code></p>","title":"Qt wallet"},{"location":"integration-guides/build-options/#rpc-server","text":"<p>This is only required for when the RPC server is being run as a child process or outside the node process completely.</p> <p><code>make nano_rpc</code></p>","title":"RPC server"},{"location":"integration-guides/build-options/#additional-build-details","text":"","title":"Additional build details"},{"location":"integration-guides/build-options/#node_2","text":"","title":"Node"},{"location":"integration-guides/build-options/#cmake-variables","text":"<p>Format: <code>cmake -D VARNAME=VARVALUE</code></p> <ul> <li><code>BOOST_ROOT=\\[boost\\]</code> (<code>/usr/local/boost/</code> if bootstrapped)</li> <li><code>CMAKE_BUILD_TYPE=Release</code> (default)</li> <li><code>ACTIVE_NETWORK=nano_live_network</code> (default)</li> <li><code>Qt5_DIR=[qt]lib/cmake/Qt5</code> (to build GUI wallet)</li> <li><code>NANO_GUI=ON</code> (to build GUI wallet)</li> <li><code>ENABLE_AVX2=ON</code>, optional <code>PERMUTE_WITH_GATHER=ON</code>, optional <code>PERMUTE_WITH_SHUFFLES=ON</code> (for CPU with AXV2 support, choose fastest method for your CPU with https://github.com/sneves/blake2-avx2/)</li> <li><code>CRYPTOPP_CUSTOM=ON</code> (more conservative building of Crypto++ for wider range of systems)</li> <li><code>NANO_SIMD_OPTIMIZATIONS=OFF</code> (Enable CPU-specific SIMD optimization: SSE/AVX or NEON, e.g.)</li> <li><code>NANO_SECURE_RPC=ON</code> (to build node with TLS)</li> <li><code>NANO_WARN_TO_ERR=ON</code> (v20.0+ turn compiler warnings into errors on Linux/Mac) </li> <li><code>NANO_TIMED_LOCKS=50</code> (v20.0+ when the number of milliseconds a mutex is held is equal or greater than this output a stacktrace, 0 disables.)</li> <li><code>NANO_STACKTRACE_BACKTRACE=ON</code> (v20.0+ use a different configuration of Boost backtrace in stacktraces, attempting to display filenames, function names and line numbers. Needs <code>libbacktrace</code> to be installed. Some workarounds may be necessary depending on system and configuration. Use CLI <code>--debug_stacktrace</code> to get an example output.)</li> <li><code>CI_BUILD=TRUE</code> (v20.0+ if enabled, uses environment variable <code>TRAVIS_TAG</code> (required) to modify the locally reported node version; example <code>TRAVIS_TAG=\"My Nano Node v20\"</code>)</li> <li><code>NANO_ASIO_HANDLER_TRACKING=10</code> (Output asio diagnostics for any completion handlers which have taken longer than this in milliseconds. For more information see the description of the PR #2681)</li> <li><code>NANO_FUZZER_TEST=ON</code> (Build the fuzz tests, not available on Windows)</li> </ul>","title":"CMake variables"},{"location":"integration-guides/build-options/#building-a-package","text":"*nixmacOSWindows   <p><code>cpack -G \"TBZ2\"</code></p>   <p><code>cpack -G \"DragNDrop\"</code></p>   <p><code>cpack -G \"NSIS\"</code></p>","title":"Building a package"},{"location":"integration-guides/build-options/#network-options","text":"<p>Main network</p> <p>The default build network is the main network. No option needs to be specified.</p> <p>Test Network</p> <ul> <li>To run a node on the test network, set CMake variable: <code>-DACTIVE_NETWORK=nano_test_network</code></li> <li>More information can be found on the Test Network page</li> </ul> <p>Beta Network</p> <ul> <li>To run a node on the beta network, set CMake variable: <code>-DACTIVE_NETWORK=nano_beta_network</code></li> <li>More information can be found on the Beta Network page</li> </ul>","title":"Network options"},{"location":"integration-guides/build-options/#testing","text":"<p>A number of tests binaries can be built when the CMake variable <code>-DNANO_TEST=ON</code>. With this variable set, <code>make</code> will also build test files, and will produce <code>core_test</code>, <code>rpc_test</code>, <code>load_test</code> and <code>slow_test</code> binaries, which can be executed:</p> <ul> <li><code>core_test</code> - Tests the majority of protocol, node and network functionality.</li> <li><code>slow_test</code> - Tests which operate on a large amount of data and may take a while. Not currently tested by CI.</li> <li><code>rpc_test</code> - Tests all RPC commands</li> <li><code>load_test</code> - Launches many nodes and RPC servers, checking sending/receiving blocks with simultaneous calls. Use <code>./load_test --help</code> to see the available options</li> </ul>","title":"Testing"},{"location":"integration-guides/build-options/#running-tests","text":"<p>To run all tests in a binary just launch it: <pre><code>./core_test\n</code></pre></p> <p>To check a specific subset of tests, gtest filtering can be used (with optional wildcards): <pre><code>./core_test --gtest_filter=confirmation_height.single\n./rpc_test --gtest_filter=rpc.*\n</code></pre></p> <p>To run tests multiple times: <pre><code>./core_test --gtest_repeat=10\n</code></pre></p> <p>If running on a debugger, add the argument <code>--gtest_break_on_failure</code> break at the moment a test fails.</p>","title":"Running Tests"},{"location":"integration-guides/build-options/#environment-variables-to-customize-tests","text":"<ul> <li><code>TEST_KEEP_TMPDIRS=1</code> - Setting this to anything will prevent the tests deleting any files it creates, useful for debugging log files. </li> <li><code>TEST_USE_ROCKSDB=1</code> - Use the RocksDB ledger backend for the tests instead of LMDB. The tests must be built with RocksDB support.</li> <li><code>TEST_BASE_PORT=26000</code> - The base port used in tests, the range of ports used in this case would be 26000 - 26199. This is useful if wanting to run multiple tests at once without port conflicts, the default base port used is 24000. </li> </ul>","title":"Environment variables to customize tests"},{"location":"integration-guides/build-options/#sanitizers","text":"<p>3 different CMake sanitizer options are supported: <code>NANO_ASAN_INT</code>, <code>NANO_TSAN</code> and <code>NANO_ASAN</code>. They cannot be used in conjunction with each other.</p>","title":"Sanitizers"},{"location":"integration-guides/build-options/#thread-sanitizer","text":"<p>Use <code>-DNANO_TSAN=ON</code> as an extra CMake option. The following environment variable should also be set:</p> <p><code>export TSAN_OPTIONS=\"suppressions=../tsan_suppressions\"</code></p> <p><code>tsan_suppressions</code> should be a path to the file in the root nano directory. This suppresses many errors relating to the mdb and rocksdb libraries.</p>","title":"Thread Sanitizer"},{"location":"integration-guides/build-options/#address-sanitizer","text":"<p>Use the CMake variable <code>-DNANO_ASAN=ON</code> or <code>-DNANO_ASAN_INT=ON</code> before running an executable.</p>","title":"Address Sanitizer"},{"location":"integration-guides/build-options/#valgrind","text":"<p>Valgrind can be used to find other issues such as memory leaks. A valgrind suppressions file is provided to remove some warnings. Valgrind can be run as follows (there are many options available):</p> <pre><code>valgrind --leak-check=full --track-origins=yes --suppressions=../valgrind.supp ./core_test\n</code></pre>","title":"Valgrind"},{"location":"integration-guides/ipc-integration/","text":"<p>The node manages communications using an IPC interface with v1 introduced in V18 (see IPC v1 Details) and upgraded to v2 in V21 to include more robust options. This latest version supports the original RPC v1 endpoint and introduces RPC v2 for completion in future release, along with an authentication system for more granular control of permissioned calls.</p> <p>Configuration</p> <p>These configuration options are set in the <code>config-node.toml</code> file.</p> <p>IPC is configured in the <code>node.ipc.tcp</code> and <code>node.ipc.local</code> sections:</p> <pre><code>[node.ipc.local]\n\n# If enabled, certain unsafe RPCs can be used. Not recommended for production systems.\n# type:bool\n#allow_unsafe = false\n\n# Enable or disable IPC via local domain socket.\n# type:bool\n#enable = false\n\n# Timeout for requests.\n# type:seconds\n#io_timeout = 15\n\n# Path to the local domain socket.\n# type:string\n#path = \"/tmp/nano\"\n\n[node.ipc.tcp]\n\n# Enable or disable IPC via TCP server.\n# type:bool\n#enable = false\n\n# Timeout for requests.\n# type:seconds\n#io_timeout = 15\n\n# Server listening port.\n# type:uint16\n#port = 7077\n</code></pre>","title":"IPC Integration"},{"location":"integration-guides/ipc-integration/#ipc-requestresponse-format","text":"<p>A client must make requests using the following framing format:</p> <pre><code>REQUEST  ::= HEADER PAYLOAD\nHEADER   ::= u8('N') ENCODING u8(0) u8(0)\nENCODING ::= u8(1)\nPAYLOAD  ::= &lt;encoding specific&gt;\n</code></pre> <p>Four encodings currently exist:</p> <ul> <li>1: legacy RPC [since v18.0]</li> <li>2: legacy RPC allowing unsafe operations if node is configured so [since v19.0]</li> <li>3: flatbuffers [since v21.0]</li> <li>4: json over flatbuffers [since v21.0]</li> </ul> <p>The encoding is followed by two reserved zero-bytes. These allow for future extensions, such as versioning and extended headers.</p> <p>Note that the framing format does not include a length field - this is optionally placed in the respective payloads. The reason is that some encodings might want to be \"streamy\", sending responses in chunks, or end with a sentinel.</p> <pre><code>LEGACY_RPC_PAYLOAD  ::= be32(length) JSON request\nLEGACY_RPC_RESPONSE ::= be32(length) JSON response\n</code></pre> <p>In short, JSON requests and responses are 32-bit big-endian length-prefixed.</p>","title":"IPC request/response format"},{"location":"integration-guides/ipc-integration/#rpc-gateway","text":"<p>The RPC gateway automatically translates between Flatbuffers and JSON messages over HTTP. The request and response is standard JSON.</p>  <p>Examples require TLS support</p> <p>The examples below assumes the node is compiled with TLS support. If not, replace https with http. If using TLS with a self-signed certificate, add --insecure to curl commands.</p>","title":"RPC Gateway"},{"location":"integration-guides/ipc-integration/#making-calls-without-a-message-envelope","text":"<p>A message envelope is a way to tell the server which message type is sent, as well as other information such as credentials.</p> <p>For HTTP clients, it's convenient to send messages without an envelope. They do so by appending the message name (using uppercase CamelCase) to the path:</p> <p><code>POST</code> to https://www.example.com:7076/api/v2/AccountWeight <pre><code>{\n    \"account\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"\n}\n</code></pre></p> <p>The RPC 1.0 <code>action</code> field is thus not necessary.</p> <p>The response message is always wrapped in an envelope. JSON clients use the <code>message</code> property to access the message:</p> <pre><code>{\n    \"time\": 1579736914615,\n    \"message_type\": \"AccountWeightResponse\",\n    \"message\": {\n        \"voting_weight\": \"668657804547735335568510480612620716\"\n    }\n}\n</code></pre> <p>The <code>message_type</code> is always Error if a call fails:</p> <pre><code>{\n    \"time\": 1579737134595,\n    \"message_type\": \"Error\",\n    \"message\": {\n        \"code\": 3,\n        \"message\": \"Access denied\"\n    }\n}\n</code></pre> <p>The <code>time</code> property is milliseconds since unix epoch when the message was produced on the server.</p> <p>Relation to the WebSocket response structure</p> <p>The <code>message</code> and <code>time</code> properties of the response envelope is exactly the same as in WebSockets. Instead of <code>message_type</code>, WebSockets use <code>topic</code>. This structure should help simplify clients using both HTTP and WebSockets.</p> <p>Headers</p> <p>When calling without an envelope, credentials and a correlation id can still be set using an HTTP header:</p> <p><code>curl --header \"Nano-Api-Key:mywalletuser\" ...</code></p> <p>The correlation header is Nano-Correlation-Id, which can be an arbitrary string. This is usually not useful for request/response JSON clients, but may be valuable if responses from RPCs and WebSocket subscriptions are dealt with in a common message handler on the client.</p>","title":"Making calls without a message envelope"},{"location":"integration-guides/ipc-integration/#making-calls-with-message-envelopes","text":"<p>If the message name is missing from the path, an envelope will be expected which tells the node about the message type.</p> <p><code>POST</code> to https://www.example.com:7076/api/v2 <pre><code>{ \n    \"message_type\" : \"AccountWeight\", \n    \"message\": {\n        \"account\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"\n    }\n}\n</code></pre></p> <p>The above is similar to using the \"action\" property in RPC 1.0. The main difference is that the message itself is always placed in a \"message\" property.</p> <p>The envelope allows additional information to be sent, such as credentials:</p> <p><code>POST</code> to https://www.example.com:7076/api/v2</p> <pre><code>{ \n    \"credentials\": \"mywalletuser\",  \n    \"message_type\" : \"AccountWeight\", \n    \"message\": {\n        \"account\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"\n    }\n}\n</code></pre> <p>Large requests While somewhat less convenient, the envelope approach is desirable for very large requests, because the node doesn't need to copy the message into an envelope.</p>","title":"Making calls with message envelopes"},{"location":"integration-guides/ipc-integration/#flatbuffers-mapping","text":"<p>Here's the corresponding message definitions for the AccountWeight request and response types:</p> <pre><code>/** Returns the voting weight for the given account */\ntable AccountWeight {\n    /** A nano_ address */\n    account: string (required);\n}\n\n/** Response to AccountWeight */\ntable AccountWeightResponse {\n    /** Voting weight as a decimal number*/\n    voting_weight: string (required);\n}\n</code></pre>","title":"Flatbuffers mapping"},{"location":"integration-guides/ipc-integration/#parsing-errors","text":"<p>Any problems with the JSON request will be reported with error details:</p> <pre><code>{\n    \"message_type\": \"Error\",\n    \"message\": {\n        \"code\": 1,\n        \"message\": \"Invalid message format: 3: 2: error: required field is missing: account in AccountWeight\"\n    }\n}\n</code></pre>","title":"Parsing errors"},{"location":"integration-guides/ipc-integration/#ipc-authorization","text":"<p>Work in progress</p> <p>Permission settings is a work in progress, and their exact definition and defaults will be part of RPC 2.0 in a future node release.</p>  <p>With IPC 2.0, the Nano node offers an authorization system.</p> <p>The configuration is done in <code>config-access.toml</code> by defining users and optional roles. Permissions are then assigned to these. The node only checks for permissions, never roles. This way, you can freely structure roles and users the way that suits your situation.</p> <p>There is also a default user with limited default permissions, currently only allowed to use the <code>AccountWeight</code> and <code>IsAlive</code> calls. This is used when no credentials are given. The permissions of the default user can also be changed in the configuration file.</p> <p>Credentials:</p> <ul> <li>IPC clients set the credentials in the message envelope </li> <li>HTTP(S) clients either use a message envelope or the HTTP Header <code>Nano-Api-Key</code></li> </ul>  <p>Layered security highly recommended</p> <p>While permissions enable node operators to pick what functionality to expose to which users, it is still highly recommended that layered security is used. For instance, a wallet backend should expose only required functionality to clients. The backend can then communicate with the node with credentials for additional security.</p>","title":"IPC Authorization"},{"location":"integration-guides/ipc-integration/#call-example","text":"<p><pre><code>curl --header \"Nano-Api-Key:mywalletuser\" --insecure -d \\\n   '{ \"account\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\"}' \\\n   https://www.example.com:7076/api/v2/AccountWeight\n</code></pre> This uses HTTPS (which the node supports through a build option), and the <code>--insecure</code> is there because the node's certificate in this example is self-signed.</p> <p>Using an envelope instead of the <code>AccountWeight</code> endpoint:</p> <pre><code>{ \n   \"credentials\": \"mywalletuser\",\n   \"message_type\" : \"AccountWeight\", \n   \"message\": \n   {\n       \"account\": \"nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3\" \n   }\n} \n</code></pre> <p><code>POST</code> the above to https://www.example.com:7076/api/v2</p>","title":"Call example"},{"location":"integration-guides/ipc-integration/#configuration-examples","text":"<p>For testing IPC without caring about permissions, this gives access to everything:</p> <pre><code>[[user]]\nallow = \"unrestricted\"\n</code></pre> <p>A more elaborate sample:</p>  <p>Work in progress</p> <p>Permission settings is a work in progress, and their exact definition and defaults will be part of RPC 2.0 in a future node release.</p>  <pre><code>[[role]]\nid = \"service_admin\"\nallow = \"api_service_register, api_service_stop\"\n\n[[user]]\n# User id's are typically randomly generated strings which\n# matches the credentials in API requests.\nid = \"user-2bb818ee-6424-4750-8bdb-db23bab7bc57\"\n\n# Inherit all the permissions from these roles\nroles = \"service_admin\"\n\n# Add additional permissions for this specific user\nallow = \"wallet_seed_change, api_topic_confirmation\"\n\n# A list of specific permissions can be denied as well\ndeny = \"api_account_weight\"\n\n[[user]]\nid = \"history-viewer-e3cf8a09-bd74-4ef2-9b84-e14f3db2bb4b\"\n\n# Add specific permission for this user\nallow = \"api_account_info, api_account_history\"\n\n# Do not inherit any default permissions. This is useful\n# for making users with a explicit set of minimum permissions.\n# The default user can also be set to bare. That way, a node can be\n# exposed with a limited set of default permissions.\nbare = true\n</code></pre>","title":"Configuration examples"},{"location":"integration-guides/ipc-integration/#reload-config","text":"<p>The access file can be reloaded without restarting the node or wallet. For the node:</p> <p><code>killall -SIGHUP nano_node</code></p> <p>(actual syntax depends on OS)</p>","title":"Reload config"},{"location":"integration-guides/ipc-integration/#ipc-v1-details","text":"<p>As of v18, the Nano node exposes a low level IPC interface over which multiple future APIs can be marshalled. Currently, the IPC interface supports the legacy RPC JSON format. The HTTP based RPC server is still available. Because the only IPC encoding is currently \"legacy RPC\", RPC config options like \"enable_control\" still apply.</p> <p>Transports</p> <p>TCP and unix domain sockets are supported. Named pipes and shared memory may be supported in future releases.</p> <p>IPC clients</p> <p>A NodeJS client is available at https://github.com/meltingice/nano-ipc-js</p> <p>A Python client is being developed at https://github.com/guilhermelawless/nano-ipc-py</p>","title":"IPC V1 Details"},{"location":"integration-guides/key-management/","text":"","title":"Key Management"},{"location":"integration-guides/key-management/#seeds","text":"","title":"Seeds"},{"location":"integration-guides/key-management/#hex-seed","text":"<p>Nano's private key(s) have been traditionally derived from a 64 character, uppercase hexadecimal string (0-9A-F). This is currently the more popular form of seed supported by a variety of services and wallets. Additional details available in The Basics guide.</p>","title":"Hex Seed"},{"location":"integration-guides/key-management/#mnemonic-seed","text":"<p>Wallets that provide mnemonic seeds should use the BIP39 standard word list and methods for generating the seed. When BIP32 master keys are generated from the seed, the HMAC hash key variation \"ed25519 seed\" should be used due to nano using ed25519 for the signing algorithm (see SLIP-0010).</p> <p>A non-standard derivation path is used for nano in the Ledger Nano implementation, as well as other popular wallets. With a coin-type of <code>165'</code> (<code>0x800000a5</code>), this is a partial BIP44 path of <code>m/44'/165'/[address index]</code>. Only hardened paths are defined.</p> <p><code>m/44'/165'/0'</code> derives the first private key, <code>m/44'/165'/1'</code> derives the second private key, and so on.</p> <p>The partial derivation path is hard-coded in the common verification tool by Ian Coleman: https://iancoleman.io/bip39/ . If using this tool to verify, note that regardless of custom settings on the BIP32 or BIP44 tabs for address generation, the resulting addresses in the table at the bottom will follow <code>m/44'/165'/[address index]</code>, even if the path in that table indicates otherwise. To see accurate paths in the Derived Addresses table, on the BIP32 tab set the BIP32 Derivation Path to <code>m/44'/165'</code>.</p>","title":"Mnemonic Seed"},{"location":"integration-guides/key-management/#demo-examples","text":"<p>External libraries, review before using</p> <p>The linked resources below contain code dealing with private key management and/or execution of transactions. The Nano Foundation does not control this code, does not endorse it and is not responsible for its use. Use of this code requires review and is at your own discretion.</p>  <p>https://github.com/roosmaa/nano-bip39-demo</p> <p>https://github.com/joltwallet/bip-mnemonic</p>","title":"Demo Examples"},{"location":"integration-guides/key-management/#implementations","text":"<p>https://github.com/numsu/nanocurrency-web-js</p>","title":"Implementations"},{"location":"integration-guides/key-management/#test-vectors","text":"<p>Given 24-Word Mnemonic: <pre><code>edge defense waste choose enrich upon flee junk siren film clown finish luggage leader kid quick brick print evidence swap drill paddle truly occur\n</code></pre> Given Passphrase: <pre><code>some password\n</code></pre> Derived BIP39 Seed: <pre><code>0dc285fde768f7ff29b66ce7252d56ed92fe003b605907f7a4f683c3dc8586d34a914d3c71fc099bb38ee4a59e5b081a3497b7a323e90cc68f67b5837690310c\n</code></pre></p>  Index 0 (<code>44'/165'/0'</code>) <p>Derived Private Key: <pre><code>3be4fc2ef3f3b7374e6fc4fb6e7bb153f8a2998b3b3dab50853eabe128024143\n</code></pre> Derived Public key: <pre><code>5b65b0e8173ee0802c2c3e6c9080d1a16b06de1176c938a924f58670904e82c4\n</code></pre> Derived Address: <pre><code>nano_1pu7p5n3ghq1i1p4rhmek41f5add1uh34xpb94nkbxe8g4a6x1p69emk8y1d\n</code></pre></p>   Index 1 (<code>44'/165'/1'</code>) <p>Derived Private Key: <pre><code>ce7e429e683d652446261c17a96da9ed1897aea96c8046f2b8036f6b05cb1a83\n</code></pre> Derived Public key: <pre><code>d9f7762e9cd4e7ed632481308cdb8f54abf0241332c0a8641f61e92e2fb03c12\n</code></pre> Derived Address: <pre><code>nano_3phqgrqbso99xojkb1bijmfryo7dy1k38ep1o3k3yrhb7rqu1h1k47yu78gz\n</code></pre></p>   Index 2 (<code>44'/165'/2'</code>) <p>Derived Private Key: <pre><code>1257df74609b9c6461a3f4e7fd6e3278f2ddcf2562694f2c3aa0515af4f09e38\n</code></pre> Derived Public key: <pre><code>a46da51986e25a14d82e32d765dcee69b9eeccd4405411430d91ddb61b717566\n</code></pre> Derived Address: <pre><code>nano_3b5fnnerfrkt4me4wepqeqggwtfsxu8fai4n473iu6gxprfq4xd8pk9gh1dg\n</code></pre></p>","title":"Test Vectors"},{"location":"integration-guides/key-management/#external-management","text":"<p>For larger, more robust systems, external private key management is recommended. In this setup, the node operator generates and stores private keys in an external database and only queries the nano_node to:</p> <ol> <li>Find receivable blocks for an account</li> <li>Sign transactions given a private key. More advanced systems may choose to implement signing themselves.</li> <li>Broadcast the signed transaction to the network.</li> </ol>  <p>Note</p> <p>WALLET_IDs are not used for External Private Key Management since private keys are not stored in the nano_node. Much of this section builds off of the Blocks Specifications documentation.</p>","title":"External Management"},{"location":"integration-guides/key-management/#external-accounting-systems","text":"<p>In order to properly implement accounting systems external to the Nano node the following best practices should be put into place, which ensure only fully confirmed blocks are used for external tracking of credits, debits, etc.</p>  <p>Confirmation and idempotency</p> <p>The details below expand on this, but the two most important pieces of any integration are:</p> <ol> <li>Always confirm blocks - make sure to follow the block confirmation tracking recommendations so you are always taking action from confirmed blocks</li> <li>Guarantee idempotency - whenever you take action from a block confirmation, it must be idempotent so you don't take the action again if the same block hash is seen through confirmation tracking</li> </ol>","title":"External accounting systems"},{"location":"integration-guides/key-management/#block-confirmation-procedures","text":"<p>Before crediting funds to an account internally based on a deposit on the network, the block sending the funds must be confirmed. This is done by verifying the network has reached quorum on the block. Details of the recommended verification process can be found in the block confirmation tracking guide.</p>","title":"Block confirmation procedures"},{"location":"integration-guides/key-management/#tracking-confirmed-balances","text":"<p>External accounting systems that track balances arriving to the node must track hashes of blocks that have been received in order to guarantee idempotency. Once confirmation of a block has been validated, the block hash should be recorded for the account along with any credits, debits or other related information. Any attempts to credit or debit accounts external to the node should check that no previous conflicting or duplicate activity was already recorded for that same block hash.</p>","title":"Tracking confirmed balances"},{"location":"integration-guides/key-management/#transaction-order-and-correctness","text":"<p>If you are creating a batch of transactions for a single account, which can be a mix of sending and receiving funds, there is no need to wait for the confirmation of blocks in that account to create the next transaction. As long as a transaction is valid, it will be confirmed by the network. The transactions that follow it can only be confirmed if the previous transactions are valid.</p> <p>However, you must always wait for the confirmation of receivable blocks before creating the corresponding receive transaction, to ensure it will be confirmed. Always wait for confirmation of transactions that you did not create yourself.</p>","title":"Transaction order and correctness"},{"location":"integration-guides/key-management/#expanding-private-keys","text":"<p>A Nano private key is a 256-bit piece of data produced from a cryptographically secure random number generator.</p>  <p>Secure Private Keys</p> <ul> <li>Generating private keys from an insecure source may result in loss of funds.</li> <li>Be sure to backup any generated private key; if lost the funds in the account will become inaccessible.</li> </ul>   <p>Step 1: Generate secure private key</p> <p>The bash command below generates a valid private key from a cryptographically secure random number generator. Always use a cryptographically secure processes for generating any private keys.</p>","title":"Expanding Private Keys"},{"location":"integration-guides/key-management/#command-example","text":"<pre><code>cat /dev/urandom | tr -dc '0-9A-F' | head -c${1:-64}\n</code></pre>","title":"Command Example"},{"location":"integration-guides/key-management/#success-result","text":"<pre><code>781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\n</code></pre>  <p>Step 2: Expand private key</p> <p>From the private key, a public key can be derived, and the public key can be translated into a Nano Address using the <code>key_expand</code> RPC command.</p>","title":"Success Result"},{"location":"integration-guides/key-management/#request-example","text":"<pre><code>curl -d '{\n  \"action\": \"key_expand\",\n  \"key\": \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#success-response","text":"<pre><code>{\n  \"private\": \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\",\n  \"public\": \"3068BB1CA04525BB0E416C485FE6A67FD52540227D267CC8B6E8DA958A7FA039\",\n  \"account\": \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\"\n}\n</code></pre>","title":"Success Response"},{"location":"integration-guides/key-management/#creating-transactions","text":"<p>Using external keys, transactions are generated in two steps: creation and broadcast. This section will be more heavy on example rather than precise specifications.</p>","title":"Creating Transactions"},{"location":"integration-guides/key-management/#send-transaction","text":"<p>Step 1: Get Account Info</p> <p>To send funds to an account, first call the <code>account_info</code> RPC command to gather necessary account information to craft your transaction. Setting <code>\"representative\": \"true\"</code> makes the nano_node also return the account's representative address, a necessary piece of data for creating a transaction.</p>","title":"Send Transaction"},{"location":"integration-guides/key-management/#request-example_1","text":"<pre><code>curl -d '{\n  \"action\": \"account_info\",\n  \"representative\": \"true\",\n  \"account\": \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#success-response_1","text":"<pre><code>{\n  \"frontier\": \"92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D\",\n  \"open_block\": \"B292BFFAAE9013BE630B31144EF15205E986940080687C0441CCFE6EAB67FE53\",\n  \"representative_block\": \"B292BFFAAE9013BE630B31144EF15205E986940080687C0441CCFE6EAB67FE53\",\n  \"balance\": \"4618869000000000000000000000000\",\n  \"modified_timestamp\": \"1524626644\",\n  \"block_count\": \"4\",\n  \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\"\n}\n</code></pre>  <p>Step 2: Build <code>block_create</code> request</p> <p>Using details from the <code>account_info</code> call response, along with other information, we can create the <code>block_create</code> RPC request.</p> <p>For more details on values, see the Blocks Specifications documentation.</p>    Field Value     <code>\"json_block\"</code> always <code>\"true\"</code>, so that the output is JSON-formatted   <code>\"type\"</code> always the constant <code>\"state\"</code>   <code>\"previous\"</code> <code>\"frontier\"</code> from <code>account_info</code> response   <code>\"account\"</code> <code>\"account\"</code> address used in the <code>account_info</code> call above that the block will be created for   <code>\"representative\"</code> <code>\"representative\"</code> address returned in the <code>account_info</code> call   <code>\"balance\"</code> balance of the account in raw after this transaction is completed (decreased if sending, increased if receiving). In this example, we will send 1 nanonano (10^{30} raw10^{30} raw) to address <code>nano_1q3hqecaw15cjt7thbtxu3pbzr1eihtzzpzxguoc37bj1wc5ffoh7w74gi6p</code>.   <code>\"link\"</code> destination address the funds will move between   <code>\"key\"</code> account's private key","title":"Success Response"},{"location":"integration-guides/key-management/#request-example_2","text":"<pre><code>curl -d '{\n  \"action\": \"block_create\",\n  \"json_block\": \"true\",\n  \"type\": \"state\",\n  \"previous\": \"92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D\",\n  \"account\": \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\",\n  \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n  \"balance\": \"3618869000000000000000000000000\",\n  \"link\": \"nano_1q3hqecaw15cjt7thbtxu3pbzr1eihtzzpzxguoc37bj1wc5ffoh7w74gi6p\",\n  \"key\": \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#success-response_2","text":"<pre><code>{\n  \"hash\": \"8DB5C07E0E62E9DFE8558CB9BD654A115B02245B38CD369753CECE36DAD13C05\",\n  \"block\": {\n    \"type\": \"state\",\n    \"account\": \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\",\n    \"previous\": \"92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D\",\n    \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n    \"balance\": \"3618869000000000000000000000000\",\n    \"link\": \"5C2FBB148E006A8E8BA7A75DD86C9FE00C83F5FFDBFD76EAA09531071436B6AF\",\n    \"link_as_account\": \"nano_1q3hqecaw15cjt7thbtxu3pbzr1eihtzzpzxguoc37bj1wc5ffoh7w74gi6p\",\n    \"signature\": \"79240D56231EF1885F354473733AF158DC6DA50E53836179565A20C0BE89D473ED3FF8CD11545FF0ED162A0B2C4626FD6BF84518568F8BB965A4884C7C32C205\",\n    \"work\": \"fbffed7c73b61367\"\n  }\n}\n</code></pre>  <p>Additional details</p> <ul> <li>The option <code>json_block</code>, available since V19.0, makes the RPC call return a non-stringified version of the block, which is easier to parse and always recommended.</li> <li><code>block_create</code> RPC commands generally take longer than other RPC commands because the nano_node has to generate the Proof-of-Work for the transaction. The response block data is already properly formatted to include in the <code>process</code> RPC command.</li> <li>The nano_node creating and signing this transaction has no concept of what the transaction amount is, nor network state; all the nano_node knows is that it is creating a block whose previous block on the account chain has hash <code>92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D</code> results in the account having a balance of <code>3618869000000000000000000000000</code>.</li> <li>If the account's balance at block hash <code>92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D</code> was actually <code>5618869000000000000000000000000</code>, then 2 nanonano would have been sent to <code>nano_1q3hqecaw15cjt7thbtxu3pbzr1eihtzzpzxguoc37bj1wc5ffoh7w74gi6p</code>.</li> </ul>   <p>What if I receive funds on my account and then broadcast the above crafted send? Would this result in me sending excess funds to the recipient?</p> <p>If you followed this guide, then the answer is \"no\". When you issued the <code>account_info</code> RPC command, you received the account's balance at a specific blockhash on its account-chain. In your crafted transaction, you specify that hash in the <code>\"previous\"</code> field. If funds were signed into your account, the headblock on your account-chain would change. Since your send no longer refers to the headblock on your account-chain when broadcasted, the network would reject your transaction.</p>   <p>Warning</p> <p>Since only the resulting balance is recorded, the transaction amount is interpreted as the difference in balance from the previous block on the account-chain and the newly created block. For this reason, it is crucial that you obtain the current account balance and headblock in the same atomic <code>account_info</code> RPC command.</p> <p>When not following this guide closely, the following inappropriate sequence of events could lead to erroneous amounts sent to a recipient.</p> <ol> <li>An account's balance, say 5 nanonano, was obtained using the <code>account_balance</code>. This balance is valid as of hypothetical BLOCK_A.</li> <li>By another process you control, a receive (BLOCK_B) was signed and broadcasted into your account-chain (race-condition).</li> <li>Lets say this <code>receive</code> increased the funds on the account chain by 10 nanonano, resulting in a final balance 15 nanonano.</li> <li>The account's frontier block is obtained by the <code>accounts_frontiers</code> RPC command, returning the hash of BLOCK_B. Other transaction metadata is obtained by other RPC commands.</li> <li>With the collected data, if a send transaction was created for 3 nanonano, the final balance would be computed as 5 - 35 - 3, or 2 nanonano.</li> <li>When this is broadcasted, since it is referring to the current head block on the account, BLOCK_B, the network would accept it. But, because the balance as of BLOCK_B was actually 15 nanonano, this would result in 12 nanonano being sent to the recipient.</li> </ol> <p>For this reason, only populate transaction data source from a single <code>account_info</code> RPC call.</p>   <p>Step 3: Broadcast the transaction</p> <p>As a result of the command above, the nano_node will return a signed, but not yet broadcasted transaction. Broadcasting of the signed transaction is covered in the Broadcasting Transactions section.</p>","title":"Success Response"},{"location":"integration-guides/key-management/#receive-transaction","text":"<p>Manually receiving first block</p> <p>The very first transaction on an account-chain, which is always a receive, is slightly special and deserves its own section First Receive Transaction.</p>   <p>Step 1: Get Account Info</p> <p>Receiving funds is very similar to sending funds outlined in the previous section, starting with calling <code>account_info</code> to get block details for the account frontier. The scenario below pretends that our previous example of a send transaction was not broadcast and confirmed on the network because the starting <code>account_info</code> details are identical.</p>","title":"Receive Transaction"},{"location":"integration-guides/key-management/#request-example_3","text":"<pre><code>curl -d '{\n  \"action\": \"account_info\",\n  \"representative\": \"true\",\n  \"account\": \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#success-response_3","text":"<pre><code>{\n  \"frontier\": \"92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D\",\n  \"open_block\": \"B292BFFAAE9013BE630B31144EF15205E986940080687C0441CCFE6EAB67FE53\",\n  \"representative_block\": \"B292BFFAAE9013BE630B31144EF15205E986940080687C0441CCFE6EAB67FE53\",\n  \"balance\": \"4618869000000000000000000000000\",\n  \"modified_timestamp\": \"1524626644\",\n  \"block_count\": \"4\",\n  \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\"\n}\n</code></pre>  <p>Step 2: Build <code>block_create</code> request</p> <p>Using details from the <code>account_info</code> call response, along with other information, we can create the <code>block_create</code> RPC request. The two differences between the send transaction are the <code>\"link\"</code> and <code>\"balance\"</code> fields.</p> <p>For more details on values, see the Blocks Specifications documentation.</p>    Field Value     <code>\"json_block\"</code> always <code>\"true\"</code>, so that the output is JSON-formatted   <code>\"type\"</code> always the constant <code>\"state\"</code>   <code>\"previous\"</code> <code>\"frontier\"</code> from <code>account_info</code> response, or <code>0</code> if first block on new account   <code>\"account\"</code> <code>\"account\"</code> address used in the <code>account_info</code> call above that the block will be created for   <code>\"representative\"</code> <code>\"representative\"</code> address returned in the <code>account_info</code> call   <code>\"balance\"</code> balance of the account in rawraw after this transaction is completed (decreased if sending, increased if receiving). In this example, we will receive 7 nanonano (7 \\times 10^{30} raw7 \\times 10^{30} raw) based on the assumed details of the block the <code>\"link\"</code> hash refers to (block contents not shown in this example).   <code>\"link\"</code> block hash of its paired send transaction, assumed to be a 7 nanonano send from block hash <code>CBC911F57B6827649423C92C88C0C56637A4274FF019E77E24D61D12B5338783</code>   <code>\"key\"</code> account's private key","title":"Success Response"},{"location":"integration-guides/key-management/#request-example_4","text":"<pre><code>curl -d '{\n  \"action\": \"block_create\",\n  \"json_block\": \"true\",\n  \"type\": \"state\",\n  \"previous\": \"92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D\",\n  \"account\": \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\",\n  \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n  \"balance\": \"11618869000000000000000000000000\",\n  \"link\": \"CBC911F57B6827649423C92C88C0C56637A4274FF019E77E24D61D12B5338783\",\n  \"key\": \"781186FB9EF17DB6E3D1056550D9FAE5D5BBADA6A6BC370E4CBB938B1DC71DA3\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#success-response_4","text":"<pre><code>{\n  \"hash\": \"350D145570578A36D3D5ADE58DC7465F4CAAF257DD55BD93055FF826057E2CDD\",\n  \"block\": {\n    \"type\": \"state\",\n    \"account\": \"nano_1e5aqegc1jb7qe964u4adzmcezyo6o146zb8hm6dft8tkp79za3sxwjym5rx\",\n    \"previous\": \"92BA74A7D6DC7557F3EDA95ADC6341D51AC777A0A6FF0688A5C492AB2B2CB40D\",\n    \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n    \"balance\": \"11618869000000000000000000000000\",\n    \"link\": \"CBC911F57B6827649423C92C88C0C56637A4274FF019E77E24D61D12B5338783\",\n    \"link_as_account\": \"nano_3kyb49tqpt39ekc49kbej51ecsjqnimnzw1swxz4boix4ctm93w517umuiw8\",\n    \"signature\": \"EEFFE1EFCCC8F2F6F2F1B79B80ABE855939DD9D6341323186494ADEE775DAADB3B6A6A07A85511F2185F6E739C4A54F1454436E22255A542ED879FD04FEED001\",\n    \"work\": \"c5cf86de24b24419\"\n  }\n}\n</code></pre>  <p>Additional details</p> <p>Here the follow scenario occurs:</p> <ul> <li>Previous balance was 4618869000000000000000000000000 rawraw</li> <li>Increased our balance by 7000000000000000000000000000000 rawraw</li> <li>Final balance becomes 11618869000000000000000000000000 rawraw</li> </ul>   <p>Step 3: Broadcast the transaction</p> <p>As a result of the command above, the nano_node will return a signed, but not yet broadcasted transaction. Broadcasting of the signed transaction is covered in the Broadcasting Transactions section.</p>","title":"Success Response"},{"location":"integration-guides/key-management/#first-receive-transaction","text":"<p>The first transaction of an account is crafted in a slightly different way. To open an account, you must have sent some funds to it with a Send Transaction from another account. The funds will be receivable on the receiving account. If you already know the hash of the receivable transaction, you can skip Step 1.</p>  <p>Step 1: Obtain the receivable transaction block hash</p> <p>Start with obtaining a list of receivable transactions in your unopened account. Limit the response to the highest value transaction by using a combination of <code>sorting</code> and <code>count</code>.</p>","title":"First Receive Transaction"},{"location":"integration-guides/key-management/#request-example_5","text":"<pre><code>curl -d '{\n  \"action\": \"receivable\",\n  \"account\": \"nano_1rawdji18mmcu9psd6h87qath4ta7iqfy8i4rqi89sfdwtbcxn57jm9k3q11\",\n  \"count\": \"1\",\n  \"sorting\": \"true\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#success-response_5","text":"<pre><code>{\n    \"blocks\": {\n        \"5B2DA492506339C0459867AA1DA1E7EDAAC4344342FAB0848F43B46D248C8E99\": \"100\"\n    }\n}\n</code></pre>  <p>Step 2: Build <code>block_create</code> request</p> <p>Using the block hash and raw transaction amount from the <code>receivable</code> call response, along with other information, we can create the <code>block_create</code> RPC request. The only difference between the normal receive transactions is the <code>\"previous\"</code> field.</p> <p>For more details on values, see the Blocks Specifications documentation.</p>    Field Value     <code>\"json_block\"</code> always <code>\"true\"</code>, so that the output is JSON-formatted   <code>\"type\"</code> always the constant <code>\"state\"</code>   <code>\"previous\"</code> always the constant \"0\" as this request is for the first block of the account   <code>\"account\"</code> <code>\"account\"</code> address used in the <code>account_info</code> call above that the block will be created for   <code>\"representative\"</code> <code>\"representative\"</code> the account address to use as representative for your account. Choose a reliable, trustworthy representative.   <code>\"balance\"</code> balance of the account in rawraw after this transaction is completed. In this example, we will receive 100\\ raw100\\ raw, based on the assumed details from the <code>\"receivable\"</code> response above.   <code>\"link\"</code> block hash of its paired send transaction, in this case assumed to be the block <code>5B2DA492506339C0459867AA1DA1E7EDAAC4344342FAB0848F43B46D248C8E99</code>   <code>\"key\"</code> account's private key","title":"Success Response"},{"location":"integration-guides/key-management/#request-example_6","text":"<pre><code>curl -d '{\n  \"action\": \"block_create\",\n  \"json_block\": \"true\",\n  \"type\": \"state\",\n  \"previous\": \"0\",\n  \"account\": \"nano_1rawdji18mmcu9psd6h87qath4ta7iqfy8i4rqi89sfdwtbcxn57jm9k3q11\",\n  \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n  \"balance\": \"100\",\n  \"link\": \"5B2DA492506339C0459867AA1DA1E7EDAAC4344342FAB0848F43B46D248C8E99\",\n  \"key\": \"0ED82E6990A16E7AD2375AB5D54BEAABF6C676D09BEC74D9295FCAE35439F694\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#success-response_6","text":"<pre><code>{\n  \"hash\": \"ED3BE5340CC9D62964B5A5F84375A06078CBEDC45FB5FA2926985D6E27D803BB\",\n  \"block\": {\n    \"type\": \"state\",\n    \"account\": \"nano_1rawdji18mmcu9psd6h87qath4ta7iqfy8i4rqi89sfdwtbcxn57jm9k3q11\",\n    \"previous\": \"0000000000000000000000000000000000000000000000000000000000000000\",\n    \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n    \"balance\": \"100\",\n    \"link\": \"5B2DA492506339C0459867AA1DA1E7EDAAC4344342FAB0848F43B46D248C8E99\",\n    \"link_as_account\": \"nano_1psfnkb71rssr34sisxc5piyhufcrit68iqtp44ayixnfnkas5nsiuy58za7\",\n    \"signature\": \"903991714A55954D15C91DB75CAE2FBF1DD1A2D6DA5524AA2870F76B50A8FE8B4E3FBB53E46B9E82638104AAB3CFA71CFC36B7D676B3D6CAE84725D04E4C360F\",\n    \"work\": \"08d09dc3405d9441\"\n  }\n}\n</code></pre>  <p>Step 3: Broadcast the transaction</p> <p>As a result of the command above, the nano_node will return a signed, but not yet broadcasted transaction. Broadcasting of the signed transaction is covered in the Broadcasting Transactions section.</p>","title":"Success Response"},{"location":"integration-guides/key-management/#broadcasting-transactions","text":"<p>Broadcast using <code>process</code> RPC command</p> <p>Common to all of these transactions is the need to broadcast the completed block to the network. This is achieved by the <code>process</code> RPC command which accepts the block as stringified JSON data. If you followed the previous examples, you used the option <code>json_block</code> for RPC <code>block_create</code>, which allows you use the non-stringified version, as long as you include the same option in this RPC call. A successful broadcast will return the broadcasted block's hash.</p>   <p>Including <code>subtype</code> in <code>process</code> RPC calls highly recommended</p> <p>In order to avoid potential incorrect sends including the optional <code>subtype</code> parameter on all <code>process</code> RPC calls is highly recommended. In the next version of the RPC this parameter will be required.</p>","title":"Broadcasting Transactions"},{"location":"integration-guides/key-management/#request-example_7","text":"<pre><code>curl -d '{\n  \"action\": \"process\",\n  \"json_block\": \"true\",\n  \"subtype\": \"open\",\n  \"block\": {\n    \"type\": \"state\",\n    \"account\": \"nano_1rawdji18mmcu9psd6h87qath4ta7iqfy8i4rqi89sfdwtbcxn57jm9k3q11\",\n    \"previous\": \"0000000000000000000000000000000000000000000000000000000000000000\",\n    \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n    \"balance\": \"100\",\n    \"link\": \"5B2DA492506339C0459867AA1DA1E7EDAAC4344342FAB0848F43B46D248C8E99\",\n    \"link_as_account\": \"nano_1psfnkb71rssr34sisxc5piyhufcrit68iqtp44ayixnfnkas5nsiuy58za7\",\n    \"signature\": \"903991714A55954D15C91DB75CAE2FBF1DD1A2D6DA5524AA2870F76B50A8FE8B4E3FBB53E46B9E82638104AAB3CFA71CFC36B7D676B3D6CAE84725D04E4C360F\",\n    \"work\": \"08d09dc3405d9441\"\n  }\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#success-response_7","text":"<pre><code>{ \n  \"hash\": \"42A723D2B60462BF7C9A003FE9A70057D3A6355CA5F1D0A57581000000000000\"\n}\n</code></pre>  <p>Block watching and re-work</p> <p>Since V20.0, blocks processed using <code>process</code> are placed under observation by the node for re-broadcasting and re-generation of work under certain conditions. If you wish to disable this feature, add <code>\"watch_work\": \"false\"</code> to the process RPC command.</p> <ul> <li>If a block is not confirmed within a certain amount of time (configuration option <code>work_watcher_period</code>, default 5 seconds), an automatic re-generation of a higher difficulty proof-of-work may take place.</li> <li>Re-generation only takes place when the network is unable to confirm transactions quickly (commonly referred as the network being saturated) and the higher difficulty proof-of-work is used to help prioritize the block higher in the processing queue of other nodes.</li> <li>Configuration option <code>max_work_generate_multiplier</code> can be used to limit how much effort should be spent in re-generating the proof-of-work.</li> <li>The target proof-of-work difficulty threshold is obtained internally as the minimum between <code>active_difficulty</code> and <code>max_work_generate_multiplier</code> (converted to difficulty).</li> <li>With a new, higher difficulty proof-of-work, the block will get higher confirmation priority across the network.</li> </ul>   <p>When a transaction does not confirm</p> <ul> <li>If a transaction is taking too long to confirm, you may call the <code>process</code> RPC command with the same block data with no risk.</li> <li>If for some reason a transaction fails to properly broadcast, subsequent transactions on the account-chain after that transaction will not be accepted by the network since the <code>\"previous\"</code> field in the transaction data refers to a non-existant block.</li> <li>If this situation occurs, rebroadcasting the missing transaction(s) will make the subsequent blocks valid in the network's ledger.</li> </ul>    <p>Rebroadcasting blocks for an account-chain</p> <p>The following command rebroadcasts all hashes on an account-chain starting at block hash provided:</p>","title":"Success Response"},{"location":"integration-guides/key-management/#request-example_8","text":"<pre><code>curl -d '{\n  \"action\": \"republish\",\n  \"hash\": \"48006BF3146C18CAD3A53A957BF64EF7C57820B21FCCE373FA637559DA260358\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#internal-management","text":"<p>The nano_node software has a built-in private-key manager that is suitable for smaller operations (&lt;1000 accounts). External Key Management allows more powerful and robust systems at the cost of additional complexity. External Key Management is recommended for larger operations.</p>","title":"Internal Management"},{"location":"integration-guides/key-management/#creating-a-wallet","text":"<p>To create an account, you first must create a wallet to hold the seed that will subsequently create the account.</p>","title":"Creating a Wallet"},{"location":"integration-guides/key-management/#request-example_9","text":"<pre><code>curl -d '{\n  \"action\": \"wallet_create\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#success-response_8","text":"<pre><code>{ \n  \"wallet\": \"E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\"\n}\n</code></pre> <p>The nano_node responds with the WALLET_ID. If you lose your WALLET_ID, it can only be recovered via a CLI command. To reiterate, the WALLET_ID is not a seed. The seed can be extracted for backup in Backing Up Seed. Many of the RPC commands in this guide require the WALLET_ID.</p>","title":"Success Response"},{"location":"integration-guides/key-management/#recovering-wallet_id","text":"<p>If you lose your WALLET_ID, you can print out all your WALLET_IDs and public addresses in those wallets with the <code>--wallet_list</code> CLI command as follows:</p>","title":"Recovering WALLET_ID"},{"location":"integration-guides/key-management/#command-format","text":"<pre><code>docker exec ${NANO_NAME} nano_node --wallet_list\n</code></pre>","title":"Command Format"},{"location":"integration-guides/key-management/#success-response_9","text":"<pre><code>Wallet_ID: E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\nnano_16odwi933gpzmkgdcy9tt5zef5ka3jcfubc97fwypsokg7sji4mb9n6qtbme\nWallet_ID: DB0711484E35A4C75230D898853A86BFAFE9F87FCE99C83A4C2668C39607DD4B\n</code></pre> <p>In this example, the nano_node's internal private-key management system contains two wallets, each with a different 256-bit seed. The first wallet has a single account and the second wallet has zero accounts. Account creation will be covered later.</p>","title":"Success Response"},{"location":"integration-guides/key-management/#backing-up-seed","text":"<p>The following command will print the seed for a given wallet to stdout. Replace <code>${WALLET_ID}</code> with the WALLET_ID that you would like to display the seed of.</p>","title":"Backing Up Seed"},{"location":"integration-guides/key-management/#command-format_1","text":"<pre><code>docker exec ${NANO_NAME:-nano_node_1} nano_node --wallet_decrypt_unsafe --wallet ${WALLET_ID}\n</code></pre>","title":"Command Format"},{"location":"integration-guides/key-management/#success-response_10","text":"<pre><code>Seed: D56143E7561D71C1AF4D563C6AF79EECE93E82479818AD8ED88BED1AAE8BE4E5\nPub: nano_16odwi933gpzmkgdcy9tt5zef5ka3jcfubc97fwypsokg7sji4mb9n6qtbme\nPrv: 1F6FEB5D1E05C10B904E1112F430C3FA93ACC7067206B63AD155199501794E3E\n</code></pre>  <p>Info</p> <p>The nano_node responds with three pieces of information:</p> <ol> <li>The seed of the wallet (back this up).</li> <li>The pairing public address</li> <li>The private key (deterministically derived from seed) of accounts within the wallet.</li> </ol> <p>Additional notes:</p> <ul> <li>If you change the seed in a wallet, future created accounts will be derived from that seed.</li> <li>Changing seeds on a wallet that already has accounts can cause accidental loss of funds from improper seed or private key backup.</li> <li>It is recommended to always create a new wallet when restoring a seed.</li> </ul>","title":"Success Response"},{"location":"integration-guides/key-management/#error-response","text":"<pre><code>Wallet doesn't exist\n</code></pre>  <p>Warning</p> <p>If anyone has access to the seed, they can freely access funds, so keep this very secure. Since the above command prints to stdout, it is recommended to wipe stdout afterwards using:</p> <pre><code>clear &amp;&amp; printf '\\e[3J'\n</code></pre>","title":"Error Response"},{"location":"integration-guides/key-management/#restoringchanging-seed","text":"<p>Warning</p> <p>Only change the seed of a wallet that contains no accounts. Changing the seed of a wallet that already has accounts may lead to a false sense of security: accounts are generated by the seed that is currently in the wallet. Generating accounts, then switching the seed and backing up the new seed does not backup the previously generated accounts.</p>","title":"Restoring/Changing Seed"},{"location":"integration-guides/key-management/#request-format","text":"<pre><code>curl -d '{\n  \"action\": \"wallet_change_seed\",\n  \"wallet\": \"&lt;WALLET_ID&gt;\",\n  \"seed\": \"&lt;SEED&gt;\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Format"},{"location":"integration-guides/key-management/#request-example_10","text":"<pre><code>curl -d '{\n  \"action\":\"wallet_change_seed\",\n  \"wallet\":\"DB0711484E35A4C75230D898853A86BFAFE9F87FCE99C83A4C2668C39607DD4B\",\n  \"seed\":\"D56143E7561D71C1AF4D563C6AF79EECE93E82479818AD8ED88BED1AAE8BE4E5\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#success-response_11","text":"<pre><code>{\n  \"success\": \"\"\n}\n</code></pre>","title":"Success Response"},{"location":"integration-guides/key-management/#error-response_1","text":"<p>Response if the wallet_id isn't found in nano_node: <pre><code>{\n  \"error\": \"Wallet not found\"\n}\n</code></pre></p> <p>Response if the seed field contains non-hexidecimal values or is too long: <pre><code>{ \n  \"error\": \"Bad seed\"\n}\n</code></pre></p>  <p>Warning</p> <p>If the hexidecimal seed represents less than 256 bits, the seed will be 0-padded on the left to become 256 bits.</p>","title":"Error Response"},{"location":"integration-guides/key-management/#account-create","text":"<p>After creating a wallet, it's corresponding WALLET_ID, and backing up the seed (not the wallet_id), the wallet can be populated with accounts. To create a new account in a wallet use the <code>account_create</code> RPC command:</p>","title":"Account Create"},{"location":"integration-guides/key-management/#request-format_1","text":"<pre><code>curl -d '{\n  \"action\": \"account_create\",\n  \"wallet\": \"&lt;WALLET_ID&gt;\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Format"},{"location":"integration-guides/key-management/#success-response_12","text":"<pre><code>{ \n  \"account\": \"nano_16odwi933gpzmkgdcy9tt5zef5ka3jcfubc97fwypsokg7sji4mb9n6qtbme\"\n}\n</code></pre>","title":"Success Response"},{"location":"integration-guides/key-management/#error-response_2","text":"<pre><code>{\n  \"error\": \"Wallet not found\"\n}\n</code></pre>","title":"Error Response"},{"location":"integration-guides/key-management/#bulk-account-create","text":"<p>To generate many accounts in bulk, it is more efficient to create them all at once using the <code>accounts_create</code> RPC command:</p>","title":"Bulk Account Create"},{"location":"integration-guides/key-management/#request-format_2","text":"<pre><code>curl -d '{\n    \"action\": \"accounts_create\",\n    \"wallet\": \"&lt;WALLET_ID&gt;\",\n    \"count\": \"&lt;NUM_ACCOUNTS&gt;\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Format"},{"location":"integration-guides/key-management/#request-example_11","text":"<pre><code>curl -d '{\n  \"action\": \"accounts_create\",\n  \"wallet\": \"DB0711484E35A4C75230D898853A86BFAFE9F87FCE99C83A4C2668C39607DD4B\",\n  \"count\":\"5\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#success-response_13","text":"<pre><code>{\n  \"accounts\": [\n    \"nano_35kgi43t5hgi64715qnppmz1yb6re1igfcrkfx4ppirkqpfmecnpd1mdmafu\",\n    \"nano_3t13y6b7h93yn9hehn8p6yqx1yqzrxxs33drhzep8huhymwxamn15pba75oj\",\n    \"nano_11exxzfoosai96w7gnrjrn7m6i8bodch37ib8jgxsm5k96na6e1wda8np881\",\n    \"nano_3xbsso8pkemwatwdnkcyn1bfcmrb8dpcg3pit9zqxj9mkxa6ifiankff6m9x\",\n    \"nano_1q5gpy46moe1csj8md8oq3x57sxqmwskk8mmr7c63q1yebnjcsxg1yib19kn\"\n  ]\n}\n</code></pre>","title":"Success Response"},{"location":"integration-guides/key-management/#receiving-funds","text":"<p>As long as the nano_node is synced and the node wallet is unlocked (node wallet locking is not covered in this guide), nano_node automatically creates and signs receive transactions for all accounts in the wallet's internal private-key management system.</p>  <p>Tip</p> <p>In the event that a receive is not automatically generated, it can be manually generated using the <code>receive</code> RPC command.</p>","title":"Receiving Funds"},{"location":"integration-guides/key-management/#semi-manual-receiving-funds","text":"<p>If the nano_node does not automatically sign in a receivable transaction, transactions can be manually signed in. The easiest way is to explicitly command the nano_node to check all of the accounts in all of its wallets for receivable blocks.</p>","title":"Semi-Manual Receiving Funds"},{"location":"integration-guides/key-management/#request-example_12","text":"<pre><code>curl -d '{\n  \"action\": \"search_receivable_all\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#success-response_14","text":"<pre><code>{\n  \"success\": \"\"\n}\n</code></pre>  <p>Note</p> <p>As the number of accounts in a nano_node grows, this command becomes increasingly computationally expensive.</p>","title":"Success Response"},{"location":"integration-guides/key-management/#sending-funds","text":"<p>The <code>send</code> RPC command sends funds from an account in the specified wallet to a destination address.</p>","title":"Sending funds"},{"location":"integration-guides/key-management/#request-format_3","text":"<pre><code>curl -d '{\n  \"action\": \"send\",\n  \"wallet\": \"&lt;WALLET_ID&gt;\",\n  \"source\": \"&lt;SOURCE_ADDRESS&gt;\",\n  \"destination\": \"&lt;DESTINATION_ADDRESS&gt;\",\n  \"amount\": \"1000000\",\n  \"id\": \"7081e2b8fec9146e\"\n}' http://127.0.0.1:7076\n</code></pre>    Field Description     wallet WALLET_ID containing the source address   source Address you control starting with \"nano_\"   destination Destination address starting with \"nano_\"   amount Amount to send in raw   id Any string      <p>Important</p> <p>The <code>\"id\"</code> field is a safety mechanism that prevents issuing a transaction multiple times by repeating the RPC command.</p> <ul> <li>If a transaction is successful, any subsequent <code>send</code> RPC commands with the same identifier will be ignored by the nano_node.</li> <li>If the request times out, then the send may or may not have gone through.</li> <li>Most exchange \"double withdraw\" issues are caused by naive error-handling routines which re-issue the send request without the <code>\"id\"</code> parameter.</li> <li>The <code>\"id\"</code> field is local to your nano_node instance and does not offer protection when sent to different instances of nano_node that manage the same seed.</li> <li>As previously mentioned, having a seed loaded in multiple online nano_node is strongly discouraged.</li> <li>If managing more than 1000 accounts, building a separate system for managing keys and accounts externally is recommended</li> </ul>   <p>Below is a sample command to send 1 nanonano from <code>nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000</code> to <code>nano_16odwi933gpzmkgdcy9tt5zef5ka3jcfubc97fwypsokg7sji4mb9n6qtbme</code>.</p>","title":"Request Format"},{"location":"integration-guides/key-management/#request-example_13","text":"<pre><code>curl -d '{\n  \"action\": \"send\",\n  \"wallet\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\",\n  \"source\": \"nano_3e3j5tkog48pnny9dmfzj1r16pg8t1e76dz5tmac6iq689wyjfpi00000000\",\n  \"destination\": \"nano_16odwi933gpzmkgdcy9tt5zef5ka3jcfubc97fwypsokg7sji4mb9n6qtbme\",\n  \"amount\": \"1000000000000000000000000000000\",\n  \"id\": \"7081e2b8fec9146e\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#success-response_15","text":"<pre><code>{ \n  \"block\": \"000D1BAEC8EC208142C99059B393051BAC8380F9B5A2E6B2489A277D81789F3F\"\n}\n</code></pre> <p>On success, the nano_node returns the hash of the transaction's block.</p>","title":"Success Response"},{"location":"integration-guides/key-management/#republishing-transactions","text":"<p>It may take a few seconds for the transaction to appear on the Nano Network. If the transaction fails to appear, you may call the <code>republish</code> RPC command with the oldest missing transaction's hash. Account-chains must be continuous and unbroken. If for some reason a transaction fails to properly broadcast, subsequent transactions on the account-chain will not be accepted by the network since the <code>\"previous\"</code> field in the transaction data refers to a block  unknown to to other nodes on the network.</p>  <p>Tip</p> <p>Republishing the missing transaction(s) will make all the subsequent blocks valid in the network's ledger. Republishing does not create new transactions.</p>  <p>The following command rebroadcasts all hashes on an acccount-chain starting at block with hash <code>${BLOCK_HASH}</code>:</p>","title":"Republishing Transactions"},{"location":"integration-guides/key-management/#request-example_14","text":"<pre><code>curl -d '{\n  \"action\": \"republish\",\n  \"hash\": \"AF9C1D46AAE66CC8F827904ED02D4B3D95AA98B1FF058352BA6B670BEFD40231\"\n}' http://127.0.0.1:7076\n</code></pre>","title":"Request Example"},{"location":"integration-guides/key-management/#success-response_16","text":"<p><pre><code>{\n  \"success\": \"\",\n  \"blocks\": [\n    \"AF9C1D46AAE66CC8F827904ED02D4B3D95AA98B1FF058352BA6B670BEFD40231\",\n    \"C9A111580A21F3E63F2283DAF6450D5178BFAC2A6C38E09B76EEA9CE37EC9CE0\"\n  ]\n}\n</code></pre> On success, the nano_node returns the hashes of all republished blocks.</p>","title":"Success Response"},{"location":"integration-guides/the-basics/","text":"","title":"The Basics"},{"location":"integration-guides/the-basics/#block-lattice-design","text":"<p>Nano's ledger is built on a data-structure called a \"Block Lattice.\" Every account (private/public key pair) has their own blockchain (account-chain). Only the holder of the private key may sign and publish blocks to their own account-chain.  Each block represents a transaction.</p>    Action Description     Send Send funds from users account to another account   Receive Receive funds from a given \"Send\" transaction    <p>The system is akin to writing (send) and cashing (receive) a Cashier's Check.  There are a few things to consider about transactions:</p> <ul> <li>The receiving account does not have to be online during the Send transaction.</li> <li>The transaction will stay as receivable indefinitely until a Receive transaction is created.</li> <li>Once funds are sent, they cannot be revoked by the sender.</li> </ul>","title":"Block Lattice Design"},{"location":"integration-guides/the-basics/#representatives","text":"<p>The Nano Network achieves consensus using the unique Open Representative Voting (ORV) model. In this setup, representatives (accounts where nano_node with the private keys are running 24/7) vote on transactions.</p>  <p>Info</p> <p>Below are some helpful things to remember about Nano's representatives and consensus:</p> <ul> <li>A representative's voting power is directly proportional to the amount of funds delegated to that account by other users of the protocol.</li> <li>An account's representative has no bearing on its transactions or nano_node operation.</li> <li>Choosing a representative with good uptime that is also a unique entity (to prevent sybil attacks) helps maintain high Nano network security.</li> <li>If an account's representative goes offline, the account's funds are no longer used to help secure the network; however, the account is unaffected.</li> <li>Anyone that runs a full-time node may be a representative and be delegated voting weight from other users of the protocol.</li> <li>An account can freely change its representative anytime within any transaction or explicitly by publishing a block which only changes the representative (sends no funds), which most wallets support.</li> </ul>","title":"Representatives"},{"location":"integration-guides/the-basics/#account-key-seed-and-wallet-ids","text":"<p>When dealing with the various IDs in the node it is important to understand the function and implication of each one.</p>  <p>Similar IDs, Different Functions</p> <p>There are several things that can have a similar form but may have very different functions, and mixing them up can result in loss of funds. Use caution when handling them.</p>","title":"Account, Key, Seed and Wallet IDs"},{"location":"integration-guides/the-basics/#wallet-id","text":"<p>This is a series of 32 random bytes of data and is not the seed. It is used in several RPC actions and command line options for the node. It is a purely local UUID that is a reference to a block of data about a specific wallet (set of seed/private keys/info about them) in your node's local database file.</p> <p>The reason this is necessary is because we want to store information about each account in a wallet: whether it's been used, what its account is so we don't have to generate it every time, its balance, etc. Also, so we can hold ad hoc accounts, which are accounts that are not derived from the seed. This identifier is only useful in conjunction with your node's database file and it will not recover funds if that database is lost or corrupted. </p> <p>This is the value that you get back when using the <code>wallet_create</code> etc RPC commands, and what the node expects for RPC commands with a <code>\"wallet\"</code> field as input.</p>","title":"Wallet ID"},{"location":"integration-guides/the-basics/#seed","text":"<p>This is a series of 32 random bytes of data, usually represented as a 64 character, uppercase hexadecimal string (0-9A-F). This value is used to derive account private keys for accounts by combining it with an index and then putting that into the following hash function where <code>||</code> means concatenation and <code>i</code> is a 32-bit big-endian unsigned integer: <code>PrivK[i] = blake2b(outLen = 32, input = seed || i)</code></p> <p>Private keys are derived deterministically from the seed, which means that as long as you put the same seed and index into the derivation function, you will get the same resulting private key every time. Therefore, knowing just the seed allows you to be able to access all the derived private keys from index 0 to 2^{32} - 1 (because the index value is a unsigned 32-bit integer).</p> <p>Wallet implementations will commonly start from index 0 and increment it by 1 each time you create a new account so that recovering accounts is as easy as importing the seed and then repeating this account creation process.</p> <p>It should be noted that Nano reference wallet is using described Blake2b private keys derivation path. However some implementations can use BIP44 deterministic wallets and mnemonic seed producing different private keys for given seed and indices. Additionally 24-word mnemonic can be derived from a Nano 64 length hex seed as entropy with clear notice for users that this is not BIP44 seed/entropy.</p> <p>Code samples</p> PythonBitcoinjs   <p>Generates a deterministic key:</p> <pre><code>import hashlib\nseed = b\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\" # \"0000000000000000000000000000000000000000000000000000000000000001\"\nindex = 0x00000001.to_bytes(4, 'big') # 1\nblake2b_state = hashlib.blake2b(digest_size=32)\nblake2b_state.update(seed+index)\n# where `+` means concatenation, not sum: https://docs.python.org/3/library/hashlib.html#hashlib.hash.update\n# code line above is equal to `blake2b_state.update(seed); blake2b_state.update(index)`\nPrivK = blake2b_state.digest()\nprint(blake2b_state.hexdigest().upper()) # \"1495F2D49159CC2EAAAA97EBB42346418E1268AFF16D7FCA90E6BAD6D0965520\"\n</code></pre>   <p>Mnemonic words for Blake2b Nano seed using Bitcoinjs: <pre><code>const bip39 = require('bip39')\n\nconst mnemonic = bip39.entropyToMnemonic('0000000000000000000000000000000000000000000000000000000000000001')\n// =&gt; abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon diesel\n\nbip39.mnemonicToEntropy(mnemonic)\n// =&gt; '0000000000000000000000000000000000000000000000000000000000000001'\n</code></pre></p>","title":"Seed"},{"location":"integration-guides/the-basics/#account-private-key","text":"<p>This is also a 32 byte value, usually represented as a 64 character, uppercase hexadecimal string(0-9A-F). It can either be random (an ad-hoc key) or derived from a seed, as described above. This is what represents control of a specific account on the ledger. If you know or can know the private key of someone's account, you can transact as if you own that account.</p>","title":"Account private key"},{"location":"integration-guides/the-basics/#account-public-key","text":"<p>This is also a 32 byte value, usually represented as a 64 character, uppercase hexadecimal string (0-9A-F). It is derived from an account private key by using the ED25519 curve using Blake2b-512 as the hash function (instead of SHA-512). Usually account public keys will not be passed around in this form, rather the below address is used.</p>","title":"Account public key"},{"location":"integration-guides/the-basics/#account-public-address","text":"<p>This is what you think of as someone's Nano address: it's a string that starts with <code>nano_</code> (previously <code>xrb_</code>), then has 52 characters which are the account public key but encoded with a specific base32 encoding algorithm to prevent human transcription errors by limiting ambiguity between different characters (no <code>O</code> and <code>0</code> for example). Then the final 8 characters are Blake2b-40 checksum of the account public key to aid in discovering typos, also encoded with the same base32 scheme (5 bytes).</p> <p>So for address <code>nano_1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjtwnqposrs</code>:</p>    Prefix Encoded Account Public Key Checksum     <code>nano_</code> <code>1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjt</code> <code>wnqposrs</code>    <p>For basic address validation, the following regular expression can be used: <code>^(nano|xrb)_[13]{1}[13456789abcdefghijkmnopqrstuwxyz]{59}$</code>. Validation of the checksum is also recommended, depending on the integration.</p>  <p>Prefixes: nano_ vs. xrb_</p> <p>As of V19.0 the Nano node only returns <code>nano_</code> addresses in all actions, but prior versions returned <code>xrb_</code> addresses. These prefixes are interchangeable \u2014 everything after the <code>_</code> remains the same. If you have an issue using one or the other prefix with any exchange or service, you can safely switch between <code>nano_</code> and <code>xrb_</code> prefixes as needed \u2014 they both represent the same account owned by your private key or seed.</p>","title":"Account public address"},{"location":"integration-guides/the-basics/#units","text":"<p>Nano can be represented using more than one unit of measurement. While the most common unit is the nanonano, the smallest unit is the rawraw. Below is the formula for converting between rawraw and nanonano.</p>   1 nano = 10^{30} raw   1 nano = 10^{30} raw    <p>Important</p> <ul> <li>All RPC commands expect units to be represented as rawraw. </li> <li>Always keep units in integer rawraw amounts to prevent any floating-point error or unit confusion.</li> <li>Depending on your implementation language, you may require a big number library to perform arithmetic directly on rawraw.</li> <li>See Distribution and Units page for more details on units.</li> <li>Because final balances are recorded rather than transaction amounts, API calls must be done carefully to avoid loss of funds. Incorrect arithmetic or use of fields may change an intended receive to a send to a non-existent address.</li> </ul>","title":"Units"},{"location":"integration-guides/the-basics/#blocks-specifications","text":"<p>All new transactions on the Nano Protocol are communicated via blocks. The account's entire state, including the balance after each transaction, is recorded in every block. Transaction amounts are interpreted as the difference in balance between consecutive blocks.</p> <p>If an account balance decreases, the transaction that caused the decrease is considered a send. Similarly, if an account balance increases, the transaction that caused the increase is considered a receive.</p>  <p>Important</p> <p>Because final balances are recorded rather than transaction amounts, API calls must be done carefully to avoid sending erroneous amounts.</p>","title":"Blocks Specifications"},{"location":"integration-guides/the-basics/#block-format","text":"<p>Because each block contains the current state of the account, the <code>\"type\"</code> of the block is always <code>\"state\"</code>. The following table presents the anatomy of a block, along with the format used within RPC calls for building blocks, and the serialized, binary representation:</p>    Key RPC Format Serialized Description     type string - \"state\"   account string 32 bytes This account's nano_ address   previous 64 hex-char string 32 bytes Previous head block on account; 0 if open block   representative string 32 bytes Representative nano_ address   balance decimal string 16 bytes Resulting balance (in raw)   link - 32 bytes Multipurpose field - see link table below   signature 128 hex-char string 64 bytes ED25519+Blake2b 512-bit signature   work 16 hex-char string 8 bytes Proof of Work Nonce    <p>Depending on the action each transaction intends to perform, the <code>\"link\"</code> field will have a different value for block_create RPC command:</p>    Action RPC Format Description     Change string Must be \"0\"   Send string Destination \"nano_\" address   Receive 64 hex-char string Pairing block's hash (block sending funds)     <p>Note</p> <ul> <li>Any transaction may also simultaneously change the representative. The above description of the \"Change\" action is for creating a block with an explicit representative change where no funds are transferred (balance is not changed).</li> <li>In the completed, signed transaction json, the <code>\"link\"</code> field is always hexadecimal.</li> <li>The first block on an account must be receiving funds (cannot be an explicit representative change). The first block is often referred to as \"opening the account\".</li> </ul>","title":"Block Format"},{"location":"integration-guides/the-basics/#self-signed-blocks","text":"<p>If you choose to implement your own signing, the order of data (in bytes) to hash prior to signing is as follows.</p> <ul> <li>All values are binary representations</li> <li>No ASCII/UTF-8 strings.</li> </ul> <p>Order of data:</p> <ol> <li>block preamble (32-Bytes, value <code>0x6</code>)</li> <li>account (32-Bytes)</li> <li>previous (32-Bytes)</li> <li>representative (32-Bytes)</li> <li>balance (16-Bytes)</li> <li>link (32-Bytes)</li> </ol> <p>The digital signing algorithm (which internally applies another Blake2b hashing) is applied on the resulting digest.</p>  <p>Private/public key usage</p> <p>Make sure that your private key uses the correct partnering public key while signing as using an incorrect public key may leak information about your private key.</p>","title":"Self-Signed Blocks"},{"location":"integration-guides/the-basics/#creating-blocks","text":"<p>For details on how to create individual blocks for sending from, receiving to, opening or changing representatives for an account, please see the Creating Transactions section.</p>","title":"Creating Blocks"},{"location":"integration-guides/the-basics/#uri-and-qr-code-standards","text":"<p>Note: <code>amount</code> values should always be in RAW.</p> <p>Note: Please use <code>nano://</code> for deep links </p>","title":"URI and QR Code Standards"},{"location":"integration-guides/the-basics/#send-to-an-address","text":"<pre><code>nano:nano_&lt;encoded address&gt;[?][amount=&lt;raw amount&gt;][&amp;][label=&lt;label&gt;][&amp;][message=&lt;message&gt;]\n</code></pre> <p>Just the address</p> <pre><code>nano:nano_3wm37qz19zhei7nzscjcopbrbnnachs4p1gnwo5oroi3qonw6inwgoeuufdp\n</code></pre> <p>Address and an amount (as RAW)</p> <pre><code>nano:nano_3wm37qz19zhei7nzscjcopbrbnnachs4p1gnwo5oroi3qonw6inwgoeuufdp?amount=1000\n</code></pre> <p>Address and a label</p> <pre><code>nano:nano_3wm37qz19zhei7nzscjcopbrbnnachs4p1gnwo5oroi3qonw6inwgoeuufdp?label=Developers%20Fund%20Address\n</code></pre> <p>Send to an address with amount, label and message</p> <pre><code>nano:nano_3wm37qz19zhei7nzscjcopbrbnnachs4p1gnwo5oroi3qonw6inwgoeuufdp?amount=10&amp;label=Developers%20Fund&amp;message=Donate%20Now\n</code></pre>","title":"Send to an address"},{"location":"integration-guides/the-basics/#representative-change","text":"<pre><code>nanorep:nano_&lt;encoded address&gt;[?][label=&lt;label&gt;][&amp;][message=&lt;message&gt;]\n</code></pre> <p>Change to representative with label and message</p> <pre><code>nanorep:nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou?label=Official%20Rep%202&amp;message=Thank%20you%20for%20changing%20your%20representative%21\n</code></pre>","title":"Representative change"},{"location":"integration-guides/the-basics/#private-key-import","text":"<pre><code>nanokey:&lt;encoded private key&gt;[?][label=&lt;label&gt;][&amp;][message=&lt;message&gt;]\n</code></pre>","title":"Private Key Import"},{"location":"integration-guides/the-basics/#seed-import","text":"<pre><code>nanoseed:&lt;encoded seed&gt;[?][label=&lt;label&gt;][&amp;][message=&lt;message&gt;][&amp;][lastindex=&lt;index&gt;]\n</code></pre>","title":"Seed Import"},{"location":"integration-guides/the-basics/#process-a-json-blob-block","text":"<p>(to be sent as the <code>block</code> argument to the RPC call <code>process</code>)</p> <pre><code>nanoblock:&lt;blob&gt;\n</code></pre>","title":"Process a JSON blob block"},{"location":"integration-guides/websockets/","text":"<p>Available in version 19.0+ only. When upgrading from version 18 or earlier, the node performs a confirmation height upgrade. During this process, the WebSocket notifications may include confirmations for old blocks. Services must handle duplicate notifications, as well as missed blocks as WebSockets do not provide guaranteed delivery. Reasons for missed blocks include intermittent network issues and internal containers (in the node or clients) reaching capacity.</p>   <p>Multiple notifications for blocks</p> <p>Depending on the node setup and sync status, multiple confirmation notifications for the same block hash may be sent by a single tracking mechanism. In order to prevent potential issues, integrations must track these block hashes externally to the node and prevent any unwanted actions based on multiple notifications.</p>  <p>The Nano node offers notification of confirmed blocks over WebSockets. This offers higher throughput over the HTTP callback, and uses a single ingoing connection instead of an outgoing connection for every block.</p> <p>The HTTP callback is still available and both mechanisms can be used at the same time.</p>","title":"WebSockets"},{"location":"integration-guides/websockets/#example-clients","text":"<p>Sample clients are available:</p> <ul> <li>Node.js: https://github.com/cryptocode/nano-websocket-sample-nodejs</li> <li>Python: https://github.com/guilhermelawless/nano-websocket-sample-py</li> </ul>","title":"Example clients"},{"location":"integration-guides/websockets/#configuration","text":"<p>These configuration options are set in the <code>config-node.toml</code> file.</p> <pre><code>[node.websocket]\n\n# WebSocket server bind address.\n# type:string,ip\naddress = \"::1\"\n\n# Enable or disable WebSocket server.\n# type:bool\nenable = true\n\n# WebSocket server listening port.\n# type:uint16\nport = 7078\n</code></pre> <p>With the above configuration, localhost clients should connect to <code>ws://[::1]:7078</code>.</p>  <p>Configuration for use with Docker</p> <p>Set the WebSocket server bind <code>address</code> to <code>::ffff:0.0.0.0</code> instead, and configure the container to map port 7078 accordingly. Review Managing the Container to ensure the websocket is not exposed externally.</p>","title":"Configuration"},{"location":"integration-guides/websockets/#secure-websockets","text":"<p>Support for <code>wss://</code> is available as of V23.0 by including the <code>NANO_SECURE_RPC</code> cmake cache flag set to <code>ON</code> when building the node and adding the <code>config-tls.toml</code> file with:</p> <pre><code>enable_https=true\nenable_wss=true\nverbose_logging=true\nserver_cert_path=\"/node/server.cert.pem\"\nserver_key_path=\"/node/server.key.pem\"\nserver_key_passphrase=\"test\"\nserver_dh_path=\"/node/dh1024.pem\"\n</code></pre> <p>This configuration is related to HTTPS support for RPC, see here for more details.</p>","title":"Secure WebSockets"},{"location":"integration-guides/websockets/#acknowledgement","text":"<p>All WebSocket actions can optionally request an acknowledgement. The following is an example for the subscribe action.</p> <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"confirmation\",\n  \"ack\": true,\n  \"id\": \"&lt;optional unique id&gt;\"\n}\n</code></pre> <p>If the action succeeds, the following message will be sent back (note that no message ordering is guaranteed):</p> <pre><code>{\n  \"ack\": \"subscribe\",\n  \"time\": \"&lt;milliseconds since epoch&gt;\",\n  \"id\": \"&lt;optional unique id&gt;\"\n}\n</code></pre>","title":"Acknowledgement"},{"location":"integration-guides/websockets/#update","text":"<p>Some subscriptions can be updated without requiring unsubscribing and re-subscribing to the same topic. A typical message is the following:</p> <pre><code>{\n  \"action\": \"update\",\n  \"topic\": \"confirmation\",\n  \"options\": {\n    ...\n  }\n}\n</code></pre> <p>Updatable filter options are mentioned in the examples below.</p>","title":"Update"},{"location":"integration-guides/websockets/#keepalive","text":"<p>This action is available since v20.0</p> <p>Keepalive allows checking the liveliness of the websocket without refreshing it or changing a subscription. Use the format:</p> <pre><code>{\n  \"action\": \"ping\"\n}\n</code></pre> <p>The expected response is:</p> <pre><code>{\n  \"ack\": \"pong\",\n  \"time\": \"&lt;milliseconds since epoch&gt;\"\n}\n</code></pre>","title":"Keepalive"},{"location":"integration-guides/websockets/#subscribeunsubscribe","text":"<p>To receive notifications through the websocket you must subscribe to the specific topic and a standard subscription without filters looks like this:</p> <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"confirmation\"\n}\n</code></pre> <p>Unsubscribing also has the format:</p> <p>To unsubscribe: <pre><code>{\n  \"action\": \"unsubscribe\",\n  \"topic\": \"confirmation\"\n}\n</code></pre></p> <p>Optional Filters</p> <p>Some topics support filters as well. Details of the subscription filter options for each topic are included in examples below.</p>  <p>Note</p> <p>Note that, if empty <code>options</code> are supplied (see examples below), an empty filter will be used and nothing will be broadcasted.</p>","title":"Subscribe/Unsubscribe"},{"location":"integration-guides/websockets/#available-topics","text":"","title":"Available Topics"},{"location":"integration-guides/websockets/#confirmations","text":"<p>Multiple notifications for blocks</p> <p>Depending on the node setup and sync status, multiple confirmation notifications for the same block hash may be sent by a single tracking mechanism. In order to prevent potential issues, integrations must track these block hashes externally to the node and prevent any unwanted actions based on multiple notifications.</p>","title":"Confirmations"},{"location":"integration-guides/websockets/#subscribing","text":"<p>To subscribe to all confirmed blocks:</p> <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"confirmation\"\n}\n</code></pre>","title":"Subscribing"},{"location":"integration-guides/websockets/#filtering-options","text":"","title":"Filtering options"},{"location":"integration-guides/websockets/#confirmation-types","text":"<p>The node classifies block confirmations into the following categories:</p> <ul> <li>Active quorum: a block is confirmed through voting (including <code>block_confirm</code> RPC if block is previously unconfirmed)</li> <li>Active confirmation height: a block which is confirmed as a dependent election from a successor through voting (or by <code>block_confirm</code> RPC if the block is already confirmed)</li> <li>Inactive: a block that is not in active elections is implicitly confirmed by a successor.</li> </ul> <p>By default, the node emits all confirmations to WebSocket clients. However, the following filtering option is available:</p> <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"confirmation\",\n  \"options\": {\n    \"confirmation_type\": \"&lt;type&gt;\"\n  }\n}\n</code></pre> <p>The most common values for <code>confirmation_type</code> are <code>all</code> (default), <code>active</code> and <code>inactive</code>.</p> <p>If more fine-grained filtering is needed, <code>active</code> can be replaced with <code>active_quorum</code> or <code>active_confirmation_height</code> per the definitions above.</p>","title":"Confirmation types"},{"location":"integration-guides/websockets/#accounts","text":"<p>Filters for confirmation can be used to subscribe only to selected accounts. Once filters are given, blocks from accounts that do not match the options are not broadcasted.</p>  <p>Legacy blocks never broadcasted</p> <p>Note that legacy blocks are never broadcasted if filters are given, even if they match the accounts.</p>  <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"confirmation\",\n  \"options\": {\n    \"all_local_accounts\": true,\n    \"accounts\": [\n      \"nano_16c4ush661bbn2hxc6iqrunwoyqt95in4hmw6uw7tk37yfyi77s7dyxaw8ce\",\n      \"nano_3dmtrrws3pocycmbqwawk6xs7446qxa36fcncush4s1pejk16ksbmakis32c\"\n    ]\n  }\n}\n</code></pre> <ul> <li>When <code>all_local_accounts</code> is set to <code>true</code>, blocks that mention accounts in any wallet will be broadcasted.</li> <li><code>accounts</code> is a list of additional accounts to subscribe to. Both prefixes are supported.</li> </ul>  <p>Updating the list of accounts</p> <p>version 21.0+ The list of <code>accounts</code> for which blocks are broadcasted can be updated (see Update): <pre><code>{\n  \"action\": \"update\",\n  \"topic\": \"confirmation\",\n  \"options\": {\n    \"accounts_add\": [\n      ... // additional accounts to track\n    ],\n    \"accounts_del\": [\n      ... // accounts to remove from tracking\n    ]\n  }\n}\n</code></pre> Note that this can result in an empty filter.</p>","title":"Accounts"},{"location":"integration-guides/websockets/#response-options","text":"","title":"Response Options"},{"location":"integration-guides/websockets/#type-field","text":"<p>Confirmations sent through WebSockets, whether filtering is used or not, contains a <code>confirmation_type</code> field with values <code>active_quorum</code>, <code>active_confirmation_height</code> or <code>inactive</code>.</p>","title":"Type field"},{"location":"integration-guides/websockets/#block-content-inclusion","text":"<p>By setting <code>include_block</code> to <code>false</code>, the block content will not be present. Default is <code>true</code>. Because account filtering needs block content to function, setting this flag to false is currently incompatible with account filtering. This restriction may be lifted in future releases.</p> <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"confirmation\",\n  \"options\": {\n    \"include_block\": \"false\",\n  }\n}\n</code></pre>","title":"Block content inclusion"},{"location":"integration-guides/websockets/#election-info","text":"<p>Details about the election leading to the confirmation can be obtained by setting the <code>include_election_info</code> option to true:</p> <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"confirmation\",\n  \"options\": {\n    \"include_election_info\": \"true\"\n  }\n}\n</code></pre> <p>Including the election info option results in the following fields being included:</p> <ul> <li>election <code>duration</code> in milliseconds</li> <li>end of election <code>time</code> as milliseconds since epoch</li> <li>weight <code>tally</code> in raw unit</li> <li>the confirmation <code>request_count</code> (version 20.0+)</li> <li>number of blocks and voters (version 21.0+)</li> </ul>","title":"Election info"},{"location":"integration-guides/websockets/#sample-results","text":"<p>Differences from the HTTP callback</p> <ul> <li>The \"block\" contains JSON instead of an escaped string. This makes parsing easier.</li> <li>The JSON received by the client contains a topic, event time (milliseconds since epoch) and the message itself.</li> <li>Subtype is part of block (if it's a state block)</li> <li>There is no \"is_send\" property since \"subtype\" signifies the intent for state blocks.</li> <li>A confirmation type is added, which can be filtered.</li> </ul>  <pre><code>{\n  \"topic\": \"confirmation\",\n  \"time\": \"1564935350664\",\n  \"message\": {\n    \"account\": \"nano_1tgkjkq9r96zd3pkr7edj8e4qbu3wr3ps6ettzse8hmoa37nurua7faupjhc\",\n    \"amount\": \"15621963968634827029081574961\",\n    \"hash\": \"0E889F83E28152A70E87B92D846CA3D8966F3AEEC65E11B25F7B4E6760C57CA3\",\n    \"confirmation_type\": \"active_quorum\",\n    \"election_info\": {\n      \"duration\": \"546\",\n      \"time\": \"1564935348219\",\n      \"tally\": \"42535295865117307936387010521258262528\",\n      \"request_count\": \"1\", // since V20.0\n      \"blocks\": \"1\", // since V21.0\n      \"voters\": \"52\" // since V21.0\n    },\n    \"block\": {\n      \"type\": \"state\",\n      \"account\": \"nano_1tgkjkq9r96zd3pkr7edj8e4qbu3wr3ps6ettzse8hmoa37nurua7faupjhc\",\n      \"previous\": \"4E9003ABD469D1F58A70518234016797FA654B494A2627B8583052629A91689E\",\n      \"representative\": \"nano_3rw4un6ys57hrb39sy1qx8qy5wukst1iiponztrz9qiz6qqa55kxzx4491or\",\n      \"balance\": \"0\",\n      \"link\": \"3098F4C0D1D8BD889AF078CDFF81E982B8EFA6D6D8FAE954CF0CDC7A256C3F8B\",\n      \"link_as_account\": \"nano_1e6rym1f5p7xj4fh1y8fzy1ym1orxymffp9tx7cey58whakprhwdzuk533th\",\n      \"signature\": \"D5C332587B1A4DEA35B6F03B0A9BEB45C5BBE582060B0252C313CF411F72478721F8E7DA83A779BA5006D571266F32BDE34C1447247F417F8F12101D3ADAF705\",\n      \"work\": \"c950fc037d61e372\",\n      \"subtype\": \"send\"\n    }\n  }\n}\n</code></pre>","title":"Sample Results"},{"location":"integration-guides/websockets/#votes","text":"<p>Experimental, unfinished</p> <p>This subscription is experimental and not all votes are broadcasted. The message format might change in the future.</p>","title":"Votes"},{"location":"integration-guides/websockets/#subscribing_1","text":"<p>To subscribe to all votes notifications:</p> <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"vote\"\n}\n</code></pre>","title":"Subscribing"},{"location":"integration-guides/websockets/#filtering-options_1","text":"<p>The following filtering options can be combined.</p>","title":"Filtering options"},{"location":"integration-guides/websockets/#representatives","text":"<p>Used to subscribe only to votes from selected representatives. Once filters are given, votes from representatives that do not match the options are not broadcasted. If the result is an empty filter (for example, all given accounts are invalid), then the filter is not used. A message is logged in the node logs when this happens.</p> <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"vote\",\n  \"options\": {\n    \"representatives\": [\n      \"nano_16c4ush661bbn2hxc6iqrunwoyqt95in4hmw6uw7tk37yfyi77s7dyxaw8ce\",\n      \"nano_3dmtrrws3pocycmbqwawk6xs7446qxa36fcncush4s1pejk16ksbmakis32c\"\n    ]\n  }\n}\n</code></pre>","title":"Representatives"},{"location":"integration-guides/websockets/#vote-type","text":"<p>Votes are one of three types:</p> <ul> <li><code>replay</code> , if this exact vote had been seen before</li> <li><code>vote</code>, if it is the first time the vote has been seen</li> <li><code>indeterminate</code>, when it cannot be determined due to a lack of an associated election</li> </ul> <p>By default only <code>vote</code> type votes are broadcasted, and the others are filtered. To disable these filters set <code>include_replays</code> to <code>true</code> and/or <code>include_indeterminate</code> to <code>true</code>.</p> <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"vote\",\n  \"options\": {\n    \"include_replays\": \"true\",\n    \"include_indeterminate\": \"true\"\n  }\n}\n</code></pre>","title":"Vote type"},{"location":"integration-guides/websockets/#sample-results_1","text":"<pre><code>{\n  \"topic\": \"vote\",\n  \"time\": \"1554995525343\",\n  \"message\": {\n    \"account\": \"nano_1n5aisgwmq1oibg8c7aerrubboccp3mfcjgm8jaas1fwhxmcndaf4jrt75fy\",\n    \"signature\": \"1950700796914893705657789944906107642480343124305202910152471520450456881722545967829502369630995363643731706156278026749554294222131169148120786048025353\",\n    \"sequence\": \"855471574\",\n    \"timestamp\": \"1554995525138\",\n    \"blocks\": [\n      \"6FB9DE5D7908DEB8A2EA391AEA95041587CBF3420EF8A606F1489FECEE75C869\"\n    ],\n    \"type\": \"replay\" // since V21.0, can be vote/replay/indeterminate\n  }\n}\n</code></pre> <p>NOTE: The <code>timestamp</code> field is a Unix timestamp in milliseconds for non-final votes, and the maximum integer value for the field (<code>18446744073709551615</code>) indicates it is a final vote.</p>","title":"Sample Results"},{"location":"integration-guides/websockets/#stopped-elections","text":"<p>If an election is stopped for any reason, the corresponding block hash is sent on the <code>\"stopped_election\"</code> topic. Reasons for stopping elections include low priority elections being dropped due to processing queue capacity being reached, and forced processing via <code>process</code> RPC when there's a fork.</p>","title":"Stopped elections"},{"location":"integration-guides/websockets/#subscribing_2","text":"<p>To subscribe to all stopped elections notifications:</p> <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"stopped_election\"\n}\n</code></pre>","title":"Subscribing"},{"location":"integration-guides/websockets/#filtering-options_2","text":"<p>No filters are currently available for the <code>stopped_election</code> topic.</p>","title":"Filtering options"},{"location":"integration-guides/websockets/#sample-results_2","text":"<pre><code>{\n  \"topic\": \"stopped_election\",\n  \"time\": \"1560437195533\",\n  \"message\": {\n    \"hash\": \"FA6D344ECAB2C5E1C04E62B2BC6EE072938DD47530AB26E0D5A9A384302FBEB3\"\n  }\n}\n</code></pre>","title":"Sample Results"},{"location":"integration-guides/websockets/#active-difficulty","text":"","title":"Active difficulty"},{"location":"integration-guides/websockets/#subscribing_3","text":"<p>To subscribe to all active difficulty notifications:</p> <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"active_difficulty\"\n}\n</code></pre>","title":"Subscribing"},{"location":"integration-guides/websockets/#filtering-options_3","text":"<p>No filters are currently available for the <code>active_difficulty</code> topic.</p>","title":"Filtering options"},{"location":"integration-guides/websockets/#sample-results_3","text":"<pre><code>{\n  \"topic\": \"active_difficulty\",\n  \"time\": \"1561661736065\",\n  \"message\": {\n    \"multiplier\": \"1.5\",\n    \"network_current\": \"fffffffaaaaaaaab\",\n    \"network_minimum\": \"fffffff800000000\",\n    \"network_receive_current\": \"fffffff07c1f07c2\", // since V21.2\n    \"network_receive_minimum\": \"fffffe0000000000\" // since V21.2\n  }\n}\n</code></pre>","title":"Sample Results"},{"location":"integration-guides/websockets/#proof-of-work","text":"<p>This subscription is available since v20.0</p>","title":"Proof of work"},{"location":"integration-guides/websockets/#subscribing_4","text":"<p>To subscribe to PoW generation notifications:</p> <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"work\"\n}\n</code></pre>","title":"Subscribing"},{"location":"integration-guides/websockets/#filtering-options_4","text":"<p>No filters are currently available for the <code>work</code> topic.</p>","title":"Filtering options"},{"location":"integration-guides/websockets/#sample-results_4","text":"<p>Successful work generation:</p> <pre><code>{\n  \"success\": \"true\",\n  \"reason\": \"\",\n  \"duration\": \"306\",\n  \"request\": {\n    \"hash\": \"3ECE2684044C0EAF2CA6B1C72F11AFC5B5A75C00CFF993FB17B6E75F78ABF175\",\n    \"difficulty\": \"ffffff999999999a\",\n    \"multiplier\": \"10.000000000009095\",\n    \"version\": \"work_1\" // since V21.0\n  },\n  \"result\": {\n    \"source\": \"192.168.1.101:7000\",\n    \"work\": \"4352c6e222703c57\",\n    \"difficulty\": \"ffffffd2ca03b921\",\n    \"multiplier\": \"22.649415016750655\"\n  },\n  \"bad_peers\": \"\"\n}\n</code></pre> <p>Work generation cancelled with one bad peer (unresponsive or provided invalid work):</p> <pre><code>{\n  \"success\": \"false\",\n  \"reason\": \"cancelled\",\n  \"duration\": \"539\",\n  \"request\": {\n    \"hash\": \"3ECE2684044C0EAF2CA6B1C72F11AFC5B5A75C00CFF993FB17B6E75F78ABF175\",\n    \"difficulty\": \"ffffff999999999a\",\n    \"multiplier\": \"10.000000000009095\"\n  },\n  \"bad_peers\": [\n    \"192.168.1.101:7000\"\n  ]\n}\n</code></pre> <p>Notes:</p> <ul> <li>The duration is in milliseconds</li> <li>If work generation fails, the notification is similar to the work cancelled notification, except <code>\"reason\": \"failure\"</code></li> <li>When work generation is done locally it will show <code>\"source\": \"local\"</code></li> </ul>","title":"Sample Results"},{"location":"integration-guides/websockets/#node-telemetry","text":"<p>This subscription is available since v21.0</p>","title":"Node telemetry"},{"location":"integration-guides/websockets/#subscribing_5","text":"<p>To subscribe to telemetry response notifications from other nodes on the network:</p> <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"telemetry\"\n}\n</code></pre>","title":"Subscribing"},{"location":"integration-guides/websockets/#filtering-options_5","text":"<p>No filters are currently available for the <code>telemetry</code> topic.</p>","title":"Filtering options"},{"location":"integration-guides/websockets/#sample-results_5","text":"<p><pre><code>{\n  \"topic\": \"telemetry\",\n  \"time\": \"1594654710305\",\n  \"message\": {\n    \"block_count\": \"51571901\",\n    \"cemented_count\": \"51571901\",\n    \"unchecked_count\": \"0\",\n    \"account_count\": \"1376750\",\n    \"bandwidth_cap\": \"10485760\",\n    \"peer_count\": \"261\",\n    \"protocol_version\": \"18\",\n    \"uptime\": \"1223618\",\n    \"genesis_block\": \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\",\n    \"major_version\": \"21\",\n    \"minor_version\": \"0\",\n    \"patch_version\": \"0\",\n    \"pre_release_version\": \"0\",\n    \"maker\": \"0\",\n    \"timestamp\": \"1594654710521\",\n    \"active_difficulty\": \"ffffffc000000000\",\n    \"node_id\": \"node_3cczh431wuh5gg64jen6a658xewpx7eiyfqn7f8gpdcfp786s7xdb51kr1rp\",\n    \"signature\": \"C9429FBC069F15E9AE552FB80500B4BA0F0CF2E25DD6C6D2018FA1D96DC4353A75E4A86872E54E7B2BFF06526719076E792DA3C83F1B2FD40244804EAC324C00\",\n    \"address\": \"::ffff:139.180.168.194\",\n    \"port\": \"7075\"\n  }\n}\n</code></pre> See the telemetry RPC command which gives more information about the message response.  </p>","title":"Sample Results"},{"location":"integration-guides/websockets/#new-unconfirmed-blocks","text":"<p>This subscription is available since v21.0</p>  <p>These blocks are not confirmed</p> <p>Blocks received through this websocket should not be used for tracking confirmations, as they are unconfirmed and could be replaced by a conflicting block. Read the confirmation tracking guide for more details.</p>","title":"New unconfirmed blocks"},{"location":"integration-guides/websockets/#subscribing_6","text":"<p>To subscribe to node telemetry response notifications:</p> <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"new_unconfirmed_block\"\n}\n</code></pre>","title":"Subscribing"},{"location":"integration-guides/websockets/#filtering-options_6","text":"<p>No filters are currently available for the <code>new_unconfirmed_block</code> topic.</p>","title":"Filtering options"},{"location":"integration-guides/websockets/#sample-results_6","text":"<pre><code>{\n  \"topic\": \"new_unconfirmed_block\",\n  \"time\": \"1587109495082\",\n  \"message\": {\n    \"type\": \"state\",\n    \"account\": \"nano_1unw379kgu1iub1caswn5khfk4b6tzinku8ww7uds9z7nwubj3dgt6yzjpiw\",\n    \"previous\": \"A01B96AFE86DC82FECD13F8C3A4F1AC779DCDAF60166F94F1A2CD3987F4609F0\",\n    \"representative\": \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n    \"balance\": \"2345399869764044123018481994\",\n    \"link\": \"E0049F6D5D5661A714D8928D287285A0105B07720661F8C8B1FC8EE5B15FC067\",\n    \"link_as_account\": \"nano_3r16mxpotom3nwcfj6nf73sada1ide5q63m3z56d5z6gwprozi59ocyuoxc1\",\n    \"signature\": \"7BDD77BE14552263F9AF5130229A3BBB9038EE4B9C29E66D3D58280EF43B7FAF2DBC7070BD9CA39C844B7068E3AF40B04CE1D5CEEEA142C8FE20EE091A3C320E\",\n    \"work\": \"8ebdd4aa0bf1263e\",\n    \"subtype\": \"receive\"\n  }\n}\n</code></pre>","title":"Sample Results"},{"location":"integration-guides/websockets/#bootstrap","text":"<p>This subscription is available since v21.0</p>","title":"Bootstrap"},{"location":"integration-guides/websockets/#subscribing_7","text":"<p>To subscribe to bootstrap attempts start/exit notifications: <pre><code>{\n  \"action\": \"subscribe\",\n  \"topic\": \"bootstrap\"\n}\n</code></pre></p>","title":"Subscribing"},{"location":"integration-guides/websockets/#filtering-options_7","text":"<p>No filters are currently available for the <code>bootstrap</code> topic.</p>","title":"Filtering options"},{"location":"integration-guides/websockets/#sample-results_7","text":"<pre><code>{\n  \"topic\": \"bootstrap\",\n  \"time\": \"1561661740065\",\n  \"message\": {\n    \"reason\": \"started\",\n    \"id\": \"C9FF2347C4DF512A7F6B514CC4A0F79A\",\n    \"mode\": \"legacy\"\n  }\n}\n</code></pre> <pre><code>{\n  \"topic\": \"bootstrap\",\n  \"time\": \"1561661740565\",\n  \"message\": {\n    \"reason\": \"exited\",\n    \"id\": \"C9FF2347C4DF512A7F6B514CC4A0F79A\",\n    \"mode\": \"legacy\",\n    \"total_blocks\": \"1000000\",\n    \"duration\": \"500\"\n  }\n}\n</code></pre> <p>Notes:</p> <ul> <li>The duration is in seconds</li> </ul>","title":"Sample Results"},{"location":"integration-guides/work-generation/","text":"<p>Some sections of this page target node version 21 or higher</p>  <p>Every block published to the network, whether a send, receive or representative change block, requires a small, valid Proof-of-Work to be completed above a minimum difficulty floor (threshold). As of V21 this threshold is different for different block types: send and change blocks require a higher threshold, while receive blocks are lower.</p> <p>This work value is not used in consensus, but instead is one of the first pieces of data used to validate blocks on the network and is a key component of maintaining consistent quality of service on the network.</p>","title":"Work Generation"},{"location":"integration-guides/work-generation/#system-considerations","text":"<p>The following configuration options should be taken into careful consideration when planning work generation resources for services integrating with Nano. These options should be combined to provide the best separation of resources between node participation on network vs. work generation needs.</p>  <p>Representatives should avoid heavy RPC use and work generation</p> <p>Supporting the network by running a representative is recommended for many services, however it is not recommended that voting nodes are used for heavy RPC or work generation activities. Wherever possible, integrations should utilize separate machines for their integration nodes and consensus-producing, voting nodes.</p>","title":"System considerations"},{"location":"integration-guides/work-generation/#cpu-vs-gpu","text":"<p>As GPUs provide faster and more energy efficient work generation than CPUs, and reduce RPC delays during heavy usage periods, they are preferred for any setups able to utilize them. In cases where the node is running on the same machine where work generation is done, GPUs are highly recommended to avoid performance impacts to the node that relying CPU cores can cause.</p>","title":"CPU vs. GPU"},{"location":"integration-guides/work-generation/#choosing-a-machine","text":"<p>Using a separate machine to manage work generation is recommended where possible. The machine running the node should have a minimum of dedicated resources to keep in sync with the network and any potential interruption due to work generation activities should be avoided. Note that this separation introduces latency, so efforts should be done to keep that to a minimum including running machines in the same region or cluster, avoiding routing work requests through external edge networks, etc.</p>","title":"Choosing a machine"},{"location":"integration-guides/work-generation/#software-for-work-generation","text":"<p>Although the node can be configured to generate work directly, there are plans to separate work generation from the node into its own application and process. To help prepare for this future architecturs the preferred setup today is to use the Nano Work Server for work generation.</p>","title":"Software for work generation"},{"location":"integration-guides/work-generation/#number-of-work-peers","text":"<p>To provide a more robust and redundant work generation setup, multiple work peers can be used. Any node configured with multiple peers will make requests serially from the list of work peers until a successful response is received.</p>  <p>Disable local CPU work generation</p> <p>Since using the same CPU resources the node relies on for work generation can cause performance issues, local CPU work generation should be turned off by setting <code>node.work_threads</code> = <code>0</code> when using work peers.</p>","title":"Number of work peers"},{"location":"integration-guides/work-generation/#recommended-configurations","text":"<p>Below are common, recommended configurations for planning work generation needs. Based on the considerations outlined above, the following general rules apply when planning resources:</p> <ul> <li>GPU-based work generation is recommended wherever reasonable</li> <li>Running the Nano Work Server is preferred, regardless of machine or CPU/GPU decisions</li> <li>CPU-based work generation on the same machine the node is running is not recommended</li> </ul>","title":"Recommended configurations"},{"location":"integration-guides/work-generation/#heavy-rpc-regular-work-generation","text":"<p>Services with heavy RPC calls and work generation can benefit from ensuring dedicated resources exist for each process separately. To maximize performance a separate machine running the Nano Work Server with a GPU attached is recommended:</p> <ol> <li>Setup a machine separate from the node with GPU attached</li> <li>Install the Nano Work Server</li> <li>Setup a service to start and monitor the work server process using the GPU option <code>--gpu &lt;PLATFORM:DEVICE&gt;</code> and run <code>nano-work-server --help</code> for additional options and details</li> <li>Configure the machine running the node to allow traffic over TCP from the work generation machine's IP address</li> <li>Add the work machine IP address as a work peer in the node's <code>config-node.toml</code> file</li> </ol>  <p>CPU for lower generation levels</p> <p>For services with heavier RPC usage but less work generation needs excluding the GPU in the above example and relying on the CPU resources of the separate machine is also an option. This can be done by setting <code>node.work_threads</code> to the appropriate thread count for your needs.</p> <p>Make sure to benchmark the machine performance to plan for any potential spikes, as CPU generation is slower.</p>","title":"Heavy RPC, regular work generation"},{"location":"integration-guides/work-generation/#light-rpc-regular-work-generation","text":"<p>Services where RPC usage is lighter but regular work generation is needed could move work generation to the same machine if a GPU is used:</p> <ol> <li>Install the Nano Work Server on the same machine as the node</li> <li>Setup a service to start and monitor the work server process with options for using the GPU - <code>--gpu &lt;PLATFORM:DEVICE:THREADS&gt;</code> is required, run <code>nano-work-server --help</code> for additional options and details</li> <li>Configure the node to prevent local CPU work generation by setting <code>node.work_threads</code> = <code>0</code></li> </ol>  <p>Node work generation option</p> <p>A less preferred alternative to setting up, running and monitoring the Nano Work Server is to use the node itself to generate work. This should only be done with an attached GPU by setting up and enabling OpenCL with <code>opencl.enable</code> = <code>true</code> and adusting <code>opencl.device</code> and <code>opencl.platform</code> to match your setup.</p>","title":"Light RPC, regular work generation"},{"location":"integration-guides/work-generation/#practical-guides","text":"","title":"Practical guides"},{"location":"integration-guides/work-generation/#work-generated-using-the-node-incl-work-peers","text":"graph TD     A{Block signing&lt;br&gt; location?}     A --&gt;|in the node| B[&lt;a href='/commands/rpc-protocol/#block_create'&gt;&lt;b&gt;RPC block_create&lt;/b&gt;&lt;/a&gt;&lt;br&gt;no &lt;i&gt;&amp;quotwork&amp;quot&lt;/i&gt;]     A --&gt;|not in the node| C_1(Create and sign &lt;b&gt;block&lt;/b&gt;)     B --&gt;block((block))     C_1 --&gt;|block| C_2[&lt;a href='/commands/rpc-protocol/#work_generate'&gt;&lt;b&gt;RPC work_generate&lt;/b&gt;&lt;/a&gt;&lt;br&gt;&lt;i&gt;&amp;quotblock&amp;quot: &lt;/i&gt;&lt;b&gt;block&lt;/b&gt;]     C_2 --&gt;|work| C_3(Use &lt;b&gt;work&lt;/b&gt; in &lt;b&gt;block&lt;/b&gt;)     C_3 --&gt;block     block --&gt;D[&lt;a href='/commands/rpc-protocol/#process'&gt;&lt;b&gt;RPC process&lt;/b&gt;&lt;/a&gt;]","title":"Work generated using the node, incl. work peers"},{"location":"integration-guides/work-generation/#work-generated-without-using-the-node","text":"graph TD     P_1(Generate work at&lt;br&gt;&lt;b&gt;&lt;a href='#difficulty-thresholds'&gt;default difficulty thresholds&lt;/a&gt;&lt;/b&gt;)     P_1 --&gt;|work| P_2(Use &lt;b&gt;work&lt;/b&gt; in block)     P_2 --&gt;P_3((block))     P_3 --&gt;P_4[&lt;a href='/commands/rpc-protocol/#process'&gt;&lt;b&gt;RPC process&lt;/b&gt;&lt;/a&gt;]     P_4 --&gt;P_5(&lt;a href='/integration-guides/block-confirmation-tracking/'&gt;Track block confirmation&lt;/a&gt;)","title":"Work generated without using the node"},{"location":"integration-guides/work-generation/#node-configuration","text":"<p>The following configuration options can be changed in <code>config-node.toml</code>. For more information on the location of this file, and general information on the configuration of the node, see the Configuration page.</p>","title":"Node Configuration"},{"location":"integration-guides/work-generation/#openclenable","text":"<p>When GPU acceleration is enabled, the CPU is also used by default</p> <p>Make sure to set <code>node.work_threads</code> to <code>0</code> when using the GPU</p>  <p>To enable GPU acceleration for work generation, set this option to <code>true</code>. The <code>opencl.platform</code> and <code>opencl.device</code> values may need to be changed if you have multiple OpenCL-enabled devices.</p>","title":"opencl.enable"},{"location":"integration-guides/work-generation/#nodework_threads","text":"<p>Recommended value: <code>node.work_threads = 0</code></p>  <p>Determines the number of local CPU threads to used for work generation. While enabled by default, it is recommended to turn off local CPU work generation.</p> <p>Set to <code>0</code> to turn off local CPU work generation.</p>","title":"node.work_threads"},{"location":"integration-guides/work-generation/#nodework_peers","text":"<p>Used when offloading work generation to another node or service. Format must be ipv6, preceded by <code>::ffff:</code> if ipv4. Hostnames are supported since v21. Calls are made to the address:port designated using the standard RPC format work_generate. Example:</p> <pre><code>[node]\nwork_peers = [\n    \"example.work-peer.org:7000\",\n    \"::ffff:192.168.1.25:7076\"\n]\n</code></pre>","title":"node.work_peers"},{"location":"integration-guides/work-generation/#nodemax_work_generate_multiplier","text":"<p>Sets a limit on the generation difficulty. Multiplier is based off the base difficulty threshold. If the node is setup as a work peer itself, requests for work higher than this limit are ignored. Default value is <code>64</code>.</p>","title":"node.max_work_generate_multiplier"},{"location":"integration-guides/work-generation/#benchmarks","text":"","title":"Benchmarks"},{"location":"integration-guides/work-generation/#benchmark-commands","text":"<p>Nano PoW Benchmarking tool</p> <p>The Nano PoW Benchmark tool is the preferred approach for benchmarking OpenCL-enabled hardware such as GPUs.</p> <p>Note that the system must have Java 8 (or above) installed, and that only OpenCL devices are supported by this tool. For testing unsupported processors such as CPUs, consider using the Nano Work Server listed below.</p> <p>Nano Work Server</p> <p>The Nano Work Server also offers built-in support for benchmarking, as shown in this example.</p> <p>Node RPC</p> <ol> <li>Setup and run a node with RPC enabled, control enabled, and the desired configuration including work peers.</li> <li>Use the script from blake2b-pow-bench.</li> </ol> <p>Node local work generation</p> <p>Note that these commands do not use the configuration of the node. Prefer using the alternative above for that purpose, such as changing the number of threads for CPU work generation, or using work peers.</p> <p>CPU with all available threads: <code>nano_node --debug_profile_generate [--difficulty fffffff800000000] [--multiplier 1.0]</code></p> <p>GPU acceleration: <code>nano_node --debug_opencl --platform=0 --device=0 [--difficulty fffffff800000000] [--multiplier 1.0]</code></p> <p>The command will trigger continual work generation, so let it run until a sufficient sample size of times are generated (at least 100 instances). Compute the average of these times which are the number of microseconds it took to generate each sample.</p>","title":"Benchmark commands"},{"location":"integration-guides/work-generation/#example-benchmarks","text":"<p>Below are work generation benchmarks from a variety of consumer-grade CPUs and GPUs. All values are presented in # work/second generated. See the difficulty thresholds section below for details about values required for different epoch versions and block types.</p>    Device Epoch v1All Blocks Epoch v2Send/Change Blocks Epoch v2Receive Blocks     Nvidia GTX 1080 26.24 3.32 203.42   Nvidia Tesla P100 (Google Cloud) 29.28 3.63 220.35   Nvidia RTX 2080 Ti 47.27 5.48 357.23   Nvidia Tesla V100 (Google Cloud) 57.48 7.25 420.33   AMD R9 290 14.57 1.92 94.47   AMD RX Vega 64 30.77 3.79 232.56   AMD Vega 8 @1750MHz 3.45 0.55 23.81   AMD R7-4800U @2.8GHz AVX2 0.64 0.06 3.70   AMD R5-3600 @4.07GHz 0.59 0.09 3.51   AMD R9-3900X @3.97GHz AVX2 1.97 0.26 15.64   Intel Core i7 6700 @3.7GHz AVX2 0.65 0.07 5.25   Intel HD Graphics 530 @1.25GHz 0.47 0.06 3.72","title":"Example benchmarks"},{"location":"integration-guides/work-generation/#work-calculation-details","text":"","title":"Work calculation details"},{"location":"integration-guides/work-generation/#work-equation","text":"<p>The <code>\"work\"</code> field in transactions contains a 64-bit nonce found using the blake2b hash function.  The nonce satisfies the following equations depending on block height:</p> <p>Block Height 1</p> <p>The first block on an account-chain doesn't have a previous (head) block, so the account public key is used (<code>||</code> means concatenation):</p>   blake2b(\\text{nonce} || \\text{public_key}) \\ge \\text{threshold}    <p>Block Height 2 and up</p> <p>Once an account has an existing block the previous block hash is used for all blocks going forward:</p>   blake2b(\\text{nonce} || \\text{prev_block_hash}) \\ge \\text{threshold}   blake2b(\\text{nonce} || \\text{prev_block_hash}) \\ge \\text{threshold}","title":"Work equation"},{"location":"integration-guides/work-generation/#difficulty-thresholds","text":"<p>The mainnet's base difficulty threshold is currently <code>fffffff800000000</code> for all send or change blocks and <code>fffffe0000000000</code> for all receive blocks. These split difficulties were set as part of the network upgrade to increase difficulty completed at the end of August 2020.</p> <p>Previous difficulty levels are outlined below as well for historical reference, but currently the epoch v2 thresholds are required when publishing new blocks to the network:</p>    Epoch version Block Type Difficulty Threshold     1 All <code>ffffffc000000000</code>   2 Send or change <code>fffffff800000000</code>   2 Receive <code>fffffe0000000000</code>    <p>For a block to be valid, its work field must satisfy the above work equations using this value for threshold.</p> <p>Development node wallet behavior</p> <p>The developer wallet included with the node is configured to pre-cache work at the base threshold.</p> <p>Difficulty management for external integrations</p> <p>For services aiming to ensure the highest priority on their transactions, the confirmation of published blocks should be monitored by their integration and work levels compared against active difficulty in a similar fashion to the development wallet mentioned above. If work is left at base difficulty there could be delays in the transactions being processed during heavy network usage times.</p>","title":"Difficulty thresholds"},{"location":"integration-guides/work-generation/#pre-caching","text":"<p>Work for an account can be pre-cached and saved for immediate use on an account as long as it was based on the current frontier block at the time of use. Although this customization must be made externally to the node, it can help level out potential spikes in work generation, especially useful with wallet implementations.</p> <p>To accomplish this, after a block is published for an account (whatever type of block), note the hash of that block and use it in a RPC work_generate call. Note that you may require setting <code>\u201cuse_peers\u201d: \u201ctrue\u201d</code>.</p> <p>Upon receiving a response, store its value in your database for later use for that account. Note that after a new block is published for the account, that value will no longer be a valid work value.</p> <p>Pre-caching when next block type is unknown</p> <p>With V21+ the work difficulty thresholds were split by block type. For many integrations, such as wallet providers, the context of what type of block will be generated next for an account is unknown. The recommendation for these cases is to generate difficulty at the higher threshold of a send/change block to ensure delays are avoided and the best user experience is available when using wallets.</p> <p>Utilizing lower work when batching</p> <p>For services that process receiving their pending transactions in bulk the lower work threshold of receive blocks can be taken advantage of. In doing so, the difficulty is 64x lower than a send/change block.</p>","title":"Pre-caching"},{"location":"integration-guides/work-generation/#difficulty-multiplier","text":"<p>Work difficulty no longer used for prioritization</p> <p>Due to changes in prioritization in V22.0 the relative difficulty of work values is no longer used to prioritize the order of transactions. The below details describe how to calculate this relative difficulty for reference, but it is no longer used by the node.</p>  <p>Relative difficulty, or difficulty multiplier, describes how much more value a PoW has compared to another. This can be obtained with the following expression:</p>   \\frac{(2^{64} - \\text{base_difficulty})}{(2^{64} - \\text{work_difficulty})}   \\frac{(2^{64} - \\text{base_difficulty})}{(2^{64} - \\text{work_difficulty})}   <p>In the inverse direction, in order to get the equivalent difficulty for a certain multiplier, the following expression can be used.</p>   2^{64} - \\frac{2^{64} - \\text{base_difficulty}}{\\text{multiplier}}   2^{64} - \\frac{2^{64} - \\text{base_difficulty}}{\\text{multiplier}}    Code Snippets PythonRustC++   <pre><code>def to_multiplier(difficulty: int, base_difficulty) -&gt; float:\n  return float((1 &lt;&lt; 64) - base_difficulty) / float((1 &lt;&lt; 64) - difficulty)\n\ndef from_multiplier(multiplier: float, base_difficulty: int = NANO_DIFFICULTY) -&gt; int:\n  return int((1 &lt;&lt; 64) - ((1 &lt;&lt; 64) - base_difficulty) / multiplier)\n</code></pre>   <pre><code>fn to_multiplier(difficulty: u64, base_difficulty: u64) -&gt; f64 {\n  (base_difficulty.wrapping_neg() as f64) / (difficulty.wrapping_neg() as f64)\n}\n\nfn from_multiplier(multiplier: f64, base_difficulty: u64) -&gt; u64 {\n  (((base_difficulty.wrapping_neg() as f64) / multiplier) as u64).wrapping_neg()\n}\n</code></pre>   <pre><code>double to_multiplier(uint64_t const difficulty, uint64_t const base_difficulty) {\n  return static_cast&lt;double&gt;(-base_difficulty) / (-difficulty);\n}\n\nuint64_t from_multiplier(double const multiplier, uint64_t const base_difficulty) {\n  return (-static_cast&lt;uint64_t&gt;((-base_difficulty) / multiplier));\n}\n</code></pre>","title":"Difficulty multiplier"},{"location":"living-whitepaper/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>   <p>Contributing to the code</p> <p>If you are interested in helping develop the C++ based Nano node we will help you out! Check out our details on contributing code to the Nano node to get started.</p>  <p>The original whitepaper for Nano was last updated in November 2017, and since then, many improvements to the protocol have been made. The current node implementation has received updates every few months on average since 2018.1 As these updates continue to make the network stronger over time, the static nature of a traditional whitepaper required too much effort to continually update and publish. To ensure information about Nano is kept as up-to-date as possible, a new \"Living Whitepaper\" is being managed through the existing documentation website, which is easier to update and is open source.2</p>","title":"Nano - Digital money for the modern world"},{"location":"living-whitepaper/#protocol-vs-node","text":"<p>The two main sections of the Living Whitepaper are the Protocol Design and Node Implementation. Although they were structured to split the required elements to conform to the protocol (Protocol Design) away from optional improvements built into the current node (Node Implementation), there is some overlap between them. Where possible, these overlaps have been highlighted; however, those interested in contributing to the development of the protocol or building another node implementation should analyze more closely the differences between these to ensure the necessary rules are followed.</p>","title":"Protocol vs. Node"},{"location":"living-whitepaper/#protocol-design","text":"<p>This section contains details of the different messages shared between nodes and common data structures, which allow data to be stored and communicated consistently across the network. Because Nano is decentralized and uses network-wide consensus to validate transactions, participating on the network requires following the message and data designs, otherwise attempts at transacting will be ignored or not properly confirmed by the network.</p> <p>Many changes done to elements outlined here require a change in the protocol version in addition to the node version.</p>","title":"Protocol Design"},{"location":"living-whitepaper/#node-implementation","text":"<p>This section expands into methods and mechanisms built into the current node software that aren't required for compliance with protocol rules, but help provide better efficiency and performance for nodes running on the network. These details could be ignored or implemented in different ways by different types or versions of node software, while still maintaining compatibility with other nodes.</p>  <p>Existing whitepaper sections related to this page: </p> <ul> <li>Introduction</li> <li>Background</li> </ul> <p>Other existing content related to this page:</p> <ul> <li>Nano Overview</li> <li>Representatives and Voting</li> <li>Incentives to run a node</li> </ul>   <ol> <li> <p>Node Releases: https://docs.nano.org/releases/node-releases/ \u21a9</p> </li> <li> <p>Nano Documentation Repository: https://github.com/nanocurrency/nano-docs/ \u21a9</p> </li> </ol>","title":"Node Implementation"},{"location":"node-implementation/blocks/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>","title":"Node Implementation - Blocks"},{"location":"node-implementation/blocks/#block-publishing-and-propagation","text":"<p>Nodes use a modified gossip protocol for message distribution that enables quick distribution of blocks and votes across the network while distributing the load required to propagate messages across multiple nodes rather than each node having to respond to requests from every other node.  Prioritization of messages are focused on the Principal Representative nodes that make up the core consensus mechanism where they receive blocks and votes directly from other nodes and then messages are spread to the rest of the network via gossiping.</p> <p>Blocks are initially broadcast and propagated across the network to different types of nodes based on the blocks status. Some basic rules are listed below:</p> <ul> <li>Nodes initially publish new blocks on the live network to all Principal Representatives they can connect to and a subset of Non Principal Representative nodes.</li> <li>When a node processes a new block that is not a known fork, or is a known fork and the block becomes the new winner on an election, nodes will republish that block to <code>sqrt(peers)</code>.</li> </ul> <p>On average, this gossiping results in blocks arriving multiple times at each node. To help reduce node resource usage, there are duplicate block filters in place to prevent reprocessing of the same blocks.</p>","title":"Block publishing and propagation"},{"location":"node-implementation/components/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>","title":"Node Implementation - Components"},{"location":"node-implementation/components/#overview-diagram","text":"","title":"Overview (diagram)"},{"location":"node-implementation/components/#node","text":"","title":"Node"},{"location":"node-implementation/components/#ledger","text":"","title":"Ledger"},{"location":"node-implementation/components/#node-wallet-dev-only","text":"","title":"Node wallet (dev only)"},{"location":"node-implementation/components/#work-generation","text":"","title":"Work generation"},{"location":"node-implementation/components/#communications","text":"","title":"Communications"},{"location":"node-implementation/components/#rpc-server","text":"","title":"RPC server"},{"location":"node-implementation/components/#ipc","text":"","title":"IPC"},{"location":"node-implementation/components/#cli","text":"","title":"CLI"},{"location":"node-implementation/components/#websockets","text":"<p>Existing whitepaper sections related to this page:</p> <ul> <li>Implementation</li> </ul>","title":"WebSockets"},{"location":"node-implementation/database/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>","title":"Node Implementation - Database"},{"location":"node-implementation/database/#ledger","text":"","title":"Ledger"},{"location":"node-implementation/database/#blocks","text":"","title":"Blocks"},{"location":"node-implementation/database/#pending-blocks","text":"","title":"Pending blocks"},{"location":"node-implementation/database/#accounts","text":"","title":"Accounts"},{"location":"node-implementation/database/#caching","text":"","title":"Caching"},{"location":"node-implementation/database/#block-cementing","text":"","title":"Block cementing"},{"location":"node-implementation/database/#database-backends","text":"","title":"Database backends"},{"location":"node-implementation/database/#lmdb","text":"","title":"LMDB"},{"location":"node-implementation/database/#rocksdb","text":"<p>Existing whitepaper sections related to this page:</p> <ul> <li>Implementation</li> </ul> <p>Other content related to this page:</p> <ul> <li>Ledger Management guide</li> </ul>","title":"RocksDB"},{"location":"node-implementation/introduction/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>  <p>Methods and mechanisms built into the current node software that aren't required for compliance with protocol rules, but help provide better efficiency and performance for nodes running on the network. These details could be ignored or implemented in different ways by other versions of node software.</p>","title":"Node Implementation - Introduction"},{"location":"node-implementation/introduction/#context-and-scope","text":"","title":"Context and scope"},{"location":"node-implementation/introduction/#efficiency-and-security","text":"","title":"Efficiency and security"},{"location":"node-implementation/introduction/#determinism","text":"","title":"Determinism"},{"location":"node-implementation/introduction/#choice-of-language-and-framework","text":"","title":"Choice of language and framework"},{"location":"node-implementation/introduction/#github-links","text":"","title":"Github links"},{"location":"node-implementation/introduction/#contributing","text":"Section Description     Components Breakdown of separate functional areas of the node   Database Storage and cementing mechanisms, backend database options   Voting Vote handling and voting weight management   Work Kernel designs, prioritization processes and rework mechanisms   Contributing How to contribute to the Nano protocol directly     <p>Existing whitepaper sections related to this page:</p> <ul> <li>Implementation</li> </ul>","title":"Contributing"},{"location":"node-implementation/networking/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>","title":"Node Implementation - Networking"},{"location":"node-implementation/networking/#peering-process","text":"<p>Initial peering pulls the IP addresses and domains from the <code>node.preconfigured_peers</code> setting in <code>config-node.toml</code> file. The default domain of <code>peering.nano.org</code> is included, which contains a list of known nodes of high trust, availability and performance - mostly nodes maintained by the Nano Foundation. Due to the peering process defined by the protocol, this initial list is quickly expanded to discovery of the full network via random peer IP sharing on keepalives.</p>","title":"Peering process"},{"location":"node-implementation/voting/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>","title":"Node Implementation - Voting"},{"location":"node-implementation/voting/#vote-rebroadcasting","text":"<p>When a block is processed, Principal Representatives evaluate whether they can generate a vote for the block (dependent blocks already confirmed, etc.). If they can, they generate the vote and publish to all other PRs they are aware of in addition to <code>2*sqrt(peers)</code> of non-PR nodes.  To reduce the load on PRs nodes, they do not republish incoming votes - only Non-PR nodes republish other votes to <code>1/2*sqrt(peers)</code> to ensure enough coverage across the rest of the network.</p> <p>Due to the direct 1:1 relationship between PR nodes, their latency is mostly geographic/network based. For Non-PRs, there is some gossiping via the random distribution, so the number of hops required is what makes up a majority of the latency and the geographic and network latency is less of a factor.</p>","title":"Vote rebroadcasting"},{"location":"node-implementation/voting/#final-votes","text":"<p>Nodes will treat votes differently depending on the value of their timestamp field, which results in two phases of voting. These votes can be considered non-final votes and final votes.</p> <p>Non-final votes are generated when a node is ready to vote on a block and it has not seen enough vote weight to reach quorum. This non-final vote will have the current Unix time stamp in seconds in the timestamp field.</p> <p>Once quorum is reached from votes received, the node will then generate a new final vote for the same block where the timestamps field contains the maximum value possible: <code>18446744073709551615</code>.</p> <p>In the above cases when evaluating quorum for generating a final vote, both non-final votes and final votes can be included. But a node will only consider a block confirmed when quorum is reached with all final votes. At that point the triggering of confirmation notifications, updating of confirmation heights, etc. occurs.</p>","title":"Final votes"},{"location":"node-implementation/voting/#rep-crawler","text":"<p>The rep crawler is a repeating process to help track the online (actively voting) status of representatives. Although typical network activity highly propagates votes to many nodes on the network, there is no guarantee that a given node will receive a recent vote from a particular representative.</p> <p>To help fill these potential gaps in online status, the rep crawler pulls a set of random representatives from its peers list - either 15 entries if the weight of peers is higher than quorum delta, otherwise 50 entries - and sends confirmation requests to them for a randomly chosen block in the local ledger.</p> <p>If the confirmation acknowledgement is returned for those peers they will be considered online and actively voting. This ongoing crawl happens every 7 seconds on the live, beta and test networks, and every 0.1 seconds on the dev network for unit test purposes.</p>","title":"Rep crawler"},{"location":"node-implementation/voting/#online-weight-calculator","text":"<p>Whenever a vote signed by a particular representative is processed by the node, it will consider that representative to be online and included in the online weight calculations. This online status will remain for a period of 5 minutes after the vote processing and the clock will reset back to 5 minutess when additional voting is seen.</p> <p>This online status is counted regardless of where the vote originated from - the rep crawler, live voting activity, etc.</p>","title":"Online weight calculator"},{"location":"node-implementation/voting/#active-transactions-loop","text":"<p>Existing whitepaper sections related to this page:</p> <ul> <li>Implementation</li> </ul> <p>Other content related to this page:</p> <ul> <li>Voting as a Representative guide</li> </ul>","title":"Active transactions loop"},{"location":"node-implementation/work/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>","title":"Node Implementation - Work"},{"location":"node-implementation/work/#opencl-implementation","text":"","title":"OpenCL implementation"},{"location":"node-implementation/work/#prioritization","text":"","title":"Prioritization"},{"location":"node-implementation/work/#work-re-generation","text":"<p>Existing whitepaper sections related to this page:</p> <ul> <li>Implementation</li> </ul> <p>Other content related to this page:</p> <ul> <li>Work Generation guide</li> </ul>","title":"Work re-generation"},{"location":"protocol-design/attack-vectors/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>","title":"Protocol Design - Attack Vectors"},{"location":"protocol-design/attack-vectors/#block-gap-synchronization","text":"Risk Low risk   Impacts Network amplify, denial of service   Description Each block has a link to its previous block.  If a new block arrives where we can't find the previous block, this leaves the node deciding whether it's out of sync or if someone is sending junk data.  If a node is out of sync, synchronizing involves a TCP connection to a node that offers bootstrapping which is much more traffic than sending a single UDP packet containing a block; this is a network amplification attack.   Defense For blocks with no previous link, nodes will wait until a certain threshold of votes have been observed before initiating a connection to a bootstrap node to synchronize.  If a block doesn't receive enough votes it can be assumed to be junk data.","title":"Block gap synchronization"},{"location":"protocol-design/attack-vectors/#transaction-flooding","text":"Risk Moderate   Impacts High I/O   Description Transaction flooding is simply sending as many valid transactions as possible in order to saturate the network.  Usually an attacker will send transactions to other accounts they control so it can be continued indefinitely.   Defense Each block has a small amount of work associated with it, around 5 seconds to generate and 1 microsecond to validate.  This work difference causes an attacker to dedicate a large amount to sustain an attack while wasting a small amount of resources by everyone else.  Nodes that are not full historical nodes are able to prune old transactions from their chain, this clamps the storage usage from this type of attack for almost all users.","title":"Transaction flooding"},{"location":"protocol-design/attack-vectors/#sybil-attack-to-change-ledger-entries","text":"Risk None   Impacts Completely destructive   Description A Sybil attack is a person creating a lot of nodes on the network, possibly thousands on a single machine, in order to get a disproportionate vote on networks where each node gets an equal vote.   Defense The Nano voting system is weighted based on account balance.  Adding extra nodes in to the network will not gain an attacker extra votes.","title":"Sybil attack to change ledger entries"},{"location":"protocol-design/attack-vectors/#penny-spend-attack","text":"Risk Moderate   Impacts Ledger bloat   Description A penny-spend attack is where an attacker spends infinitesimal quantities to a large number of accounts in order to waste the storage resources of nodes.   Defense Blocks publishing is rate-limited by work so this limits accounts to a certain extent.  Nodes that are not full historical nodes can prune accounts below a statistical metric where the account is probably not a valid account.  Finally, Nano is tuned to use minimal permanent storage space so space required to store one additional account is proportional to the size of one block + indexing ~ 96b + 32b ~ 128b.  This equates to 1GB being able to store 8 million penny-spend account.  If nodes want to be aggressive, they can calculate a distribution based on access frequency and delegate infrequently used accounts to slower storage.","title":"Penny-spend attack"},{"location":"protocol-design/attack-vectors/#50-attack","text":"Risk Low   Impacts Completely destructive   Description The metric of consensus for Nano is a balance weighted voting system.  If an attacker is able to gain over 50% of the voting strength, they can cause the network to oscillate their decisions rendering the system useless.  An attacker must have at least some value tied up in the network as a balance which they're willing to forfeit as an expense to performing this type of attack since this attack ruins the integrity of the system.  An attacker is able to lower the amount of balance they must forfeit by preventing good nodes from voting through a network DDOS.   Defense There are multiple levels of defense against this type of attack:<ul><li>Primary defense: voting weight being tied to investment in the system; attempting to flip the ledger would be destructive to the system as a whole which would destroy their investment.</li><li>Secondary defense: cost of this attack is proportional to the market cap of all of Nano.  In proof of work systems, technology can be invented that gives disproportionate control compared to monetary investment and if the attack is successful, this technology could be repurposed after the attack is complete.  With Nano the cost of attacking the system scales with the system and if an attack were to be successful the cost of the attack can't be recovered.</li><li>Tertiary defense: In order to maintain the maximum quorum of voters, the next line of defense is representative voting.  Account holders who are unable to reliably participate in voting for connectivity reasons can name a representative who can vote with the weight of their balance.</li><li>Forks in Nano are never accidental so nodes can make policy decisions on how to interact with forked blocks.  The only time non-attacker accounts are vulnerable to block forks is if they receive a balance from an attacking account.  Accounts wanting to be secure from block forks can wait a little or a lot longer before receiving from an account who generated forks or opt to never receive at all.  Receivers could also generate separate accounts for receiving from dubious accounts in order to protect the rest of their balance.</li><li>A final line of defense is block cementing.  As blocks are confirmed in V19.0+, the node marks the height of the last block confirmed for every account and will refuse the replacement of an already confirmed block. Attempts to fork after previous confirmation of a block will immediately fail.</li>The most sophisticated version of a &gt;50% attack is detailed in the diagram below.  \"Offline\" is the percentage of representatives who have been named but are not online to vote.  \"Stake\" is the amount of investment the attacker is voting with and will be lost if they successfully attack the system.  \"Active\" are representatives that are online and voting according to the protocol.  An attacker can offset the amount of stake they must forfeit by knocking other voters offline via a network denial of service attack.  If this attack can be sustained, the representatives being attacked will become unsynchronized and this is demonstrated by \"Unsynced\".  Finally, an attacker can gain a short burst in relative voting strength by switching their denial of service attack to a new set of representatives while the old set is resynchronizing their ledger, this is demonstrated by \"Attacked\".If an attacker is able to cause Stake &gt; Active by a combination of these circumstances, they would be able to successfully flip votes on the ledger at the expense of their stake.  We can estimate how much this type of attack could cost by examining the market cap of other systems.  If we estimate 33% of representatives are offline or attacked via denial of service, an attacker would need to purchase 33% of the market cap in order to attack the system via voting.Voting attack cost:<ul><li>Euro - M1 in 2014 ~6 trillion, attack amount 2 trillion</li><li>USD - M0 in 2014 ~4 trillion, attack amount 1.2 trillion</li><li>UK pound sterling - M0 in 2007 ~1.5 trillion, attack amount 500 billion</li><li>Bitcoin - Market cap 2014 ~3 billion, attack amount 1 billion</li>","title":"&gt;50% attack"},{"location":"protocol-design/attack-vectors/#bootstrap-poisoning","text":"Risk Low   Impacts New-user denial of service   Description The longer an attacker is able to hold an old private key with a balance, the higher the probability of balances that existed at that time no longer having representatives that are participating in voting because their balances or representatives have transferred to new people.  This means if a node is bootstrapped to an old representation of the network where the attacker has a quorum of voting stake compare to representatives at that point in time, they would be able to oscillate voting decisions to that node.  If this new user wanted to interact with anyone besides the attacking node all of their transactions would be denied since they have different head blocks.  The net result is nodes can waste the time of new nodes in the network by feeding them bad information.   Defense Nodes can be paired with an initial database of accounts and known-good block heads; this is a replacement for downloading the database all the way back to the genesis block.  The closer the download is to be current, the higher the probability of accurately defending against this attack.  In the end this attack is probably no worse than feeding junk data to nodes while bootstrapping since they wouldn't be able to transact with anyone who has a contemporary database.","title":"Bootstrap poisoning"},{"location":"protocol-design/attack-vectors/#other-attacks","text":"<ul> <li>Network Attacks Part 2 - Additional deep-dive into potential attack vectors &amp; mitigations</li> </ul>  <p>Existing whitepaper sections related to this page:</p> <ul> <li>Attack Vectors</li> </ul>","title":"Other attacks"},{"location":"protocol-design/blocks/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>   <p>Key terms in this section</p> <ul> <li> <p>block is the digital encoding of the transaction details.</p> </li> <li> <p>transaction is the action of creating and publishing a block to the network. Depending on the type of transaction, the block will have different requirements.</p> </li> <li> <p>transfer is the completion of both a send transaction and the corresponding receive transaction, representing the movement of funds which can be sent again by the recipient.</p> </li> </ul>","title":"Protocol Design - Blocks"},{"location":"protocol-design/blocks/#state-blocks","text":"<p>All new transactions on the Nano Protocol are communicated via blocks. The account's entire state, including the balance after each transaction, is recorded in every block. Transaction amounts are interpreted as the difference in balance between consecutive blocks.</p>    Key RPC Format Serialized Description     type string - \"state\"   account string 32 bytes This account's nano_ address   previous 64 hex-char string 32 bytes Previous head block on account; 0 if open block   representative string 32 bytes Representative nano_ address   balance decimal string 16 bytes Resulting balance (in raw)   link - 32 bytes Multipurpose field - see link table below   signature 128 hex-char string 64 bytes ED25519+Blake2b 512-bit signature   work 16 hex-char string 8 bytes Proof of Work Nonce    <p>Depending on the action each transaction intends to perform, the <code>\"link\"</code> field will have a different value for block_create RPC command:</p>    Action RPC Format Description     Change string Must be \"0\"   Send string Destination \"nano_\" address   Receive 64 hex-char string Pairing block's hash (block sending funds)    <p>An example of a Nano block: <pre><code>\"block\": {\n  \"type\": \"state\",\n  \"account\": \"nano_3qgmh14nwztqw4wmcdzy4xpqeejey68chx6nciczwn9abji7ihhum9qtpmdr\",\n  \"previous\": \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\",\n  \"representative\": \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\",\n  \"balance\": \"1000000000000000000000\",\n  \"link\": \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\",\n  \"link_as_account\": \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\",\n  \"signature\": \"3BFBA64A775550E6D49DF1EB8EEC2136DCD74F090E2ED658FBD9E80F17CB1C9F9F7BDE2B93D95558EC2F277FFF15FD11E6E2162A1714731B743D1E941FA4560A\",\n  \"work\": \"cab7404f0b5449d0\"\n}\n</code></pre> Note that there is an open proposal to update the state block with version, block height, and subtype fields.</p>","title":"State Blocks"},{"location":"protocol-design/blocks/#account-balance","text":"<p>If an account balance decreases, the transaction that caused the decrease is considered a send. Similarly, if an account balance increases, the transaction that caused the increase is considered a receive.</p>","title":"Account balance"},{"location":"protocol-design/blocks/#block-vs-transaction","text":"<p>In traditional blockchain-based cryptocurrencies like Bitcoin, a block is a group of transactions. In Nano, a block is a single transaction, so the term \u201cblock\u201d and \u201ctransaction\u201d are often used interchangeably. \"Transaction\" specifically refers to the action, while block refers to the digital encoding of the transaction. Transactions are signed by the private-key belonging to the account on which the transaction is performed. </p>","title":"Block vs. transaction"},{"location":"protocol-design/blocks/#creating-transactions","text":"","title":"Creating transactions"},{"location":"protocol-design/blocks/#open-receive","text":"<p>To create an account, an open transaction must be issued first. This is always the first transaction (block height 1) of every account-chain and can be created upon the first receipt of funds. To open an account, you must have sent some funds to it with a send transaction from another account. The funds will be pending on the receiving account. The account field stores the public-key (address) derived from the private-key that is used for signing. The link field contains the hash of the transaction that sent the funds. On account creation, a representative must be chosen to vote on your behalf; this can be changed later. The account can declare itself as its own representative. </p>","title":"Open (Receive)"},{"location":"protocol-design/blocks/#send","text":"<p>A send transaction is one that decreases the sender's account balance by the amount they intend to send. To send from an address, the address must already have been opened with an open (receive) block and therefore will have a balance. The previous field contains the hash of the previous block in the account-chain. The link field contains the account for funds to be sent to. A send block is immutable once confirmed by the network. This means the funds are deducted from the balance of the sender's account and wait as pending until the receiving party signs a block to accept these funds. Pending funds should not be considered awaiting confirmation, as they are as good as spent from the senders account and the sender cannot revoke the transaction.</p>","title":"Send"},{"location":"protocol-design/blocks/#receive","text":"<p>A receive block is very similar to the send block mentioned above, except the account balance is increasing and the link field contains the send block's hash. To complete a transaction, the recipient of sent funds must create a receive block on their own account-chain. The source field references the hash of the associated send transaction. Once this block is created and broadcasted, the account's balance is updated and the funds have officially moved into their account.</p>","title":"Receive"},{"location":"protocol-design/blocks/#change-rep","text":"<p>Nano account holders have the ability to choose a representative to vote on their behalf. This can be done any time (i.e. in an open, send, or receive transaction) by changing the representative field. In conventional PoS systems, the account owner\u2019s node must be  continuosly running to participate in voting. This is impractical for many users, so to remove this requirement Nano was designed to give a representative the power to vote on an account\u2019s behalf. A change transaction is what changes the representative of an account by subtracting the vote weight from the old representative and adding the weight to the new representative. No funds are moved in this transaction, and the representative does not have spending power of the account\u2019s funds.</p>","title":"Change rep"},{"location":"protocol-design/blocks/#epoch-blocks","text":"<p>Since all accounts on the Nano network are asynchronous, an asynchronous form of chain upgrades is needed. Unlike Bitcoin and other traditional blockchains, Nano is not able to say \u201cupgrade at block X\u201d, so Epoch blocks were one of the approaches developed to solve this problem. </p> <p>Epoch blocks are a special block type that can only be generated using a pre-determined private key currently owned by the Nano Foundation. These blocks will be accepted by nodes and be attached as the frontier blocks on each account-chain on the network. This feature was built to allow very limited controls using these blocks: they cannot change account balances or representatives, only upgrade the account versions to allow new block structures. Furthermore, if the majority of the network does not upgrade to a new node version that enables a particular epoch block, then the epoch block will have minimal or no effect. </p> <p>As an account-chain upgrade, Epoch blocks move accounts on the network from Epoch X to Epoch X+1. Any future transactions from an upgraded account will have a minimum version of X+1, which cannot be received by previous node versions.</p> <p>Epoch blocks are unable to change any balances or representatives on accounts. If an epoch block did attempt to change the balance of an account, the node would reject it because the signature would be incorrect, as only the account-chain holder can sign blocks which change balances or representatives.</p>  <p>Existing whitepaper sections related to this page:</p> <ul> <li>Nano Components</li> <li>System Overview</li> </ul> <p>Existing content:</p> <ul> <li>Athena and Epoch v2 Blocks Explained</li> <li>Blocks specifications</li> <li>Creating transactions</li> <li>Nano 101: Epoch Blocks</li> <li>Nano How 2: Blocks and Lattices</li> <li>Network Upgrades details on epoch blocks</li> </ul>","title":"Epoch blocks"},{"location":"protocol-design/distribution-and-units/","text":"<p>Page may be migrating</p> <p>This page may be migrated into another page or section - TBD.</p>   Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>","title":"Protocol Design - Distribution and Units"},{"location":"protocol-design/distribution-and-units/#divisibility","text":"<p>There are three important aspects of divisibility of the supply which are satisfied by the final distributed amount:</p> <ul> <li>The supply needs to be able to be divided up amongst a large number of users with users possibly wanting several accounts.</li> <li>Each account needs to be able to represent an adequate dynamic range of value.</li> <li>The supply should be able to deal with deflation over time as accounts are abandoned.</li> </ul>","title":"Divisibility"},{"location":"protocol-design/distribution-and-units/#distribution","text":"<p>The distribution of Nano (formerly RaiBlocks) was performed through solving manual captchas starting in late 2015 and ending in October 2017. Distribution stopped after ~39% of the Genesis amount was distributed and the rest of the supply was burnt.1</p>  <p>Distribution Accounts</p> <ul> <li>Genesis: <code>nano_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3</code> </li> <li>Landing: <code>nano_13ezf4od79h1tgj9aiu4djzcmmguendtjfuhwfukhuucboua8cpoihmh8byo</code></li> <li>Faucet: <code>nano_35jjmmmh81kydepzeuf9oec8hzkay7msr6yxagzxpcht7thwa5bus5tomgz9</code></li> <li>Burn: <code>nano_1111111111111111111111111111111111111111111111111111hifc8npp</code></li> </ul>  <p>During distribution the Genesis seed was kept in cold storage and funds were moved to the Landing account once per week to minimize the number of live, undistributed blocks. These were subsequently moved into the Faucet account for distribution until the faucet was closed and remaining funds sent to the Burn account.</p>  <p>Total Supply</p> <p>With 2^{128} - 1 raw (i.e. <code>FFFF FFFF FFFF FFFF FFFF FFFF FFFF FFFF</code> HEX raw) in the original Genesis account, upon closing of the faucet and burning of the remaining funds, the total supply which is 100% in circulation ended at ~133,248,297 nano (or more precisely 133248297920938463463374607431768211455 raw). Since then, additional funds have been sent to the known burn address slightly lowering the amount in circulation as a result. This amount can be found using the available_supply RPC.</p>","title":"Distribution"},{"location":"protocol-design/distribution-and-units/#unit-dividers","text":"<p>A 128 bit integer is used to represent account balances. The reference wallet uses nano as a divider.</p>    Name Integer Power Previous     nano (NANO/Nano) 1000000000000000000000000000000 10^{30}10^{30} Mnano   raw 1 10^{0}10^{0} raw    <p>NOTE: 1 raw is the smallest possible division and is used in QR codes as <code>amount</code>, while nano is the current standard division used for human readable elements in most wallets, on exchanges, etc.</p> <p>A set of SI prefixes2 from the base nano has been previously used to make the numbers more accessible and avoid confusion in certain scenarios, but this approach is not common (e.g., micronano or \u03bcnano for 10^{24}10^{24}).</p>   <ol> <li> <p>https://medium.com/nanocurrency/the-nano-faucet-c99e18ae1202 \u21a9</p> </li> <li> <p>The SI prefixes are metric prefixes that were standardized for use in the International System of Units (SI) by the International Bureau of Weights and Measures (BIPM). https://www.bipm.org/en/measurement-units/si-prefixes \u21a9</p> </li> </ol>","title":"Unit Dividers"},{"location":"protocol-design/introduction/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>   <p>Contributing to the protocol</p> <p>If you are interested in helping develop the Nano protocol check out our details on contributing code to the Nano node as a starting point to understanding the current implementation contributions, as these are often tightly coupled with protocol-related changes.</p>","title":"Protocol Design - Introduction"},{"location":"protocol-design/introduction/#living-whitepaper-information","text":"<p>The following sections of the Living Whitepaper outline the design of the Nano protocol. The focus here is providing details of the blueprints for the different messages shared between nodes which allow data to be stored and communicated consistently across the network. The following Protocol Design sections are largely required to participate on the network, while the Node Implementation sections primarily cover functionality that improves performance and security through a specific node design.</p>","title":"Living Whitepaper Information"},{"location":"protocol-design/introduction/#abstract","text":"<p>Since Bitcoin's release in 2009, there has been a growing shift away from traditional, government-backed currencies and financial systems towards modern payments systems based on cryptography, which offer the ability to store and transfer funds in a trustless and secure manner 1. In order to function effectively, a currency must be easily transferable, non-reversible, and have limited or no fees. Unfortunately, increased transaction times, high fees, limited network scalability, and high energy consumption have raised questions about the practicality of Bitcoin as an everyday currency.  Here we introduce Nano, a cryptocurrency with a novel block-lattice architecture where each account has its own blockchain, enabling near instant confirmation, feeless transactions, and scalability that is not artificially limited by protocol-side variables like block sizes or block times. </p>","title":"Abstract"},{"location":"protocol-design/introduction/#introduction","text":"<p>Nano is a low-latency, feeless, scalable, and environmentally friendly cryptocurrency that improves on many of Bitcoin's core properties via unique design decisions. For example, each Nano user has their own blockchain, allowing them to update their chain asynchronously vs other transactions on the network, resulting in fast transactions with minimal overhead. Transactions keep track of account balances rather than transaction amounts, allowing aggressive database pruning without compromising security. Consensus is maintained by Open Representative Voting (ORV), which facilitates irreversible finality (full-settlement). User-selected representative nodes vote on each transaction, and every node independently cements each transaction after seeing enough representative votes to achieve quorum.</p> <p>To date, the Nano network has processed more than 118 million transactions with an unpruned ledger size of only 68GB. Average transaction confirmation time during typical network conditions is 0.2 seconds 2. The production network has seen traffic as high as 161 CPS (80.5-161 TPS), while the beta network has achieved &gt;1800 CPS (900-1800 TPS) 3. Nano\u2019s feeless, split-second transactions make it an ideal cryptocurrency for consumer transactions, while also maintaining decentralization, censorship-resistance, and self-sovereignty.</p>","title":"Introduction"},{"location":"protocol-design/introduction/#background","text":"<p>In 2008, an anonymous individual under the pseudonym Satoshi Nakamoto published a whitepaper outlining the world\u2019s first decentralized cryptocurrency, Bitcoin 1. A key innovation brought about by Bitcoin was the blockchain, a public, immutable and decentralized data-structure which is used as a ledger for the currency\u2019s transactions. Unfortunately, as Bitcoin matured, several issues in the protocol made Bitcoin prohibitive for many applications: </p> <ol> <li> <p>Poor scalability: Each block in the blockchain can store a limited amount of data, which means the system can only process so many transactions per second, making spots in a block a commodity. Median transaction fees fluctuate between a few cents and as high as $34 (currently ~$2.98 as of August 26, 2020) 4.</p> </li> <li> <p>High latency: Average confirmation times fluctuate between 10 and 300 minutes 5. In addition, most Bitcoin services require more than one confirmation before considering a transaction fully-settled 6, which adds additional latency for end users.</p> </li> <li> <p>Power inefficient: The Bitcoin network consumes an estimated 67.26TWh per year (comparable to the power consumption of the Czech Republic), using an average of 570kWh per transaction 7.</p> </li> </ol> <p>Bitcoin, and other cryptocurrencies, function by achieving consensus on their global ledgers in order to verify legitimate transactions while resisting malicious actors. Bitcoin achieves consensus via an economic measure called Proof of Work (PoW). In a PoW system participants compete to compute a number, called a nonce, such that the hash of the entire block is in a target range. This valid range is inversely proportional to the cumulative computation power of the entire Bitcoin network in order to maintain a consistent average time taken to find a valid nonce. The finder of a valid nonce is then allowed to add the block to the blockchain; therefore, those who exhaust more computational resources to compute a nonce play a greater role in the state of the blockchain. PoW provides resistance against a Sybil attack, where an entity behaves as multiple entities to gain additional power in a decentralized system, and also greatly reduces race conditions that inherently exist while accessing a global data-structure. </p> <p>An alternative consensus protocol, Proof of Stake (PoS), was first introduced by Peercoin in 2012 8. In a PoS system, participants vote with a weight equivalent to the amount of wealth they possess in a given cryptocurrency. With this arrangement, those who have a greater financial investment are given more power and are inherently incentivized to maintain the honesty of the system or risk losing their investment. PoS does away with the wasteful computation power competition, only requiring light-weight software running on low power hardware. </p> <p>While Nano uses a weighted-voting system that can be compared to PoS, it differs significantly from traditional PoS. See the Open Representative Voting (ORV) page for more details.</p> <p>The original Nano (RaiBlocks) paper and first beta implementation were published in December, 2014, making it one of the first Directed Acyclic Graph (DAG) based cryptocurrencies 9. Soon after, other DAG cryptocurrencies began to develop, most notably DagCoin, Obyte (formerly Byteball) and IOTA 10, 11, 12. These DAG-based cryptocurrencies broke the blockchain mold, improving system performance and security. Obyte achieves consensus by relying on a \u201cmain-chain\u201d comprised of honest, reputable and user-trusted \u201cwitnesses\u201d, while IOTA achieves consensus via the cumulative PoW of stacked transactions. Nano achieves consensus via a balance-weighted vote on conflicting transactions. This consensus system provides quicker, more deterministic transactions while still maintaining a strong, decentralized system. Nano continues this development and has positioned itself as one of the highest performing cryptocurrencies.</p>  <p>Existing whitepaper sections related to this page:</p> <ul> <li>Introduction</li> <li>Background</li> </ul> <p>Other existing content related to this page:</p> <ul> <li>Nano Overview</li> <li>Representatives and Voting</li> <li>Incentives to run a node</li> </ul>   <ol> <li> <p>S. Nakamoto, \u201cBitcoin: A peer-to-peer electronic cash system,\u201d 2008. [Online]. Available: http://bitcoin.org/bitcoin.pdf \u21a9\u21a9</p> </li> <li> <p>\"Block Confirmation Times\", 2021. [Online]. Available: https://nanoticker.info \u21a9</p> </li> <li> <p>\"Nano Stress Tests - Measuring BPS, CPS, &amp; TPS in the real world\", 2020. [Online]. Available: https://forum.nano.org/t/nano-stress-tests-measuring-bps-cps-tps-in-the-real-world/436 \u21a9</p> </li> <li> <p>\u201cBitcoin median transaction fee historical chart.\u201d [Online]. Available: https://bitinfocharts.com/comparison/bitcoin-median-transaction-fee.html \u21a9</p> </li> <li> <p>\u201cBitcoin average confirmation time.\u201d [Online]. Available: https://www.blockchain.com/charts/avg-confirmation-time \u21a9</p> </li> <li> <p>\"Irreversible Transactions - How many confirmation are required\", 2020. [Online]. Available: https://en.bitcoin.it/wiki/Irreversible_Transactions#How_many_confirmations_are_required \u21a9</p> </li> <li> <p>\"Bitcoin Energy Consumption Index\", 2020. [Online]. Available: https://digiconomist.net/bitcoin-energy-consumption/ \u21a9</p> </li> <li> <p>S. King and S. Nadal, \u201cPpcoin: Peer-to-peer crypto-currency withproof-of-stake\u201d, 2012. [Online]. Available: https://decred.org/research/king2012.pdf \u21a9</p> </li> <li> <p>C. LeMahieu, \u201cRaiblocks distributed ledger network\u201d, 2014. https://content.nano.org/whitepaper/Nano_Whitepaper_en.pdf \u21a9</p> </li> <li> <p>S. D. Lerner, \u201cDagCoin Draft\u201d, 2015. Available: https://bitslog.files.wordpress.com/2015/09/dagcoin-v41.pdf \u21a9</p> </li> <li> <p>A. Churyumov, \u201cByteball: A Decentralized System for Storage and Transfer of Value\u201d, 2016. Available: https://obyte.org/Byteball.pdf \u21a9</p> </li> <li> <p>S. Popov, \u201cThe tangle\u201d, 2016. Available: https://assets.ctfassets.net/r1dr6vzfxhev/2t4uxvsIqk0EUau6g2sw0g/45eae33637ca92f85dd9f4a3a218e1ec/iota1_4_3.pdf \u21a9</p> </li> </ol>","title":"Background"},{"location":"protocol-design/ledger/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>","title":"Protocol Design - Ledger"},{"location":"protocol-design/ledger/#ledger-design","text":"<p>The Nano ledger is the global set of accounts where each account has its own chain of transactions (Figure 1). This is a key design component that falls under the category of replacing a run-time agreement with a design-time agreement - everyone agrees via signature checking that only an account owner can modify the balance and representative on their own chain. This converts a seemingly shared data structure (a global blockchain) into a set of non-shared ones (individual account-chains).</p> <p>Each Nano node determines for itself whether or not to add a valid transaction to its local ledger. This means that there is no waiting for leader-selection as there is in single-blockchain cryptocurrencies like Bitcoin, where a single miner or staker extends the global blockchain with a new block (group of transactions) after solving a Proof-of-Work or being chosen through random selection. The block lattice ledger design removes this bottleneck, drastically decreasing transaction latency, improving decentralization, and simplifying transaction validation. Nano has no concept of block sizes or block times that arbitrarily limit the number of transactions that can be processed - the network will confirm as many transactions as current network conditions allow.</p> <p></p> <p></p> <p>Figure 1.  Each account has its own blockchain containing the account\u2019s balance history. Block 1 must be a receive transaction with it's <code>previous</code> field as constant <code>0</code>.</p>","title":"Ledger design"},{"location":"protocol-design/ledger/#accounts","text":"<p>An account is the public-key portion of a digital signature key-pair. The public-key, also referred to as the address, is shared with other network participants while the private-key is kept secret. A digitally signed packet of data ensures that the contents were approved by the private-key holder. One user may control many accounts, but only one public address may exist per account.</p> <p>Although a special private key can be used to publish epoch transactions to all accounts, the only changes allowed for this special type of transaction are related to upgrading the account version. This means that account owners are the only ones who can modify the balance and representative on their own account chains and thus contention only happens on a per-account basis or in relation to epoch distributions1.</p> <p>For example, if account A attempts a double spend that must be resolved by the network, account B can still make transactions as normal. Transactions are processed independently and asynchronously.</p>","title":"Accounts"},{"location":"protocol-design/ledger/#blocks","text":"<p>In traditional blockchain-based cryptocurrencies like Bitcoin, a block is a group of transactions. In Nano, a block contains the details of a single transaction. There are four different transaction types in Nano (send, receive, change representative and epoch) and in order to transfer funds, two transactions are required - a send transaction and a receive transaction. </p> <p>This difference in transaction structures means the terminology used can have different meanings, so it is worth defining these more explicitly:</p> <ul> <li> <p>block is the digital encoding of the transaction details (Figure 2).</p> </li> <li> <p>transaction is the action of creating and publishing a block to the network. Depending on the type of transaction, the block will have different requirements.</p> </li> <li> <p>transfer is the completion of both a send transaction and the corresponding receive transaction, representing the movement of funds which can be sent again by the recipient.</p> </li> </ul> <p></p> <p><pre><code>\"block\": {\n  \"type\": \"state\",\n  \"account\": \"nano_3qgmh14nwztqw4wmcdzy4xpqeejey68chx6nciczwn9abji7ihhum9qtpmdr\",\n  \"previous\": \"F47B23107E5F34B2CE06F562B5C435DF72A533251CB414C51B2B62A8F63A00E4\",\n  \"representative\": \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\",\n  \"balance\": \"1000000000000000000000\",\n  \"link\": \"19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\",\n  \"link_as_account\": \"nano_18gmu6engqhgtjnppqam181o5nfhj4sdtgyhy36dan3jr9spt84rzwmktafc\",\n  \"signature\": \"3BFBA64A775550E6D49DF1EB8EEC2136DCD74F090E2ED658FBD9E80F17CB1C9F9F7BDE2B93D95558EC2F277FFF15FD11E6E2162A1714731B743D1E941FA4560A\",\n  \"work\": \"cab7404f0b5449d0\"\n}\n</code></pre> Figure 2 - An example Nano block with all required fields</p> <p>Note that there is an open proposal to update the state block with version, block height, and subtype fields.</p>","title":"Blocks"},{"location":"protocol-design/ledger/#why-require-two-transactions-to-transfer","text":"<p>Although send transactions confirmed by the network are irreversible, in order for the recipient to send those funds again they first must complete a receive transaction on their account. This receiving requirement to complete a transfer of funds provides a few benefits:</p> <ul> <li>Sending of funds can be performed while the receiver is offline</li> <li>Account owners are the only ones who are allowed to modify the balance and representative on their accounts</li> <li>Allows account owners to ignore transactions, which prevents continuous sending of tiny amounts in an attempt to prevent use of the account</li> </ul>","title":"Why require two transactions to transfer"},{"location":"protocol-design/ledger/#block-lattice","text":"<p>The lattice structure of the ledger arises from blocks connecting across account-chains. All block types use the <code>previous</code> field to vertically extend the account-chain. In addition, send and receive blocks also use the <code>link</code> field to connect across account-chains. Figure 3 below illustrates the lattice structure at a high level with additional details about blocks available on the blocks page.</p> <p></p> <p></p> <p>As illustrated above, the ledger was initiated with a genesis account containing the genesis balance. The genesis balance was a fixed quantity and can never be increased. The genesis balance was divided across various accounts via send transactions registered on the genesis account-chain. The sum of the balances of all accounts in the ledger will never exceed the initial genesis balance, which gives the system an upper bound on quantity and no ability to increase it.</p>","title":"Block lattice"},{"location":"protocol-design/ledger/#ledger-pruning","text":"<p>Since every transaction in Nano includes a block with the complete current state of an account, the ledger can be significantly pruned. While there are a few exceptions (e.g. pending transactions), Nano's ledger design could be pruned down to one block per account (plus pending), regardless of how many transactions the account has sent or received. Note that pruning is not implemented yet, and exact implementation details are still being tested and discussed. </p> <p>See the official forum or GitHub discussions for more detail.</p>  <p>Existing whitepaper sections related to this page:</p> <ul> <li>Nano Components</li> </ul> <p>Other existing content related to this page:</p> <ul> <li>Block Lattice design</li> <li>Accounts, Keys, Seeds, etc.</li> <li>Looking up to Confirmation Height</li> <li>Ledger Management guide</li> </ul>   <ol> <li> <p>Epoch blocks details, Network Upgrades documentation: https://docs.nano.org/releases/network-upgrades/#epoch-blocks \u21a9</p> </li> </ol>","title":"Ledger pruning"},{"location":"protocol-design/networking/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>","title":"Protocol Design - Networking"},{"location":"protocol-design/networking/#tcp-messages","text":"<p>TCP is used for traffic on the live network and for bulk data transfer on the bootstrap network.</p>","title":"TCP messages"},{"location":"protocol-design/networking/#network-details","text":"Port Type Default Details     7075 TCP Enabled <ul><li>Node bootstrapping server</li><li>Share port configuration in <code>config-node.toml</code>, option <code>node.peering_port</code></li><li>Binds to all adapters; unicast</li><li>Contents: Raw nano protocol stream</li><li>Transmits the ledger to new nodes in bulk</li><li>If blocked other nodes will not be able retrieve the ledger from this node</li></ul>   7076 TCP Disabled <ul><li>RPC server</li><li>Port configurable in <code>config-rpc.toml</code>, option <code>rpc.port</code></li><li>Enable in <code>config-node.toml</code>, option <code>rpc.enable</code> or by starting <code>nano_rpc</code> manually</li><li> Binds to localhost by default for security reasons, configurable in <code>config-rpc.toml</code>, option <code>rpc.address</code>; unicast</li><li>Contents: Unencrypted HTTP requests containing JSON object bodies</li><li>Allows the node to be queried or controlled through HTTP requests</li><li>If blocked the node will not be able to be queried or controlled by HTTP</li><li>WARNING: Exposing this port externally while setting <code>enable_control</code> option to <code>true</code> in configs could expose your wallet, allow the node to be stopped remotely and open your node up to other dangerous activity. See the Node Security page for more details.</li></ul>   7078 TCP Disabled <ul><li>Websocket server</li><li>Port configurable in <code>config-node.toml</code>, option <code>node.websocket.port</code></li><li>Enable in <code>config-node.toml</code>, option <code>node.websocket.enable</code></li><li>Binds to localhost by default due to data throughput potentially being very high; producer-subscriber broadcast</li><li>Contents: Standard websocket frames containing JSON-encoded objects</li><li>See WebSocket Support for details on configuration</li></ul>     <p>UDP disabled by default, deprecated</p> <p>As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined.</p>","title":"Network Details"},{"location":"protocol-design/networking/#ipv4ipv6-addressing","text":"<p>The system is built to only operate on IPv6 and uses IPv4-mapped IPv6 addresses to connect to IPv4 hosts.</p>","title":"IPV4/IPV6 addressing"},{"location":"protocol-design/networking/#node-telemetry","text":"<p>In v21 node telemetry was added to node. This allows peers to communicate telemetry metrics to each other. For specific details on the message format see <code>telemetry_ack</code> in the protocol specification.</p> <p>The nodes are designed to reply to <code>telemetry_req</code> messages. They avoid replying if messages are received from the same peer in quick succession; the minimum time until another reply is 60 seconds on the main network, 15 seconds on beta. This is done to reduce bandwidth.</p> <p>Telemetry messsages bypass the node's bandwidth limiter so that services monitoring the network can still do so during when the network is heavily used. Sending <code>telemetry_req</code> frequently within this exclusion zone could see your ip blacklisted by other peers. The node safely handles this for you by doing ongoing requests periodically and only sent when valid to do so.</p>","title":"Node telemetry"},{"location":"protocol-design/networking/#signing","text":"<p><code>Telemetry_ack</code> messages are signed using ED25519 as follows:</p> <pre><code>ED25519(key = node id public key, message = \"node id || block count || cemented count|| unchecked count || account count || bandwidth capacity || peer count || protocol version || uptime || genesis block hash || major version || minor version || patch version || pre-release version || maker || timestamp since UTC epoch || active difficulty\")\n</code></pre> <p>The node id used in the initial handshake is used for signing. The genesis block hash should be in big endian. The data is signed so that it cannot be forged by a Man In The Middle (MITM) attack.</p>  <p>Peer disconnections</p> <p>Sending incorrectly signed telemetry data to peers will result in being blacklisted as it is seen as malicious, make sure the signing is correct! Verify signatures against known signing done by node by testing local telemetry. Nodes with a different genesis block hash will also be disconnected.</p>","title":"Signing"},{"location":"protocol-design/networking/#peering-process","text":"<p>Initial identification of peers is a node implementation detail, but once a node successfully connects with another using the protocol handshake, the keepalive messages each node sends will include a random selection of the IP addresses of 8 of their peers. Any new IP addresses will be included in the list of potential peers the node will attempt to connect with during bootstrapping, vote request, telemetry and other activities.</p>","title":"Peering process"},{"location":"protocol-design/networking/#live-traffic","text":"","title":"Live traffic"},{"location":"protocol-design/networking/#bootstrap-traffic","text":"<p>Existing whitepaper sections related to this page:</p> <ul> <li>Networking</li> </ul>","title":"Bootstrap traffic"},{"location":"protocol-design/orv-consensus/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>  <p>Existing whitepaper sections: System Overview, Implementation</p> <p>Existing content:</p> <ul> <li>Representatives and voting</li> <li>Representatives</li> <li>PoW for Receive block</li> </ul>","title":"Protocol Design - ORV Consensus"},{"location":"protocol-design/orv-consensus/#overview","text":"<p>In order to protect against double spending and Sybil attacks, Nano uses a unique consensus mechanism called Open Representative Voting (ORV). In ORV, user-selected representative nodes vote on each transaction, and every node (representative or not) independently cements each transaction after seeing enough representative votes to achieve quorum. Since Nano transactions are processed individually and asynchronously, deterministic finality (irreversible, full-settlement) is achieved in a short period of time, typically less than 1 second 1.</p> <p>Due to Nano's block-lattice ledger design, only account owners have the ability to sign blocks into their account-chains, so all forks must be the result of poor programming or malicious intent (double-spend) by the account owner, which means that nodes can easily make policy decisions on how to handle forks without affecting legitimate transactions.</p> <p>Because Nano accounts can freely delegate their voting weight to representatives at any time, the users have more control over who has power with consensus and how decentralized the network is. Also note that delegation of voting weight does not mean staking of any funds - the account delegating can still spend all their available funds at any time without restrictions. This is a key advantage to the design of Open Representative Voting (ORV). With no direct monetary incentive for nodes, this removes emergent centralization forces for longer-term trending toward decentralization of the network.2</p>","title":"Overview"},{"location":"protocol-design/orv-consensus/#open-representative-voting-orv-vs-proof-of-stake-pos","text":"<p>While Nano uses a weighted-voting system (ORV) that can be compared to PoS, it differs from traditional PoS because:</p> <ul> <li> <p>There is not one monolithic blockchain that requires leader selection (i.e. a staker or a miner) to extend</p> </li> <li> <p>Representatives do not create or produce shared blocks (groups of transactions)</p> </li> <li> <p>Each Nano account has its own blockchain that only the owner can modify (representatives can only modify their own blockchain)</p> </li> <li> <p>In Nano, a block is a single transaction (not a group of transactions). Transactions are evaluated individually and asynchronously</p> </li> <li> <p>Users can remotely re-delegate their voting weight to anyone at any time</p> </li> <li> <p>Anyone can be a representative</p> </li> <li> <p>No funds are staked or locked up</p> </li> <li> <p>Representatives do not earn transaction fees</p> </li> <li> <p>Representatives cannot reverse transactions that nodes have locally confirmed (due to block cementing).</p> </li> </ul>","title":"Open Representative Voting (ORV) vs Proof of Stake (PoS)"},{"location":"protocol-design/orv-consensus/#confirmation-speed","text":"<p>Nano's &lt;1 second average transaction confirmation time often leads to questions about how finality can be achieved so quickly vs alternatives like Bitcoin. There are a few factors that contribute to this difference:</p> <ul> <li> <p>The block-lattice ledger design replaces a run-time agreement with a design-time agreement</p> </li> <li> <p>A Nano block is a single transaction that can be processed individually and asynchronously vs other transactions</p> </li> <li> <p>Lightweight Open Representative voting (ORV) and contention minimization</p> </li> </ul> <p>Only account owners have the ability to sign blocks into their account-chains, so all forks must be the result of poor programming or malicious intent (double-spend) by the account owner, which means that nodes can easily make policy decisions on how to handle forks without affecting legitimate transactions. </p> <p>A Bitcoin block is a group of transactions (~1 Megabyte per block) that has to be propagated and processed together, while a Nano block is a single transaction (~200 bytes) that is almost 5000 times smaller than a Bitcoin block. To make a Nano transaction, a node publishes a block to all the Nano Principal Representatives (PRs) 3 at the speed of internet latency (20-100ms typically, depending on location), and those PRs then generate their vote (another small network packet) and publish it to each other and a subset of non-PR peers (who then publish to a subset of their peers). This pattern of communication is known as gossip-about-gossip.</p> <p>Once a node sees enough PR vote responses to cross its local vote weight threshold for confirmation (&gt;50% of online vote weight by default), it considers the transaction to be confirmed and then cements it as irreversible. Since the vast majority of transactions are not forks (no extra voting for fork resolution required), average Nano confirmation times are comparable to typical request-response internet latency.</p>","title":"Confirmation Speed"},{"location":"protocol-design/orv-consensus/#principal-representatives-vs-non-principal-representatives","text":"<p>There are two types of representatives in Nano: Principal Representatives (PR) and non-principal ones. To become a Principal Representative (PR), a Nano account must have at least 0.1% of online voting weight delegated to it, but the only operational difference between the two representative types is that PR votes are rebroadcasted by other nodes who receive the votes, helping the network reach consensus more quickly. </p> <p>This implementation decision was made in part because of the exponential bandwidth cost of allowing every Nano node (potentially thousands) to send a vote to every other Nano node. Outside of PRs, the vast majority of nodes would not be able to meaningfully contribute to consensus due to their low vote weight delegation. The delegated vote weight for most nodes might only be a millionth of a percent vs total online vote weight, while &gt;50% online vote weight is required for a transaction to achieve confirmation. A 0.1% minimum was thus chosen as a compromise.</p>","title":"Principal Representatives vs Non-Principal Representatives"},{"location":"protocol-design/orv-consensus/#incentives-for-participating-in-consensus","text":"<p>Incentives to run a node</p>","title":"Incentives for participating in consensus"},{"location":"protocol-design/orv-consensus/#block-validation","text":"","title":"Block validation"},{"location":"protocol-design/orv-consensus/#voting","text":"","title":"Voting"},{"location":"protocol-design/orv-consensus/#vote-contents","text":"","title":"Vote contents"},{"location":"protocol-design/orv-consensus/#vote-by-hash","text":"","title":"Vote-by-hash"},{"location":"protocol-design/orv-consensus/#fork-handling","text":"","title":"Fork handling"},{"location":"protocol-design/orv-consensus/#fork-resolution","text":"","title":"Fork resolution"},{"location":"protocol-design/orv-consensus/#simple","text":"","title":"Simple"},{"location":"protocol-design/orv-consensus/#complex","text":"","title":"Complex"},{"location":"protocol-design/orv-consensus/#why-pow-for-receive-blocks","text":"","title":"Why PoW for receive blocks"},{"location":"protocol-design/orv-consensus/#quorum","text":"<p>Existing whitepaper sections related to this page:</p> <ul> <li>System Overview</li> <li>Implementation</li> </ul> <p>Existing content related to this page:</p> <ul> <li>Representatives and voting</li> <li>Representatives</li> <li>PoW for Receive block</li> </ul>   <ol> <li> <p>\"Block Confirmation Times\", 2021. [Online]. Available: https://nanoticker.info \u21a9</p> </li> <li> <p>C. LeMahieu, \"Emergent centralization due to economies of scale\", 2020. [Online]. Available: https://medium.com/@clemahieu/emergent-centralization-due-to-economies-of-scale-83cc85a7cbef \u21a9</p> </li> <li> <p>Srayman, \"Community Blog: Proposal for Nano Node Network Optimizations\", 2020. [Online]. Available: https://medium.com/nanocurrency/proposal-for-nano-node-network-optimizations-21003e79cdba \u21a9</p> </li> </ol>","title":"Quorum"},{"location":"protocol-design/resource-usage/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>","title":"Protocol Design - Resource Usage"},{"location":"protocol-design/resource-usage/#network","text":"","title":"Network"},{"location":"protocol-design/resource-usage/#principal-representatives-voting","text":"","title":"Principal Representatives (Voting)"},{"location":"protocol-design/resource-usage/#representatives-voting","text":"","title":"Representatives (Voting)"},{"location":"protocol-design/resource-usage/#observer-non-voting","text":"","title":"Observer (Non-voting)"},{"location":"protocol-design/resource-usage/#disk-io","text":"","title":"Disk I/O"},{"location":"protocol-design/resource-usage/#disk-capacity","text":"","title":"Disk Capacity"},{"location":"protocol-design/resource-usage/#historical","text":"","title":"Historical"},{"location":"protocol-design/resource-usage/#pruned","text":"","title":"Pruned"},{"location":"protocol-design/resource-usage/#cpugpu","text":"","title":"CPU/GPU"},{"location":"protocol-design/resource-usage/#work-generation","text":"","title":"Work Generation"},{"location":"protocol-design/resource-usage/#principal-representative","text":"","title":"Principal Representative"},{"location":"protocol-design/resource-usage/#representative","text":"","title":"Representative"},{"location":"protocol-design/resource-usage/#observer","text":"<p>Existing whitepaper sectionsrelated to this page:</p> <ul> <li>Resource Usage</li> </ul> <p>Existing content related to this page:</p> <ul> <li>Representatives and voting</li> <li>Representatives</li> </ul>","title":"Observer"},{"location":"protocol-design/signing-hashing-and-key-derivation/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>","title":"Protocol Design - Signing, Hashing and Key Derivation"},{"location":"protocol-design/signing-hashing-and-key-derivation/#signing-algorithm-ed25519","text":"<p>ED25519 is an elliptic curve algorithm developed in an academic setting with a focus on security from side channel attack, performance, and fixing a lot of the little annoyances in most elliptic curve systems1. However, it should be noted that instead of using SHA-512 in the key derivation function, Nano uses Blake2b-512.</p>  <p>Incorrect, SHA-512 has been used</p>  <pre><code>0000000000000000000000000000000000000000000000000000000000000000 -&gt;\n3B6A27BCCEB6A42D62A3A8D02A6F0D73653215771DE243A63AC048A18B59DA29\n</code></pre>  <p>Correct, Blake2b-512 digested the seed</p>  <pre><code>0000000000000000000000000000000000000000000000000000000000000000 -&gt;\n19D3D919475DEED4696B5D13018151D1AF88B2BD3BCFF048B45031C1F36D1858\n</code></pre>","title":"Signing algorithm: ED25519"},{"location":"protocol-design/signing-hashing-and-key-derivation/#hashing-algorithm-blake2","text":"<p>Compared to existing cryptocurrencies, the hash algorithm chosen is much less important since it's not being used in a Proof-of-Work context.  In Nano hashing is used purely as a digest algorithm against block contents.  Blake2b-256 is a highly optimized cryptographic hash function whose predecessor was a SHA3 finalist.2</p>","title":"Hashing algorithm: Blake2"},{"location":"protocol-design/signing-hashing-and-key-derivation/#key-derivation-function-argon2","text":"<p>The key derivation function of Argon2d version 1.0 is used for securing the account keys in the reference wallet. 3</p>   <ol> <li> <p>http://ed25519.cr.yp.to/ \u21a9</p> </li> <li> <p>https://blake2.net/ \u21a9</p> </li> <li> <p>https://en.wikipedia.org/wiki/Argon2 \u21a9</p> </li> </ol>","title":"Key derivation function: Argon2"},{"location":"protocol-design/work/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>","title":"Protocol Design - Work"},{"location":"protocol-design/work/#spam-resistance","text":"<p>A spam transaction is loosely defined as a block broadcasted with the intention of saturating the network, reducing its availability for other network participants, or increasing the size of the ledger. In order to make spam attempts more costly, each valid block in Nano requires a proof-of-work solution to be attached to it - similar to the original proposition of Hashcash1. Participants can compute the required work in the order of seconds. The cost of spamming the network then increases linearly with the number of spam transactions, thus reducing the impact of spam transactions from theoretically infinite to a manageable amount.</p> <p>With this design, there is an added step of verifying a block's work. As one could spam invalid blocks (in this context, blocks with invalid work), one key requirement is that the cost of verifying work is negligible.</p>","title":"Spam resistance"},{"location":"protocol-design/work/#work-algorithm-details","text":"<p>Every block includes a work field that must be correctly populated. Valid work is obtained by randomly guessing a nonce such that:</p>   H(\\text{nonce} || \\text{x}) \\ge \\text{threshold}    <p>where HH is an algorithm, usually in the form of a hash function, |||| is the concatenation operator, thresholdthreshold is a parameter of the network that relates to the resources spent to obtain a valid work, and xx is either:</p> <ul> <li>The account's public key, in the case of the first block on the account, or</li> <li>The previous block's hash</li> </ul> <p>The following image illustrates the process by which valid work is obtained for Block 2.</p> <p></p> <p>The work field is not used when signing a block. This design has two consequences:</p> <ol> <li> <p>A block can be securely signed locally, while the work is requested from a remote server, with larger resources. This is especially important for devices with low resources.</p> </li> <li> <p>Since all inputs are known before generating a block, a user can precompute the work for the next block, eliminating any time between creating and broadcasting a block. After a block is broadcasted, the next block's work can be computed immediately, using the last block's hash as input. </p> </li> </ol>","title":"Work algorithm details"},{"location":"protocol-design/work/#choosing-an-algorithm","text":"<p>While the specific algorithm used is an implementation decision, there is a minimal set of requirements that must be met for compatibility with the Nano protocol.</p> <ol> <li>Asymmetry. Verifying work should take the least amount of resources (including time) as possible.</li> <li>Small proof size. Work should take a minimal amount of a block's size compared to the resources required to generate it, in order to reduce overhead and maximize throughput.</li> <li>Amortization-free. The cost of obtaining work for multiple blocks should scale linearly with the number of blocks. This ensures fairness for all participants.</li> <li>Progress-free. Any attempt at obtaining work should follow a stochastic process, with no dependence on previous attempts.</li> </ol> <p>Additional requirements of parameter flexibility, constrained parallelism, and being optimization-free, are desired but not required 2.</p>  <p>Existing whitepaper sections related to this page:</p> <ul> <li>System Overview</li> </ul> <p>Existing content related to this page:</p> <ul> <li>Basics - PoW</li> <li>Dynamic PoW &amp; Prioritization</li> <li>Nano How 4: Proof of Work</li> <li>Work Generation guide</li> </ul>   <ol> <li> <p>A. Back, \u201cHashcash - a denial of service counter-measure,\u201d 2002. [Online]. Available: http://www.hashcash.org/papers/hashcash.pdf \u21a9</p> </li> <li> <p>For more details on these requirements, refer to A. Biryukov, \"Equihash: Asymmetric Proof-of-Work Based on the Generalized Birthday Problem\" 2017. [Online]. Available: https://doi.org/10.5195/ledger.2017.48 \u21a9</p> </li> </ol>","title":"Choosing an algorithm"},{"location":"releases/network-upgrades/","text":"<p>For details on why and how network upgrades happen, along with explanations of the various types, please see the Upgrades overview and Upgrade methods sections further down.</p>  <p>  Technical Update Mailing List Sign up for email updates on the latest protocol/node releases and other technical details including network upgrades. Join Mailing List       </p>","title":"Network Upgrades"},{"location":"releases/network-upgrades/#planned-upgrades","text":"<p>No planned network upgrades</p>","title":"Planned upgrades"},{"location":"releases/network-upgrades/#future-upgrades","text":"","title":"Future upgrades"},{"location":"releases/network-upgrades/#new-pow-algorithm","text":"<p>Purpose</p> <p>To help ensure Quality of Service on the network by providing the ability to generate and validate PoW using a new algorithm. This algorithm will be more memory-hard causing the resources required for generating transactions to shift accordingly.</p> <p>Transition details</p>    Date Type Description     2019-11-21 Node release Nano node V20.0 released to include a new PoW server and epoch block support. These are only foundational updates and will not be configured for activation in this release.   2020-08-29 Epoch blocks Following the postponing of the Nano PoW algorithm in favor or research towards other options, the original epoch v2 blocks intended for the PoW algorithm update were modified for increasing work difficulty using the existing algorithm in V21.0 and subsequently distributed in August 2020. Any future PoW algorithm updates will require a different epoch block version.   TBD Node release Nano node VXX.X released to include new PoW algorithm in PoW server and final changes allowing transition via epoch blocks.   TBD Epoch blocks start Distribution of epoch blocks to each account which upgrades them to use the new PoW algorithm.  Once an account is upgraded nodes will only validate work made using the new PoW algorithm for that account.   TBD Epoch blocks end Distribution of epoch blocks ends after all accounts are upgraded.    <p>Transition Explanation</p> <p>In the above transition plan a phased node upgrade was used to provide support for some foundational elements of the new PoW algorithm while further details of the design are worked out. The epoch block distribution in this transition represents a clean switch from one PoW algorithm to the other - no block in the ledger is allowed to have work generated by either PoW, instead older block versions must use the existing PoW and new block versions must use the newer PoW.</p> <p>This clean switch comes with benefits including reduction in code complexity related to handling two types of PoW generation and validation for the same block versions, and the setting of a clear point in the ledger for each account where work values changed - potentially useful for future snapshoting.</p> <p>To mitigate the impacts of this approach the Nano Foundation will be communicating regularly about progress and monitoring closely the activity on the network to ensure proper conditions exist to finalize the transition.</p>","title":"New PoW algorithm"},{"location":"releases/network-upgrades/#past-upgrades","text":"","title":"Past upgrades"},{"location":"releases/network-upgrades/#final-votes","text":"<p>Purpose</p> <p>To enable the final votes feature which will add a second round of voting to the consensus process as follows: once initial voting weight for an unconfirmed block has reached quorum, nodes will issue final votes by setting the timestamp to the maximum integer possible for that field (18446744073709551615). These final votes will then be required to confirm the block and increase the related accounts confirmation height in the ledger.</p> <p>Because this is a consensus change, a network upgrade is required to activate. As noted above, this will be done using a canary block once at least 80% of voting weight on the network has been upgraded. After the canary block is distributed by the Nano Foundation, the final votes will be used for confirmation going forward.</p> <p>Transition details</p>    Date Type Description     2021-05-14 Node release Nano node V22.0 released with final votes functionality and hardcoded with the block hash for the canary to activate the behavior.   2021-06-03 Canary block Canary block hash <code>B0AA9D2D10837ABD6E96DD9ECD9409F5D6F5B982D26D0E395FF3ECFBC2D139A0</code> distributed to the network which forced nodes upgraded to V22.0+ to only confirm blocks using final votes. Non-final votes reaching quorum are used to trigger when final votes are generated, not used for confirmation.","title":"Final votes"},{"location":"releases/network-upgrades/#increased-work-difficulty","text":"<p>Purpose</p> <p>To help ensure Quality of Service on the network by increasing the difficulty required for send and change blocks to be considered valid by the network (8x compared to current). To help offset the difficulty increase and add incentive to receive blocks so ledger pruning can be done more broadly in the future, the difficulty for receive blocks will simultaneously be reduced (\u215b compared to current).</p> <p>Transition details</p> <p>This upgrade is sometimes referenced as the epoch v2 upgrade and the relate events to complete are as follows:</p>    Date Type Description     2020-06-16 Node release Nano node V21.0 released which includes changes necessary for supporting new difficulty validation and generation   2020-08-18 v2 epoch blocks distribution start Distribution of v2 epoch blocks to all accounts to mark in the ledger the point at which the new work difficulty levels will be required. The start of this distribution process will occur once key services and over 90% of voting weight on the network has upraded.   2020-08-29 v2 epoch blocks distribution end Distribution of epoch blocks ends after all accounts are upgraded.     <p>Nodes de-peered with epoch blocks</p> <p>Due to the nature of the work difficulty changes, any nodes not updated to V21.0+ at the time of epoch block distribution will be de-peered from the network.</p>  <p>Transition Explanation</p> <p>When changing the work difficulty requirements it is necessary to mark a point in each account where the difficulty requirements change so bootstrapping and other behaviors can accurately validate historical blocks. For this reason the epoch blocks are being distributed to act as the marker in the ledger.</p> <p>Once epoch block distribution is started the ability to validate the new work difficulty levels is required. Since node versions before V21.0 do not have the ability to do this, they will be immediately de-peered from the network and cannot participate with the current network until upgraded.</p> <p>To mitigate the impacts of this approach the Nano Foundation will be communicating regularly about progress and monitoring closely the activity on the network. Once acceptable conditions exist to finalize the transition, the distribution will begin. The current plan is to start once over 90% of voting weight has been upgraded, along with all the key services on the network.</p>  Recommended preparations <p>In order to best prepare for the transition to new thresholds, the following items should be considered:</p> <p>Work generation guide The new Work Generation guide was written to help users and integrations leverage their work generation at all times.</p> <p>Work validation The <code>work_validate</code> RPC has multiple changes to the response, one which will break most existing integrations when upgrading to V21, two others that will become useful after upgrade:</p> <ul> <li>If <code>difficulty</code> parameter is not explicitly passed in the request, the existing <code>valid</code> field will not be returned (breaking)</li> <li><code>valid_all</code> is a new return field, <code>true</code> if the work is valid at the current default difficulty (will go up after epoch upgrade)</li> <li><code>valid_receive</code> is a new return field, <code>true</code> if the work is valid at the lower epoch_2 receive difficulty (only useful after the epoch upgrade is finished)</li> <li>If possible, it is best to avoid using this RPC until the epoch upgrade is completed</li> </ul> <p>External work generation nano-work-server has been updated to use the higher threshold (<code>fffffff800000000</code>) by default when not given an explicit <code>difficulty</code>. The <code>work_validate</code> response has the same breaking changes as above.</p> <ul> <li>Prefer directly using the server as a work peer as outlined in the guide. The node always requests the appropriate difficulty threshold when using RPC block_create, or work_generate with the optional <code>block</code>.</li> <li>In cases where requesting directly from a node is not possible, avoid using the lower threshold for receive blocks (<code>fffffe0000000000</code>) until the epoch upgrade is fully complete.</li> </ul> <p>Work generation performance Testing out work generation capabilities on a machine is recommended. Details for how to accomplish this can be found in the Benchmark section of the Work Generation guide.</p> <p>Active difficulty changes The active difficulty RPC command and WebSocket topic allow programatically retrieving the current difficulty from the <code>network_minimum</code> field in the response. When this field changes from <code>ffffffc000000000</code> (pre-epoch v2 difficulty) to <code>fffffff800000000</code> (8x higher epoch v2 difficulty), it indicates the epoch upgrade has begun.</p>  Post-distribution changes <p>Accounts that have already been upgraded can optionally use <code>fffffe0000000000</code> as the lower threshold for receive blocks going forward. The current epoch version of an opened account can be obtained using the <code>account_info</code> RPC, field <code>account_version</code>. Once that field has the value <code>\"2\"</code>, the lower threshold may be used.</p>  <p>Other integration considerations Although it is already recommended as best practice, any integrations not already calling for the frontier block when constructing a transaction should do so. If hashes are being internally tracked and frontier is not requested, the integration could unintentionally cause a fork on the account with distribution of epoch blocks.</p> <p>See Step 1: Get Account Info for the <code>account_info</code> RPC recommendation when creating transactions.</p>","title":"Increased work difficulty"},{"location":"releases/network-upgrades/#state-blocks","text":"<p>Purpose</p> <p>The upgrade to state blocks involved multiple node releases and three different actions on the network including distribution of two canary blocks and the first epoch blocks.</p> <p>Transition Details</p>    Date Type Description     2018-03-23 Node release Nano node V11.0 released with support for state blocks built-in but not yet activated.   2018-04-11 Canary block Parse canary block distributed which enabled parsing of state blocks by nodes so manual generation of that block type would be accepted on the network going forward. This action was performed after a majority of the network upgraded to the required V11.0 to allow confirmations to occur on this new block type.   2018-05-20 Canary block Generation canary block distributed which forced the generation of state blocks by nodes going forward. At this point both state and legacy type (open, send, receive, change) blocks remain valid on the network.   2018-08-20 Node release Nano node V15.0 released with support for epoch blocks built-in and away distribution.   2018-10-25 Epoch v1 block distribution start Distribution of epoch v1 blocks begins.   2019-05-24 Epoch v1 block distribution end Distribution of epoch v1 blocks is finished. All accounts, opened and unopened, are now capped and can no longer attempt inserting legacy style blocks.","title":"State blocks"},{"location":"releases/network-upgrades/#vote-by-hash","text":"<p>Purpose</p> <p>The upgrade to include the vote-by-hash feature was based on a hardcoded timestamp in the node. After this time nodes began voting using this new feature.</p> <p>Transition Details</p>    Date Type Description     2018-08-22 Node release Nano node V15.2 release with support for vote-by-hash but not yet activated.   2018-09-0100:00:00 UTC Hardcoded date Nodes upgraded to V15.2 began voting using the vote-by-hash method. Nodes not yet upgraded would fail to properly interpret votes so were no longer compatible with the network.","title":"Vote-by-Hash"},{"location":"releases/network-upgrades/#upgrades-overview","text":"<p>Nano is a protocol, an agreed upon standard that allows computers to communicate with each other and agree on data. Because of these communication standards, having mechanisms that force all nodes to upgrade certain behaviors at the same time is critical to the consensus and consistency in the network.</p> <p>In most blockchain networks these upgrades can be scheduled to take effect once a particular block height is hit because all nodes operate off a single, synchronous chain. Due to the Nano network being asynchronous this method doesn\u2019t work, so instead we need methods for upgrading accounts asynchronously.</p> <p>There are a couple different options for handling these upgrades and the process is currently managed primarily by the Nano Foundation. The upgrades are tested on the beta network to ensure all components are behaving as expecting before being considered for updating on the main network. If the behavior being changed involves consensus, any manual upgrade actions are triggered once a large majority of nodes and major services have upgraded. </p> <p>Of course many features, including protocol changes, can be activated immediately with a new node release, so these network upgrade scenarios are only reserved for certain cases. Options for providing better agreement on capabilities between nodes has been discussed in this GitHub issue. There is also a discussion around how to potentially automate network upgrade processes in this forum topic: https://forum.nano.org/t/automated-network-upgrades/113.</p>","title":"Upgrades overview"},{"location":"releases/network-upgrades/#upgrade-methods","text":"<p>There are various methods used to upgrade and a brief overview of each, along with benefits and drawbacks, are included below. Upgrades for behaviors contained and activated with a single node release are not included as they are the foundation on top of which these other methods are made capable.</p>","title":"Upgrade methods"},{"location":"releases/network-upgrades/#phased-node-upgrades","text":"<p>A feature is introduced in a node release but not activated for use across the network until a subsequent node release. See State block upgrade details for an example.</p>    Trigger Uses blocks Benefits Drawbacks     Multiple node upgrades No <ul><li>No manual intervention or automated process needed</li><li>Uses already established upgrade process node operators are used to</li></ul> <ul><li>Longer time period to get feature activated</li><li>Cannot be used to perform upgrades needed simultaneously across the network</li></ul>","title":"Phased node upgrades"},{"location":"releases/network-upgrades/#hardcoded-date","text":"<p>A date is hardcoded into the node release to activate a feature or behavior at a specific time in the future. See Vote-by-Hash upgrade details for an example.</p>    Trigger Uses blocks Benefits Drawbacks     Node upgrade + specific date No <ul><li>Simple to implement</li><li>No manual activity required</li></ul> <ul><li>Inability to adjust timing without rushing new release out</li></ul>","title":"Hardcoded date"},{"location":"releases/network-upgrades/#canary-blocks","text":"<p>The hash of a block is hardcoded in the node such that once that hash is seen by the node, it will activate a feature or behavior. Multiple block hashes can be used to perform different phases of a transition. See State blocks upgrade details for an example. </p>    Trigger Uses blocks Benefits Drawbacks     Node upgrade + distribution of one block per transition phase Yes <ul><li>Can be used for multi-phase upgrades, including in combination with other options</li><li>Timing flexible</li></ul> <ul><li>Requires manual intervention</li><li>Adds additional code complexity</li><li>Can cause unchecked table to fill during transition</li></ul>","title":"Canary block(s)"},{"location":"releases/network-upgrades/#epoch-blocks","text":"<p>A special block type that can only be generated using a pre-determined private key. These will be accepted by nodes and be attached as the frontier blocks on each account-chain on the network. This feature was built to allow very limited controls using these blocks: they cannot change account balances or representatives, only upgrade the account versions to allow new block structures. See State block upgrade details for an example.</p>    Trigger Uses blocks Benefits Drawbacks     Node upgrade + distribution of epoch blocks Yes <ul><li>Provides clean upgrade markers directly within the ledger on every account-chain</li><li>Timing flexible</li><li>Ability to asynchronously upgrade block versions even for inactive/unopened account chains</li></ul> <ul><li>Requires manual intervention</li><li>Introduces ability for non-account owner to write to account chain in a highly restricted way</li><li>Adds additional code complexity</li><li>Requires large volume of blocks</li></ul>    <p>The following are the epoch versions and the related accounts which are used to distribute them to the network. For certain protocol implementations these epoch signers need to be included to efficiently determine whether incoming blocks are epoch blocks.</p>    Version Epoch signer account Purpose     1 <code>xrb_3t6k35gi95xu6tergt6p69ck76ogmitsa8mnijtpxm9fkcm736xtoncuohr3</code> (Genesis account) See State blocks   2 <code>nano_3qb6o6i1tkzr6jwr5s7eehfxwg9x6eemitdinbpi7u8bjjwsgqfj4wzser3x</code> (Used for epoch 2 only) See Increased work difficulty","title":"Epoch blocks"},{"location":"releases/node-releases/","text":"<p>Updates to the Nano protocol are done through major node releases, occurring approximately every 1 to 4 months, and necessary patch releases in between. As changes are made to the protocol over time, newer node versions will stop peering with older versions. Details on which versions are actively peering, supported and being developed are included below.</p>  <p>Nano Roadmap on GitHub</p> <p>Head over to the Nano Roadmap GitHub Project for a more dynamic and updated view of the upcoming features under research and implementation for the Nano node and protocol.</p>","title":"Node Releases"},{"location":"releases/node-releases/#current-release","text":"<p>The following release is the latest and only release actively supported by the Nano Foundation. This release and the Active Releases below represent the only node versions that will participate on the main network. More details can be found on the Current Release Notes page.</p>    Node Protocol Database Release Date Release Notes GitHub Links     22.1 18 21 2021-06-11 V22.1 Release - Milestone - Changelog    <p>Builds and Commands</p>    OS Download link/command Verification     Universal Linux https://repo.nano.org/live/binaries/nano-node-V23.0-Linux.tar.bz2 SHA256 Checksum   Debian https://repo.nano.org/live/binaries/nano-node-V23.0-Linux.deb SHA256 Checksum   macOS https://repo.nano.org/live/binaries/nano-node-V23.0-Darwin.dmg SHA256 Checksum   Windows (exe) https://repo.nano.org/live/binaries/nano-node-V23.0-win64.exe SHA256 Checksum   Windows (zip) https://repo.nano.org/live/binaries/nano-node-V23.0-win64.zip SHA256 Checksum   Docker <code>docker pull nanocurrency/nano:V23.0</code>See Pulling the Docker Image for more details.    RHEL/CentOS rpm <code>sudo rpm -iUvh https://repo.nano.org/live/binaries/nanocurrency-23.0-26.el7.x86_64.rpm</code>This installs <code>nano_node</code> and <code>nano_rpc</code> to <code>/usr/bin</code>. SHA256 Checksum","title":"Current Release"},{"location":"releases/node-releases/#next-planned-release","text":"<p>The following release is currently under development. Details about potential features to be included can be found in the Nano Roadmap GitHub Project.</p>    Node Protocol Database Release Date Release Notes GitHub Links     23.0 18 21 2021-01-17 V23.0 Release - Milestone - Changelog     <p>Setup for testing on beta or test network</p> <p>If you are looking to test the latest version of the node ahead of release, check out the Beta Network and Test Network pages for more details about how to get setup on the appropriate network. Typically general integration and node upgrades are tested on the public test network, while new feature and load testing are conducted on the beta network.</p>","title":"Next Planned Release"},{"location":"releases/node-releases/#active-releases","text":"<p>The following releases can still actively participate on the network by peering with other nodes of the same versions. Any nodes running versions earlier than these will no longer peer with the latest and fall out of sync with the network.</p>    Node Protocol Database Release Date Release Notes GitHub Links     22.1 18 21 2021-06-11 V22.1 Release - Milestone - Changelog        Node Protocol Database Release Date Release Notes GitHub Links     22.0 18 21 2021-05-14 V22.0 Release - Milestone - Changelog     Known issue with RocksDB: RPC <code>unchecked_keys</code> not working properly <p>Issue: The RPC <code>unchecked_keys</code> is returning <code>0</code> for all calls when used with the RocksDB backend. This known issue will be resolved in a future release.</p> <p>Solution: Until the issue is resolved any integrations using this command should remain on the existing LMDB backend</p>      Node Protocol Database Release Date Release Notes GitHub Links     21.3 18 18 2021-03-18 V21.3 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>      Node Protocol Database Release Date Release Notes GitHub Links     21.2 18 18 2020-09-03 V21.2 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>      Node Protocol Database Release Date Release Notes GitHub Links     21.1 18 18 2020-07-14 V21.1 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>   Known Issue Windows V21: Crash when using config <code>node.logging.stable_log_filename</code> <p>Setting <code>node.logging.stable_log_filename</code> configuration option to <code>true</code> results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to <code>false</code>.</p>      Node Protocol Database Release Date Release Notes GitHub Links     21.0 18 18 2020-06-16 V21.0 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>   Known Issue Linux V21: 'unable to find libboost' <p>If you are on Linux and unable to get V21.0 to start, <code>unable to find libboost...</code> https://github.com/nanocurrency/nano-node/releases/download/V21.0/nano-node-V21.0.1-Linux.tar.bz2 has been added to the release artifacts with the correct lib rpath. Please use this if you do not wish to move the lib folder into the bin folder after extraction.</p>   Known Issue Windows V21: Crash when using config <code>node.logging.stable_log_filename</code> <p>Setting <code>node.logging.stable_log_filename</code> configuration option to <code>true</code> results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to <code>false</code>.</p>","title":"Active Releases"},{"location":"releases/node-releases/#inactive-releases","text":"<p>The following versions are no longer peered with by nodes running the active versions above and will not work properly communicate if run on the network. The details below are for historical purposes only.</p>  Inactive Releases    Node Protocol Database Release Date Release Notes GitHub Links     20.0 17 15 2019-11-12 V20.0 Release - Milestone - Changelog   19.0 17 14 2019-07-11 V19.0 Release - Milestone - Changelog   18.0 16 13 2019-02-21  Release - Milestone - Changelog   17.1 15  2018-12-21  Release - Milestone - Changelog   17.0 15  2018-12-18  Release - Milestone - Changelog   16.3 14  2018-11-20  Release - Milestone - Changelog   16.2 14  2018-10-11  Release - Milestone - Changelog   16.1 14  2018-09-29  Release - Milestone - Changelog   16.0 14  2018-09-11  Release - Milestone - Changelog   15.2 13  2018-08-22  Release - Milestone - Changelog   15.1 13  2018-08-20  Release - Milestone - Changelog   15.0 13  2018-08-20  Release - Milestone - Changelog   14.2 11  2018-06-21  Release - Changelog   14.1 10  2018-06-11  Release - Changelog   14.0 10  2018-06-11  Release - Changelog   13.0 9  2018-05-10  Release - Changelog   12.1 8  2018-04-21  Release - Changelog   12.0 8  2018-04-18  Release - Changelog   11.2 7  2018-04-04  Release - Changelog   11.1 7  2018-03-29  Release - Changelog   11.0 7  2018-03-23  Release - Changelog   10.0 6  2018-02-15  Release - Changelog    <p>Details for versions older than 10.0 can be found in tagged releases in Github.</p>","title":"Inactive Releases"},{"location":"releases/node-releases/#release-notes","text":"<p>For the latest release notes, see the Current Release Notes page. To reference release notes for older versions see the Previous Release Notes section in the table of contents.</p>","title":"Release Notes"},{"location":"releases/release-v19-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links     19.0 17 14 2019-07-11 V19.0 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>","title":"V19.0"},{"location":"releases/release-v19-0/#upgrade-notices","text":"","title":"Upgrade Notices"},{"location":"releases/release-v19-0/#version-limits","text":"<p>Upgrades from versions V17.1 and to V19 will involve a sequential database upgrade and impact participation of the node on the network. RPC calls will be unavailable for a long period of time amongst other impacts.</p>  <p>Upgrading from V17.1 and earlier to V19.0 not recommended</p> <p>It is highly recommended that nodes are upgraded to V18.0 first or a V18.0 ledger is acquired and used when upgrading to V19.0.</p>","title":"Version Limits"},{"location":"releases/release-v19-0/#confirmation-tracking-considerations","text":"<p>The addition of confirmation height to the database requires the node to validate that blocks are confirmed before the cementing can occur. This process can take up to 24 hours or longer to complete and will cause an increase in some resource usage, particularly CPU and network bandwidth increases, but won\u2019t impact participation on the network. For integrations watching confirmations, the existing HTTP callback, block_confirm RPC and confirmation_history RPC methods will continue to function as before.</p>  <p>Tracking confirmed block hashes required</p> <p>It is required that tracking of confirmed block hashes outside the node is done to avoid potential duplicate notifications from causing issues. This was a requirement in previous versions and remains the same with V19.</p>  <p>For those looking to utilize the new WebSocket confirmation subscription or new <code>confirmed</code> field in <code>block_info</code> RPC responses, special considerations should be taken if implementing before confirmation height updates are complete:</p> <ul> <li>If the websocket confirmation subscription is hooked up to receive all confirmations (default) then notifications for confirmations will come through during the cementing process on a new or upgrading ledger as the confirmation process will occur (it also fires for dependent confirmations)</li> <li>Calls to <code>block_info</code> for blocks in the ledger before the confirmation height upgrade process began may indicate <code>confirmed</code> as <code>false</code> despite their having been confirmed on the network before. This is expected behavior.</li> <li>To validate that confirmation height upgrade is complete, note the <code>count</code> value from the <code>block_count</code> RPC when the upgrade is started and once the <code>cemented</code> amount returned by this call (include the <code>include_cemented</code> option) is higher than that previous count, cementing is in sync.</li> </ul>","title":"Confirmation tracking considerations"},{"location":"releases/release-v19-0/#emitting-nano_-prefixed-addresses","text":"<p>In this and future versions, all addresses emitted from the node will use the <code>nano_</code> prefix. It will continue to support input for <code>xrb_</code> prefixed addresses, but all services must verify they are properly set up to handle the node outputting <code>nano_</code> prefixed addresses.</p>","title":"Emitting nano_ prefixed addresses"},{"location":"releases/release-v19-0/#live-network-over-tcp","text":"<p>Live network traffic over TCP is now available and operates on the same port (7075 for main network, 54000 for beta network) as the bootstrapping network that was already available over TCP. Because of this, existing network setups that are open inbound and outbound on port 7075 for TCP should function as expected with V19.0. For those running production services, it is still recommended to verify network ports setup and consider setting up a new node on internal networks to ensure it can connect and participate on the main network before production nodes are upgraded.</p> <ul> <li>To check for proper connection via TCP, call the <code>peers</code> RPC with <code>peer_details</code> option and look for peers with <code>type</code> = <code>tcp</code>. This command can be used to search for these instances:</li> </ul> <pre><code>curl -sd '{\"action\": \"peers\", \"peer_details\":\"true\"}' [::1]:7076 | grep \"\\\"type\\\": \\\"tcp\\\"\" | wc -l\n</code></pre>","title":"Live network over TCP"},{"location":"releases/release-v19-0/#major-updates","text":"","title":"Major Updates"},{"location":"releases/release-v19-0/#confirmation-height","text":"<p>This provides cementing of blocks by marking on an account the highest block height that has been confirmed for the account. A more detailed look at this feature can be found in the relatd Medium article: https://medium.com/nanocurrency/looking-up-to-confirmation-height-69f0cd2a85bc</p>","title":"Confirmation Height"},{"location":"releases/release-v19-0/#tcp-network","text":"<p>Blocks being published and voted on live are now supported via TCP, with UDP remaining as a fallback. See the TCP callouts in Upgrade Notices above for information about verifying your network setup is ready for the upgrade.</p>","title":"TCP Network"},{"location":"releases/release-v19-0/#dynamic-proof-of-work-and-prioritization","text":"<p>With the ability to track work difficulty seen on the network and have the node wallet produce more difficult work for local blocks, this feature allows users to get their transactions prioritized for processing. More details about this feature can be found in the Medium article: https://medium.com/nanocurrency/dynamic-proof-of-work-prioritization-4618b78c5be9</p>","title":"Dynamic Proof-of-Work and Prioritization"},{"location":"releases/release-v19-0/#rpc-process-options","text":"<p>By default the RPC server will run in the node process, but can be configured to run as a child process or completely out of process (currently limited to running on the same computer), depending on your needs. See Running Nano as a service for more details.</p>","title":"RPC Process Options"},{"location":"releases/release-v19-0/#rpccli-updates","text":"<p>No Breaking Changes</p> <p>There were no breaking changes made in V19 for any RPC or CLI commands. It is recommended any integrations run tests against V19 before upgrading production nodes, and also explore the various changes below to improve their setups.</p>  <ul> <li>NEW <code>unopened</code> RPC provides the total pending balance for unopened accounts</li> <li>NEW <code>active_difficulty</code> RPC allows tracking of the difficulty levels seen on the network which can be used to target higher levels of PoW to prioritize transactions</li> <li>Using <code>--diagnostics</code> CLI option now validates config and generates default one if it doesn\u2019t exist</li> <li><code>wallet_create</code> and <code>wallet_change_seed</code> RPCs accept seed and return restored accounts for easier seed management</li> <li>The <code>pending</code> RPC can now optionally be using <code>sorting</code> by amount</li> <li>Difficulty and multiplier options available in <code>work_generate</code> and <code>work_validate</code> RPCs for easier management of dynamic work levels on blocks</li> <li>State blocks returned by <code>block_info</code>/<code>blocks_info</code> contain <code>subtype</code> for easier identification of block types</li> <li>Json literals supported for block input (<code>process</code>, <code>sign</code>, and <code>block_hash</code>) and output (<code>block_create</code>, <code>block_info</code>, <code>blocks_info</code>, <code>confirmation_info</code>, <code>unchecked_get</code> and <code>unchecked_keys</code>) on RPC calls</li> <li>A new optional argument <code>include_not_found</code> in <code>blocks_info</code> allows requests which contain invalid block hashes to get results that include an array of <code>blocks_not_found</code> instead of just an error</li> <li>The <code>account_history</code> RPC now:<ul> <li>Accepts <code>account_filter</code> to allow filtering of results to a specific account or set of accounts</li> <li>Allows <code>reverse</code> option to return details starting from the head block on the account</li> <li>Block <code>height</code> on account chain now included in response</li> </ul> </li> <li>The <code>accounts_pending</code> RPC allows for sorting by amounts</li> <li>For <code>ledger</code> and <code>unopened</code> RPCs a new optional threshold value can be used to limit results by balance</li> <li>A new <code>include_cemented</code> option in <code>block_count</code> RPC adds return of the cemented blocks in the ledger - cemented blocks are ones that have been confirmed and are at or below the confirmation height set on the account</li> </ul>","title":"RPC/CLI Updates"},{"location":"releases/release-v19-0/#node-configuration-updates","text":"<p>Config.json </p> <ul> <li>New <code>active_elections_size</code> will limit the number of active elections allowed before dropping occurs. Default is 50,000 but higher settings are recommended for nodes provisioned with 8GB RAM or more</li> <li>New <code>bandwidth_limit</code> will limit the outbound voting traffic to 5MB/s by default</li> <li>New <code>confirmation_history_size</code> provides an adjustable limit on the batching of confirmations return in the confirmation_history RPC. Default 2048 which will support up to ~56 confirmations/sec before confirmations may be missed. The new websocket setup with confirmation subscription is recommended over use of the confirmation_history RPC.</li> </ul>  <p>Advanced Configuration</p> <p>New <code>vote_generator_delay</code> allows for tuning performance of bundling votes by hash before sending.</p>  <p>Rpc_config.json This new file was split out from the config.json file as the RPC server can now be run in its own process. Entries previously existing in config.json were migrated over and new values added. One setting to note: the <code>max_request_size</code> parameter is defaulted to 32MB - if your service is submitting data amounts larger than this you will need to adjust accordingly.</p> <p>Automated config backups Backups of config files will be made prior to upgrades. During upgrades from V18 to V19 you will see a backup created even for the new rpc_config.json - this is expected behavior given the upgrade process.</p>","title":"Node Configuration Updates"},{"location":"releases/release-v19-0/#developerdebug-options","text":"<ul> <li>New launch flag for tuning block processor: <code>--block_processor_batch_size</code>, <code>--block_processor_full_size</code> and <code>--block_processor_verification_size</code></li> <li>New launch flags for disabling TCP real-time network and UDP for debugging connectivity</li> <li>Expanded <code>stats</code> RPC contains additional values related to confirmation height</li> </ul>","title":"Developer/Debug Options"},{"location":"releases/release-v19-0/#deprecations","text":"<p>The following RPC calls are being deprecated and will be removed in a future release:</p> <ul> <li>history</li> <li>payment_begin</li> <li>payment_end</li> <li>payment_init</li> <li>payment_wait</li> </ul>","title":"Deprecations"},{"location":"releases/release-v19-0/#other-notices","text":"<p>New nanorep QR code standard A new nanorep QR code standard for easier management of representative changes was added for wallets and other services to consider supporting.</p> <p>New recommended block explorer The Nano Foundation supports a new recommended block explorer - NanoCrawler. We encourage services and exchanges linking out to block explorers to consider using NanoCrawler going forward as it provides solid design and performance for referencing blocks, accounts and more.</p>","title":"Other Notices"},{"location":"releases/release-v20-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links     20.0 17 15 2019-11-12 V20.0 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>   Known Issue V20: Peers stake reporting inaccurate (Windows only) <ul> <li> <p>Issue: For Windows builds only, when calling confirmation_quorum RPC the <code>peers_stake_total</code> amount returned may be inaccurate, returning a range from the correct full peer stake amount down to 0.</p> </li> <li> <p>Solution: A solution to the issue has been found and as this is a reporting issue only, the fix will be included in the next released version. For those manually building the node, patching the fix pull request onto the V20.0 tag can resolve the issue now. Or alternatively, building on the V20.0 tag with <code>RelWithDebInfo</code> option, see Build Instructions for Windows.</p> </li> </ul>","title":"V20.0"},{"location":"releases/release-v20-0/#upgrade-notices","text":"<p>Only node V18.0 and higher supported</p> <p>With V20.0 only nodes V18.0 and higher will be peered with on the network (see Active Releases above). This means any nodes running versions earlier than 18.0 will begin to lose peers and fall out of sync over time once upgrades to V20.0 begin.</p> <p>If you are running a node version earlier than V18.0, please update as soon as possible to avoid disruption.</p>","title":"Upgrade Notices"},{"location":"releases/release-v20-0/#database-upgrades","text":"<p>Upgrade requires downtime, read carefully</p> <p>Please review the following details carefully as the automatic database upgrade process will cause downtime for the node.</p>  <p>This version brings some new optimizations to the ledger which require database upgrades to be performed. Due to the nature of upgrades, the following impacts will occur:</p> <ul> <li>Upgrade times depend on specs of the node host but are expected to be between 5 and 15 minutes for most cases.</li> <li>Upgrade activities are synchronous which means the node will not be participating on the network and RPC requests won\u2019t be available during the upgrade process - services requiring uptime should plan to swap out their ledger for one upgraded by a separate node or download from a trusted source.</li> <li>Ledger size will grow by up to 50% during this process - please ensure you have free disk space of 3x the current ledger before starting the upgrade (currently ~16GB on the main network).</li> <li>A database vacuum will be automatically performed after the upgrade to reclaim disk space, which can be verified complete in the logs.</li> <li>Doing proper ledger backups is recommended before starting this process. Ensure you have enough disk space to allow for any ledger backups plus the additional disk space required for the database upgrade mentioned above. A new config option in V20, <code>node.backup_before_upgrade</code>, will allow for automated ledger backups between future versions.</li> </ul>","title":"Database upgrades"},{"location":"releases/release-v20-0/#new-toml-config-files","text":"<p>A new setup in V20.0 uses internal default config values, so config files are only needed for non-default settings. During upgrade new .toml format files will be created for the config.json and rpc_config.json files if they contain non-default values. Before migration <code>config_backup_toml_migration.json</code> and <code>rpc_config_backup_toml_migration.json</code> files will be created for backup.</p> <p>The following commands can be used to generated commented out, complete config files for review:</p>  <p>Only set non-default values in .toml files</p> <p>It is not recommended to uncomment all values in the .toml file output from commands below. Instead, only uncomment or insert non-default values to ensure any default value changes in future release are only overridden when needed.</p>     Name Description Generated with     <code>config-node.toml</code> Node configuration <code>nano_node --generate_config node</code>   <code>config-rpc.toml</code> RPC configuration <code>nano_node --generate_config rpc</code>   <code>config-nano-pow-server.toml</code> Proof of work server configuration <code>nano_pow_server --generate_config</code>   <code>config-qtwallet.toml</code> Qt developer wallet configuration This file is maintained by the Qt wallet    <p>More details on the new configuration setup can be found in the node Configuration documentation.</p>","title":"New .toml config files"},{"location":"releases/release-v20-0/#networking-changes","text":"<p>Improvements to default network setup in this version requires less setup from node operators, specifically around port forwarding. Although new setups will immediately benefit, any existing systems that have already setup port forwarding may be impacted by these changes. For those systems, we recommend validating your network setup allows proper peering with a test V20.0 node prior to upgrading. If you run into issues, review the Troubleshooting UPnP documentation for assistance. Additional help can be sought in the Node and Representative Management forum category. </p>","title":"Networking changes"},{"location":"releases/release-v20-0/#proof-of-work-management","text":"<p>A couple changes to PoW management that services should be aware of:</p> <ul> <li>With OpenCL enabled, nodes will still use the local CPU for work generation by default. Setting <code>node.work_threads</code> to <code>0</code> will turn this off if required.</li> <li>Regenerating PoW for delayed transactions during high network load will now happen by default through the process RPC. If you wish to turn this off, setting <code>watch_work</code> to <code>false</code> is required.</li> </ul> <p>Other updates to review Improvements to the External Management and Block Confirmation and Tracking documentation should help clarify the recommended approaches to building integrations.</p>","title":"Proof-of-Work management"},{"location":"releases/release-v20-0/#major-updates","text":"","title":"Major Updates"},{"location":"releases/release-v20-0/#migration-to-toml-config-files","text":"<p>Better legibility, support for comments, and no more having the node write to your config files are some of the benefits of this upgrade. Any non-default values captured in your existing .json files will be migrated and you can export a full list of configuration options for use with simple commands. See additional callouts in Upgrade Notices above and in the node Configuration documentation.</p>","title":"Migration to .toml config files"},{"location":"releases/release-v20-0/#proof-of-work-regeneration-outside-development-wallet","text":"<p>Any requests to the process RPC will have the new <code>watch_work</code> option turned on by default, allowing the node to regenerate Proof-of-Work for blocks even if they are outside of the node\u2019s development wallet. This makes Dynamic PoW and prioritization function more consistently across the network. If you have an external integration utilizing this RPC call, you will automatically start taking advantage of rework during confirmation delays on the network.</p>","title":"Proof-of-Work regeneration outside development wallet"},{"location":"releases/release-v20-0/#rocksdb-experimental-support","text":"<p>With better disk IO usage, RocksDB is being introduced in this version with experimental support. It is not recommended for use in production, but those interested in testing out a more performant database for the ledger should checkout how to install RocksDB and try it out on development and test systems. We also have a related discussion in our forum for those interested.</p>","title":"RocksDB experimental support"},{"location":"releases/release-v20-0/#active-elections-and-other-optimizations","text":"<p>Thanks to our excellent community testers putting effort into collecting and analyzing block, voting and confirmation data from the beta network, we\u2019ve found various optimizations with the active elections process, confirmation request attempts and bootstrapping behaviors. Various changes have been implemented to help reduce resource usage on nodes in various areas and increase the available throughput on the network. This feature also enhances the effectiveness of prioritization and rework of PoW. No action is needed to take advantage of these great updates. </p>","title":"Active elections and other optimizations"},{"location":"releases/release-v20-0/#infrastructure-for-pow-transition","text":"<p>Back in September we announced a new PoW algorithm design we had been working on which aimed to be memory hard. After open sourcing an implementation of the algorithm, an efficient low-memory solution was found and we subsequently removed the algorithm implementation from V20.</p> <p>As part of the original implementation work we were able to setup infrastructure for moving PoW out of the node process in the future, and also added support for version 2 of epoch blocks, which will allow the network upgrade later when a new PoW algorithm is ready. These updates will be included in Lydia but not be utilized until a future version. To follow along with node releases going forward, check out the Upcoming Features page.</p>","title":"Infrastructure for PoW transition"},{"location":"releases/release-v20-0/#rpc-updates","text":"<ul> <li>BEHAVIOR CHANGE <code>process</code> now takes an optional flag <code>watch_work</code> (default <code>true</code>). Unless set to <code>false</code>, processed blocks can be subject to PoW rework</li> <li>BEHAVIOR CHANGE <code>bootstrap</code>, <code>bootstrap_any</code> and <code>boostrap_lazy</code> will now throw errors when certain launch flags are used to disabled bootstrap methods - see each RPC page for details</li> <li>BEHAVIOR CHANGE RPCs requiring work generation will now throw errors when work generation is disabled (no work peers, no OpenCL and no work threads configured)</li> <li><code>block_count</code> no longer requires config option <code>enable_control</code> to get the cemented block count</li> <li><code>unchecked</code> now takes an optional flag <code>json_block</code> to return blocks in JSON-format</li> <li><code>version</code> now includes more fields - network label, identifier (hash of the genesis open block) and build information</li> <li><code>peers</code> and <code>node_id</code> now return node IDs with a <code>node_</code> prefix</li> <li>work_generate and work_validate can now take a multiplier (against base difficulty) to set a different difficulty threshold</li> </ul>","title":"RPC Updates"},{"location":"releases/release-v20-0/#cli-updates","text":"<ul> <li>NEW <code>generate_config [node|rpc]</code> prints sample configuration files to stdout<ul> <li><code>use_defaults</code> additional argument to generate uncommented entries (not recommended)</li> </ul> </li> <li>NEW <code>config</code> passes configuration arguments, alternative to setting in the config file</li> </ul>","title":"CLI Updates"},{"location":"releases/release-v20-0/#node-configuration-updates","text":"<p>Support in Nano Forum</p> <p>For node operators looking to upgrade to V20.0 or tune their configurations, the Node and Representative Management category of the forum is a great resource to use.</p>   <p>Generate .toml config to see options</p> <p>As noted in the Upgrade Notices above, this version will migrate your existing .json files over to .toml files. Only non-default values for these fields will be added to the new .toml file. If you wish to adjust other options, use the config generation commands to see all available options.</p>  <p>The following options are notable node configuration updates. Additional configuration changes have been included in this release and can be found when generating the config files.</p> <ul> <li><code>backup_before_upgrade</code> (default <code>false</code>) enables automatic backup of the ledger and wallet databases when updating to a new node version</li> <li><code>work_watcher_period</code> (default <code>5</code> seconds) controls how frequently the node should check the confirmation status of block in the work watcher, and re-generate higher difficulty work if unconfirmed</li> <li><code>max_work_generate_multiplier</code> (default <code>64.0</code>) previously <code>max_work_generate_difficulty</code>, now a multiplier for easier management, specifies the absolute maximum difficulty multiplier to be used for work generation</li> </ul>","title":"Node Configuration Updates"},{"location":"releases/release-v20-0/#developerdebug-options","text":"<ul> <li>New RPC <code>epoch_upgrade</code> allowing easier epoch distribution (Note - this epoch requires a special private key to be used, see the Network Upgrades page for information)</li> <li>RPC <code>bootstrap</code> has a new optional \"bypass_frontier_confirmation\"</li> <li>RPC <code>bootstrap_status</code> now displays more data about the current bootstrap attempt</li> <li>New CLI <code>debug_stacktrace</code> displays an example stacktrace, simulating an unexpected program crash</li> <li>New CLI <code>debug_account_versions</code> displays the total number of accounts separated by version and opened/unopened</li> <li>CLI <code>debug_validate_blocks</code> updated to cover more cases</li> <li>CLI <code>debug_profile_verify</code> renamed to <code>debug_profile_validate</code> and now provides simplified work validation profiling</li> <li>New CMake build options:</li> <li><code>NANO_ROCKSDB</code> enables use of the RocksDB database backend, experimental</li> <li><code>NANO_WARN_TO_ERR</code> turns compiler warnings into errors on Linux/Mac</li> <li><code>NANO_TIMED_LOCKS</code> provides information on mutexes held for a long time</li> <li><code>NANO_STACKTRACE_BACKTRACE</code> uses <code>libbacktrace</code> to provide stacktraces</li> <li><code>CI_BUILD</code> if set, uses the <code>TRAVIS_TAG</code> environment variable to modify the locally reported node version, to help with support tickets</li> </ul>","title":"Developer/Debug Options"},{"location":"releases/release-v20-0/#deprecations","text":"<p>The following functionality is now deprecated and will be removed in a future release:</p> <ul> <li>Addresses containing a dash (ex. <code>nano-</code> or <code>xrb-</code>) are being deprecated and will not longer be compatible with the node in a future release. Addresses using underscores will only be supported.</li> </ul>","title":"Deprecations"},{"location":"releases/release-v21-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links     21.0 18 18 2020-06-16 V21.0 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>   Known Issue Linux V21: 'unable to find libboost' <p>If you are on Linux and unable to get V21.0 to start, <code>unable to find libboost...</code> https://github.com/nanocurrency/nano-node/releases/download/V21.0/nano-node-V21.0.1-Linux.tar.bz2 has been added to the release artifacts with the correct lib rpath. Please use this if you do not wish to move the lib folder into the bin folder after extraction.</p>   Known Issue Windows V21: Crash when using config <code>node.logging.stable_log_filename</code> <p>Setting <code>node.logging.stable_log_filename</code> configuration option to <code>true</code> results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to <code>false</code>.</p>","title":"V21.0"},{"location":"releases/release-v21-0/#upgrade-notices","text":"<p>Upgrade notices for nodes upgrading below V21.0</p> <p>These upgrade notices and other details are only for nodes upgrading from V20.0 and lower. For operators upgrading to the latest from V21.0 or higher there are no special considerations.</p>  <p>The following key upgrade details should be reviewed by all node operators to determine how they will impact plans for upgrading:</p>","title":"Upgrade Notices"},{"location":"releases/release-v21-0/#database-upgrades","text":"<p>An in-place database upgrade will occur with this release to accomodate epoch-related flags. Machines will need at least 30GB free disk space to accommodate the upgrade. During the upgrade process, which may take multiple hours to complete depending on the machine specs, the node will not participate on the network or respond to RPC calls.</p> <p>As a result, the recommended approach is to upgrade the ledger in a separate environment before replacing on production. For detailed steps on this approach and other options, see the Updating the node section of the Ledger Management page.</p>","title":"Database upgrades"},{"location":"releases/release-v21-0/#minor-rpc-breaking-changes","text":"<p>Although breaking changes were kept to a minimum in this release, there are two RPC calls with such changes: <code>work_validate</code> and <code>bootstrap_status</code>. For integrations using them, carefully review the additional details on these changes included in the RPC Updates section below.</p>","title":"Minor RPC breaking changes"},{"location":"releases/release-v21-0/#upcoming-v2-epoch-upgrade","text":"<p>As outlined in the February Development Update: V21 PoW Difficulty Increases, an epoch block distribution must be done to complete the upgrade to the new work difficulty thresholds. All integrations generating work are encouraged to review the details on the Network Upgrades page under the Upcoming upgrades section ahead of the epoch V2 distribution.</p>  <p>Only nodes V21.0+ will be active after epoch distribution</p> <p>Nodes upgrading to V21.0+ will remain peered with nodes V19.0 and V20.0 on the network until the epoch v2 block distribution begins. After the first epoch v2 block is distributed, all nodes not running V21.0+ will no longer be able to participate on the network. This distribution will occur once 90% of voting weight and key services on the network have upgraded. Communications around the progress towards this goal will be sent following the release.</p> <p>More details about this network upgrade can be found on the Network Upgrades page under the Upcoming upgrades section</p> <p>All network participants are encouraged to upgrade to V21.1 as soon as possible to avoid disruption.</p>","title":"Upcoming v2 epoch upgrade"},{"location":"releases/release-v21-0/#udp-disabled-by-default","text":"<p>With all active peers capable of communicating via TCP, the UDP connections will be disabled by default in this version. To avoid disruptions, all nodes should allow traffic on 7075 TCP (see Network Ports details) and once upgraded, the <code>peers</code> RPC call should return at least dozens of peers and the <code>confirmation_quorum</code> RPC call should have a <code>peers_stake_total</code> value in the high tens of millions of Nano.</p> <p>Although not recommended, if necessary the temporary use of UDP can be done with the new <code>--enable_udp</code> flag.</p>","title":"UDP disabled by default"},{"location":"releases/release-v21-0/#major-updates","text":"","title":"Major Updates"},{"location":"releases/release-v21-0/#work-difficulty-increase","text":"<p>As mentioned in the Upgrade Notices section above, work difficulty changes were implemented in V21, but will not be activated until epoch v2 blocks are distributed at a future date. Please review the Upcoming upgrades section of the Network Upgrades page for details.</p> <p>Updates on the progress toward the epoch upgrade will be posted in our many social channels as well as sent through our technical updates mailing list which can be joined here: Join Mailing List.</p>","title":"Work difficulty increase"},{"location":"releases/release-v21-0/#node-telemetry","text":"<p>To allow better communication between nodes about various performance and other details, telemetry was added between peers. Various version details, account and block counts, active difficulty and more can be discovered from individual peers or summarized across them.</p> <p>Details of what is shared and options for receiving them can be found in the node telemetry WebSocket section and <code>node_telemetry</code> RPC.  For protocol level details, see Node Telemetry section under Protocol Design &gt; Networking.</p>  <p>Telemetry can be forged</p> <p>Although the telemetry messages are signed by nodes, the data provided by other peers can be forged by malicious nodes so they cannot be guaranteed as accurate. All details in these messages should be used as rough indicators of peer and broad network situations, but not exclusively relied on for any key integration or network activities.</p>  <p>Continued conversation around telemetry is happening through the related forum discussion.</p>","title":"Node Telemetry"},{"location":"releases/release-v21-0/#ipc-20","text":"<p>As a key update towards the upcoming RPC 2.0 redesign, this background upgrade will provide more performant communication to the node, allow easier integration across various languages by supporting Flatbuffers and provide the foundation for more granular authorization of specific calls.</p>","title":"IPC 2.0"},{"location":"releases/release-v21-0/#better-election-alignment-and-performance","text":"<p>Behind the scenes many improvements were made to better streamline alignment of elections across the network and allow for better performance. Resource usage by nodes, particularly network bandwidth, will be reduced even further than previous levels. No action is needed to take advantage of this increase other than upgrading your node to V21 as soon as you can!</p>","title":"Better election alignment and performance"},{"location":"releases/release-v21-0/#node-configuration-and-management-updates","text":"<p>Support in Nano Forum</p> <p>For node operators looking to upgrade their node or tune their configurations, the Node and Representative Management category of the forum is a great resource to use.</p>  <p>The following options are notable node configuration updates. Additional configuration changes have been included in this release and can be found when generating the config files.</p> <ul> <li>The ability to enable a static log file name is available via the <code>node.logging.stable_log_filename</code> option. If update to <code>true</code>, a static log file of <code>log/node.log</code> will be written to and rotated to timestamped files once full. This option requires the node being built with Boost 1.70+ (default for Docker images and published binaries).</li> <li>Nodes will now clear their peers lists and online weight if they are started after more than 1 week of being offline. This aims to improve re-peering in these situations, as well as provide more accurate online weight values as the node begins participating on the network again (related PR).</li> <li>When <code>watch_work</code> is set to <code>false</code> in the process RPC, it is no longer required to have <code>enable_control</code> = <code>true</code> in the <code>config-rpc.toml</code> file.</li> </ul>  <p>Log when voting, warn multiple accounts</p> <p>When the node is started there are new messages pushed to the logs which indicate when voting is enabled and how many representatives are configured to vote. A warning will be included in both the logs and <code>stdout</code> if multiple representatives are configured to be voting.</p>","title":"Node Configuration and Management Updates"},{"location":"releases/release-v21-0/#rpc-updates","text":"<ul> <li>BREAKING CHANGE <code>work_validate</code> has multiple changes to the response, one which will break most existing integrations:<ul> <li>If <code>difficulty</code> parameter is not explicitly passed in the request, the existing <code>valid</code> field will not be returned (breaking)</li> <li><code>valid_all</code> is a new return field, <code>true</code> if the work is valid at the current default difficulty (will go up after epoch upgrade)</li> <li><code>valid_receive</code> is a new return field, <code>true</code> if the work is valid at the lower epoch_2 receive difficulty (only useful after the epoch upgrade is finished)</li> <li>To best understand how these and other epoch related changes will impact your integration, it is highly recommended that the Upcoming upgrades &gt; Increased work difficulty section of the Network Upgrades is carefully reviewed</li> </ul> </li> <li><code>active_difficulty</code> RPC and WebSocket will automatically begin returning the higher difficulty threshold for send/change blocks in the <code>network_minimum</code> field once the epoch upgrade begins, otherwise the response formats will remain the same</li> <li>BREAKING CHANGE <code>bootstrap_status</code> responses now have <code>connections</code> field as an array of connection-related fields and adds an <code>attempts</code> field with an area of individual bootstrap attempt details, each including information such as a unique id, type of bootstrap (legacy, lazy) and various other granular information.</li> <li><code>block_create</code> response now contains the <code>difficulty</code> value of the work included in the block for easy reference by integrations. When generating work for the created block, the node ledger data is used to estimate the required difficulty threshold.</li> <li><code>work_generate</code> request now accepts optional <code>block</code> (and corresponding boolean <code>json_block</code>), which is used to estimate the required difficulty threshold by using ledger data. Two common use-cases are generating work for blocks created elsewhere, and re-generating work for a previously published block.</li> <li><code>account_info</code> responses now contain <code>confirmation_height_frontier</code> which is the hash of the last confirmed block.</li> </ul>  <p>Including <code>subtype</code> in <code>process</code> RPC calls highly recommended</p> <p>In order to avoid potential incorrect sends including the optional <code>subtype</code> parameter on all <code>process</code> RPC calls is highly recommended. In the next version of the RPC this parameter will be required.</p>","title":"RPC Updates"},{"location":"releases/release-v21-0/#cli-updates","text":"<ul> <li>NEW <code>--debug_generate_crash_report</code> greatly simplifies troubleshooting when a node crashes in Linux.</li> <li>NEW <code>--rebuild_database</code> provides a better compaction method for LMDB. NOTE: This requires approximately <code>data.ldb</code> file size * 2 in free space on disk.</li> <li>NEW <code>--compare_rep_weights</code> gives the ability to compare the current ledger voting weight distribution against the hard coded weights provided in the node on release. Useful when attempting to use a downloaded ledger. More details on use can be found on the Ledger Management page.</li> <li>NEW <code>--inactive_votes_cache_size</code> allows adjusting of the cache that holds votes where the block does not have an action election, default is 16384 votes.</li> </ul>","title":"CLI Updates"},{"location":"releases/release-v21-0/#websockets","text":"<ul> <li>Updates to WebSocket subscriptions are now allowed on the <code>confirmation</code> topic. With <code>options</code> of <code>accounts_add</code> and <code>accounts_del</code> an existing subscription can now be more easily managed to avoid resubscribing with a large list of accounts or managing multiple subscriptions.</li> <li>NEW <code>bootstrap</code> topic provides notifications about the starting and exiting of bootstrap attempts.</li> <li>NEW <code>new_unconfirmed_block</code> topic provides notifications about blocks which were just processed and are being seen by the node for the first time. This is useful for integrations that want to watch for blocks they didn't create themselves, but for which they want to update with new work (external work watcher).</li> <li>WebSocket server is now enabled by default in V21+ Docker images to make it more consistent with RPC server setup and documented port mappings</li> </ul>","title":"WebSockets"},{"location":"releases/release-v21-0/#developerdebug-options","text":"<ul> <li><code>confirmation_active</code> RPC response includes new <code>unconfirmed</code> and <code>confirmed</code> fields to help with more granular election tracking and monitoring</li> <li>When the node is started there are new messages pushed to the logs which indicate when voting is enabled and how many representatives are configured to vote. A warning will be included in both the logs and <code>stdout</code> if multiple representatives are configured to be voting.</li> <li>New <code>--debug_generate_crash_report</code> CLI command consumes the dump files to create a helpful crash report. See What to do if the node crashes (Linux) for more details on using this command.</li> <li>New <code>logging.log_rpc</code> configuration can be optionally set to <code>false</code> to prevent explicit logging of RPC requests made to the node</li> </ul>","title":"Developer/Debug Options"},{"location":"releases/release-v21-0/#deprecations","text":"<p>The following functionality is now deprecated and will be removed in a future release:</p> <ul> <li>UDP is disabled by default in this version and will be removed in a future release. Launch flag <code>--disable_udp</code> is deprecated and temporary use of UDP can be done with the new <code>--enable_udp</code> flag.</li> </ul>","title":"Deprecations"},{"location":"releases/release-v21-1/","text":"Node Protocol Database Release Date Release Notes GitHub Links     21.1 18 18 2020-07-14 V21.1 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>   Known Issue Windows V21: Crash when using config <code>node.logging.stable_log_filename</code> <p>Setting <code>node.logging.stable_log_filename</code> configuration option to <code>true</code> results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to <code>false</code>.</p>   <p>No special upgrade considerations</p> <p>V21.1 is a service release which doesn't require any special upgrade considerations when upgrading from V21.0.</p>","title":"V21.1"},{"location":"releases/release-v21-2/","text":"Node Protocol Database Release Date Release Notes GitHub Links     21.2 18 18 2020-09-03 V21.2 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>   <p>No special upgrade considerations</p> <p>V21.2 is a service release which doesn't require any special upgrade considerations when upgrading from V21.0.</p>","title":"V21.2"},{"location":"releases/release-v21-3/","text":"Node Protocol Database Release Date Release Notes GitHub Links     21.3 18 18 2021-03-18 V21.3 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>   <p>No special upgrade considerations</p> <p>V21.3 is a service release which doesn't require any special upgrade considerations when upgrading from V21.0 or higher. If upgrading from V20.0 or lower, please review the V21.0 Release Notes for upgrade notices and other considerations.**</p>","title":"V21.3"},{"location":"releases/release-v22-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links     22.0 18 21 2021-05-14 V22.0 Release - Milestone - Changelog     Known issue with RocksDB: RPC <code>unchecked_keys</code> not working properly <p>Issue: The RPC <code>unchecked_keys</code> is returning <code>0</code> for all calls when used with the RocksDB backend. This known issue will be resolved in a future release.</p> <p>Solution: Until the issue is resolved any integrations using this command should remain on the existing LMDB backend</p>","title":"V22.0"},{"location":"releases/release-v22-0/#upgrade-notices","text":"","title":"Upgrade notices"},{"location":"releases/release-v22-0/#database-upgrades-with-increased-disk-requirements","text":"<p>Upgrade requires 150GB of free disk space</p>  <p>This version performs a database upgrade of the ledger format on disk. This process requires a large amount of disk space and due to the DoS attack on nano earlier in the year, the disk space requirements during upgrade require attention.</p> <p>Upgrading to V22.0 requires approximately 150GB of free disk space, however, the final upgraded ledger size is ~50GB. The upgrade takes between 30 minutes and 4 hours on most machines, depending on the speed of the disk.</p> <p>Due to these impacts, upgrading the database in a staging environment is recommended where possible. For operators who are unable to perform this direct upgrade, you may download a snapshot of an already upgraded ledger.</p> <p>We are in the process of adding online upgrade support for future versions which will eliminate these upgrade disk requirements.</p>","title":"Database upgrades with increased disk requirements"},{"location":"releases/release-v22-0/#docker-tag-latest-removed","text":"<p>As a best security and node management practice, the <code>latest</code> tag for Docker containers has been removed from available tags at https://hub.docker.com/r/nanocurrency/nano. Going forward the only tags available for the live network will be explicit version tags, no dynamically updated tags will be maintained. For this upgrade, the tag <code>V22.0</code> will be required.</p>","title":"Docker tag <code>latest</code> removed"},{"location":"releases/release-v22-0/#upcoming-canary-block-for-final-votes-activation","text":"<p>In order for nodes to begin issuing final votes for unconfirmed blocks, and using those votes for cementing blocks, a canary block will need to be distributed to activate the feature. To ensure enough vote weight is prepared for the consensus change, the Nano Foundation will be monitoring upgrades on the network and will distribute the canary block once at least 80% of voting weight is on V22.0+.</p> <p>To stay updated on progress towards the canary block distribution, please sign up for the technical update mailing list.</p>","title":"Upcoming canary block for final votes activation"},{"location":"releases/release-v22-0/#remove-election-difficulty-sorting","text":"<p>Higher work difficulty on blocks will no longer result in increased election priority. Instead, a new election prioritization and scheduling mechanism was designed with initial changes being made in this release. With these changes the work generation is still required for transactions to be valid, but higher difficulties are no longer part of prioritization. Instead, the balance of the account and the time it was last used will be used to determine when elections are started.</p> <p>For nearly all services and integrations this will have no noticeable impact on how quickly voting will begin on a published transaction. As more improvements are added in V23, addition details will be available about the future of work generation and recommendations for optimizing this in the long term.</p>","title":"Remove election difficulty sorting"},{"location":"releases/release-v22-0/#node-count-limits-per-subnetwork","text":"<p>The current limits of 5 nodes per IPv4 address is being expanded to include /48 IPv6 subnetwork as well. In addition, a 20 node limit is being applied to the /24 IPv4 range and /32 IPv6 range.</p>","title":"Node count limits per subnetwork"},{"location":"releases/release-v22-0/#node-v190-or-later-required","text":"<p>Upgrades from versions below V19.0 have been removed from the code base. All nodes must be on at least V19.0 for the upgrade to V22.0 to work. Note that participation on the live network does require at least V21.0 of the node.</p>","title":"Node V19.0 or later required"},{"location":"releases/release-v22-0/#major-updates","text":"","title":"Major updates"},{"location":"releases/release-v22-0/#final-votes","text":"<p>To help with handle specific fork situations, the final votes feature will add a second round of voting to the consensus process as follows: once initial voting weight for an unconfirmed block has reached quorum, nodes will issue final votes by setting the timestamp to the maximum integer possible for that field (<code>18446744073709551615</code>). These final votes will then be required to confirm and cement a block in the ledger.</p> <p>Because this is a consensus change, a network upgrade is required to activate. As noted above, this will be done using a canary block once at least 80% of voting weight on the network has been upgraded. After the canary block is distributed by the Nano Foundation, the final votes will be used for cementing going forward.</p>","title":"Final votes"},{"location":"releases/release-v22-0/#rocksdb-for-production-use","text":"<p>Originally introduced in V20.0, support for RocksDB as the backend to the node has been improved over time and is now ready for use in production nodes running V22.0. With disk IO being a potential bottleneck in performance on some machines, RocksDB has shown promise in reducing disk activity in some node scenarios. To upgrade, see the new command to migrate from LMDB to RocksDB in the CLI Updates section below.</p>","title":"RocksDB for production use"},{"location":"releases/release-v22-0/#experimental-ledger-pruning","text":"<p>An initial, experimental version of a much requested feature is being made available in V22.0. This feature is NOT for production use. Many of the details can be found in the related pull request, but the main goal is to reduce the disk space required for the ledger by removing blocks not near the frontiers or that are pending sends. Although the final ledger size will be significantly reduced, it does require first downloading the full ledger and then pruning, to ensure integrity of the data. It also is not available for voting nodes, only non-voting nodes will allow this feature.</p>","title":"Experimental ledger pruning"},{"location":"releases/release-v22-0/#election-scheduler-and-prioritization-changes","text":"<p>A new election prioritization and scheduling mechanism was designed and the initial updates for this feature are included in this release. These changes will keep work generation as a requirement for transactions to be valid, but switch the election scheduler and prioritization behaviors to use a combination of balance and time since the account was last used. With this approach nodes across the network are expected to see improved performance in clearing the backlog of elections while the network is not actively under spam attack. Future changes in V23 will be targeting improved performance while the network is under load. </p>","title":"Election scheduler and prioritization changes"},{"location":"releases/release-v22-0/#node-configuration-and-management-updates","text":"<ul> <li>REMOVAL The <code>online_weight_quorum</code> value, which was used in combination with online voting weight values to determine the voting weight necessary for confirming a block, has been removed as a configuration option and hardcoded to 67% for all nodes. Any existing overrides for <code>online_weight_quorum</code> in the <code>config-node.toml</code> file can be removed.</li> <li>The default value for <code>active_elections_size</code> in <code>config-node.toml</code> has been reduced from 50,000 to 5,000. This change was to help limit extra network traffic generated by large amounts of elections as behavior of the active elections container was modified for election scheduler and prioritization needs.</li> </ul>","title":"Node configuration and management updates"},{"location":"releases/release-v22-0/#rpc-updates","text":"<ul> <li>BREAKING CHANGE All RPCs with the <code>include_only_confirmed</code> option available has that option set by default and setting it explicitly to <code>false</code> will be required to have unconfirmed blocks returned/counted in the response (such as <code>pending</code> amounts or <code>balance</code> amounts). These RPCs include:</li> <li>NEW OPTION account_balance</li> <li>accounts_pending</li> <li>pending</li> <li>pending_exists</li> <li>wallet_pending</li> <li>Option to <code>include_only_confirmed</code> blocks for the returned <code>balance</code> and <code>pending</code> fields was added to <code>account_balance</code> and <code>include_confirmed</code> option to provide extra <code>confirmed_balance</code> and <code>confirmed_height</code> fields for <code>account_info</code> also added (<code>confirmed_height</code> was only added for consistency in naming, as <code>confirmation_height</code> already existed and will be the same value). </li> <li>BREAKING CHANGE <code>block_count_type</code> was removed after the database upgrade that merged blocks into the state block format was completed.</li> <li>BREAKING CHANGE When both <code>count</code> and <code>sorting</code> options are included in the RPC pending, the result will now be done over all pending blocks before the subset is returned. Previously only a portion of the pending was scanned before returning the requested count.</li> <li>RPC <code>bootstrap_any</code> now allows and optional <code>account</code> field for targeting specific account attempt</li> <li>RPC <code>bootstrap_lazy</code> now returns more accurate status of whether the bootstrap was <code>started</code> and whether a new lazy <code>key_inserted</code></li> </ul>","title":"RPC updates"},{"location":"releases/release-v22-0/#cli-updates","text":"<ul> <li>Passing values using the <code>--config</code> command no longer require escaping of quotes</li> <li>NEW <code>--migrate_database_lmdb_to_rocksdb</code> does the necessary migration of an existing LMDB database over to RocksDB. Note that after migration the necessary configuration changes to enabled RocksDB must be done to use the new backend.</li> </ul>","title":"CLI updates"},{"location":"releases/release-v22-0/#websocket-updates","text":"<ul> <li>Topic <code>confirmation</code> has new optional <code>include_election_info_with_votes</code> which will include the <code>representative</code>, <code>timestamp</code>, <code>sequence</code>, <code>hash</code>, and <code>weight</code> for each of the votes on the election.</li> </ul>","title":"WebSocket updates"},{"location":"releases/release-v22-0/#developerdebug-options","text":"<ul> <li>When a legacy bootstrap is returned from RPC <code>bootstrap_status</code>, the <code>frontiers_age</code> and <code>last_account</code> will now be included</li> <li>NEW CLI <code>--debug_unconfirmed_frontiers</code> outputs the frontier and confirmed (cemented) frontier for any accounts which are not yet fully cemented (warning: could output a lot if used on a ledger with large amount of uncemented blocks).</li> <li>New <code>nano_test_network</code> added which is the basis for the new public test network for integration testing (test.nano.org) and allows customizing of various core network parameters to allow for custom test networks to be deployed from scratch.</li> <li>C++17 support is now required</li> <li>Block rollback messages in logs are no longer available by default to avoid excessive logs in certain scenarios (<code>node.logging.ledger_rollback</code> option to enable)</li> <li>Signals available for config file reloading with initial support for <code>bandwidth_limit</code> and <code>bandwidth_limit_burst_ratio</code> options by calling <code>kill -SIGHUP [process #]</code></li> </ul>","title":"Developer/debug options"},{"location":"releases/release-v22-0/#deprecationsremovals","text":"<ul> <li>All RPC <code>payment_*</code> removed (previously deprecated in V19.0)</li> <li>RPC <code>active_difficuly</code> deprecated due to difficulty not longer being used for prioritization, only for checking validity of blocks</li> <li>CLI commands <code>--batch_size</code> and <code>--debug_mass_activity</code> removed (previously deprecated in V21.0)</li> </ul>","title":"Deprecations/removals"},{"location":"releases/release-v22-1/","text":"Node Protocol Database Release Date Release Notes GitHub Links     22.1 18 21 2021-06-11 V22.1 Release - Milestone - Changelog","title":"V22.1"},{"location":"releases/release-v22-1/#upgrade-notices","text":"<p>There are no special considerations when upgrading from V22.0 to V22.1. There are no database upgrades or API changes.</p>","title":"Upgrade notices"},{"location":"releases/release-v22-1/#major-updates","text":"<ul> <li>Fixes an issue where UPnP leases might be lost and port mappings might cease</li> <li>Fixes an issue where manually started or hinted elections would be quickly removed from the election scheduler</li> <li>Fixes an issue where new connections might not be able to be accepted</li> <li>Doubles the length of the connection backlog</li> </ul>","title":"Major updates"},{"location":"releases/release-v22-1/#developerdebug-options","text":"<ul> <li>Elections dropped due to timeout/overflow have been separated in node statistics.</li> </ul>","title":"Developer/debug options"},{"location":"releases/release-v22-1/#builds-and-commands","text":"OS Download link/command Verification     Universal Linux https://repo.nano.org/live/binaries/nano-node-V23.0-Linux.tar.bz2 SHA256 Checksum   Debian https://repo.nano.org/live/binaries/nano-node-V23.0-Linux.deb SHA256 Checksum   macOS https://repo.nano.org/live/binaries/nano-node-V23.0-Darwin.dmg SHA256 Checksum   Windows (exe) https://repo.nano.org/live/binaries/nano-node-V23.0-win64.exe SHA256 Checksum   Windows (zip) https://repo.nano.org/live/binaries/nano-node-V23.0-win64.zip SHA256 Checksum   Docker <code>docker pull nanocurrency/nano:V23.0</code>See Pulling the Docker Image for more details.    RHEL/CentOS rpm <code>sudo rpm -iUvh https://repo.nano.org/live/binaries/nanocurrency-23.0-26.el7.x86_64.rpm</code>This installs <code>nano_node</code> and <code>nano_rpc</code> to <code>/usr/bin</code>. SHA256 Checksum","title":"Builds and commands"},{"location":"releases/release-v23-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links     23.0 18 21 2021-01-17 V23.0 Release - Milestone - Changelog","title":"V23.0"},{"location":"releases/release-v23-0/#upgrade-notices","text":"<p>There are no upgrade impacts to be considered with V23.0. However all exchanges, services and integrations are encouraged to test their implementations on the test network (excluding load testing).</p>","title":"Upgrade notices"},{"location":"releases/release-v23-0/#major-updates","text":"","title":"Major updates"},{"location":"releases/release-v23-0/#refactoring-and-cleanup","text":"<p>Many of the more than 150 pull requests closed for this release were part of efforts to refactor and cleanup many areas of the code. These updates are helping provide a foundation for better improvements in subsequent releases. More details can be found in the V23.0 Follis \u2014 Development Update.</p>","title":"Refactoring and cleanup"},{"location":"releases/release-v23-0/#unit-tests-and-bug-fixes","text":"<p>Another focus area was improving and cleaning up the unit tests, along with various minor bugs and fixes. Test runs are now more consistent and reliable with V23, and will continue to be improved on in the coming releases.</p>","title":"Unit tests and bug fixes"},{"location":"releases/release-v23-0/#naming-conventions","text":"<p>Recent updates to naming conventions are noteworthy:</p>","title":"Naming conventions"},{"location":"releases/release-v23-0/#receivable-instead-of-pending","text":"<p>After community discussions, a change from the term <code>pending</code> to <code>receivable</code>/<code>ready to be received</code> and similar was decided on and partially implemented in V23.0. These changes can be seen in various areas of the node wallet as well as across many RPC calls. </p>  <p>There are no breaking changes with this update, but switching to <code>receivable</code> terms is advised.</p>  <p>To keep backwards compatibility:</p> <ul> <li>The <code>pending</code> RPC call name is deprecated in favor of <code>receivable</code> (additional RPC call name changes to be completed in the next release)</li> <li>All RPC responses containing a key of <code>pending</code> still include the key as deprecated, and an additional <code>receivable</code> key with the same value was added as the preferred option</li> <li>Any RPC examples in the documentation have been updated to favor <code>receivable</code></li> </ul> <p>The aim of this change is to help reduce the confusion around send blocks that are confirmed, but a matching receive block has not yet been published for them. See RPC updates below for a list of impacted RPC calls.</p>","title":"Receivable instead of pending"},{"location":"releases/release-v23-0/#unit-name-simplifications","text":"<p>Updates to simplify the unit names used within the node wallet and unit conversion RPCs were completed. This means previous unit conversion RPCs are now deprecated (see Deprecations/removals below) and the wallet uses the only remaining standard units of <code>raw</code> (10^0) and <code>nano</code> (10^30).</p>","title":"Unit name simplifications"},{"location":"releases/release-v23-0/#rpc-updates","text":"<ul> <li><code>account_history</code> RPC now includes whether the block was <code>confirmed</code> in the response, allowing more efficient confirmation validation in some cases.</li> <li>NEW <code>accounts_representatives</code> RPC allows requesting representatives from multiple accounts in a single call.</li> <li><code>block_info</code> and <code>blocks_info</code> RPCs now include the <code>successor</code> block hash in responses for easier ledger walking.</li> <li><code>delegators</code> now allows for optional parameters <code>count</code> (to limit number of returned accounts), <code>threshold</code> (to require a minimum balance for returned delegators) and <code>start</code> (to allow paging by providing account to start after).</li> <li><code>wallet_info</code> RPC return includes count of all blocks and confirmed blocks from all accounts in the given wallet.</li> </ul>","title":"RPC updates"},{"location":"releases/release-v23-0/#pendingreceivable-term-rpc-updates","text":"<p>There are various changes related to the switch from <code>pending</code> to <code>receivable</code> in RPC calls as noted above. Although all changes are backwards compatible, switching to the term <code>receivable</code> in these cases is advised.</p> <p>There are two main types of changes: RPC call name changes and updates to keys in the call requests and responses.</p> <p>RPC call name changes</p> <ul> <li><code>pending</code> replaced by <code>receivable</code></li> <li><code>pending_exists</code> replaced by <code>receivable_exists</code></li> </ul> <p>Response/request key changes only</p> <ul> <li><code>account_balance</code></li> <li><code>account_info</code></li> <li><code>accounts_balances</code></li> <li><code>blocks_info</code></li> <li><code>ledger</code></li> <li><code>wallet_balances</code></li> <li><code>wallet_info</code></li> <li><code>wallet_ledger</code></li> </ul>  <p>There are no breaking changes with this update, but switching to <code>receivable</code> terms is advised.</p>","title":"Pending/Receivable term RPC updates"},{"location":"releases/release-v23-0/#websocket-updates","text":"<p>Support added for <code>wss://</code> to allow secure WebSocket connections alongside existing TLS support for RPC. Further details and documentation is pending, with initial pull request available here: https://github.com/nanocurrency/nano-node/pull/3032.</p>","title":"WebSocket updates"},{"location":"releases/release-v23-0/#developerdebug-options","text":"<ul> <li>NEW CONFIGURATION OPTION <code>node.rep_crawler_weight_minimum</code> allows configuration of the minimum vote weight a node needs to qualify for the rep crawler to solicit confirmations from them. By default the rep crawler only tracks Principal Representatives (all previous versions behave this way) but a lower value for this option can provide broader tracking for debugging purposes.</li> <li>NEW CLI COMMANDS<ul> <li><code>--disable_add_initial_peers</code></li> <li><code>--debug_block_dump</code></li> <li><code>--initialize</code></li> <li><code>--disable_ongoing_bootstrap</code></li> <li><code>--disable_rep_crawler</code></li> <li><code>--disable_request_loop</code></li> </ul> </li> </ul>","title":"Developer/debug options"},{"location":"releases/release-v23-0/#deprecationsremovals","text":"<ul> <li>Most unit conversion RPCs were deprecated, including <code>krai_from_raw</code>, <code>krai_to_raw</code>, <code>mrai_from_raw</code>, <code>mrai_to_raw</code>, <code>rai_from_raw</code>, <code>rai_to_raw</code></li> </ul>","title":"Deprecations/removals"},{"location":"releases/release-v23-0/#builds-and-commands","text":"OS Download link/command Verification     Universal Linux https://repo.nano.org/live/binaries/nano-node-V23.0-Linux.tar.bz2 SHA256 Checksum   Debian https://repo.nano.org/live/binaries/nano-node-V23.0-Linux.deb SHA256 Checksum   macOS https://repo.nano.org/live/binaries/nano-node-V23.0-Darwin.dmg SHA256 Checksum   Windows (exe) https://repo.nano.org/live/binaries/nano-node-V23.0-win64.exe SHA256 Checksum   Windows (zip) https://repo.nano.org/live/binaries/nano-node-V23.0-win64.zip SHA256 Checksum   Docker <code>docker pull nanocurrency/nano:V23.0</code>See Pulling the Docker Image for more details.    RHEL/CentOS rpm <code>sudo rpm -iUvh https://repo.nano.org/live/binaries/nanocurrency-23.0-26.el7.x86_64.rpm</code>This installs <code>nano_node</code> and <code>nano_rpc</code> to <code>/usr/bin</code>. SHA256 Checksum","title":"Builds and commands"},{"location":"releases/roadmap/","text":"<p>Nano Roadmap moved to GitHub</p> <p>Head over to the new Nano Roadmap GitHub Project for a more dynamic and updated view of the upcoming features under research and implementation on the Nano node and protocol.</p>","title":"Roadmap"},{"location":"running-a-node/advanced-monitoring/","text":"<p>For keeping a closer watch on node performance a Prometheus-based exporter monitoring solution is available. It provides an easy way to automatically gather and export a multitude of stats and metrics from the node RPC, as well as from the machine running the exporter. For added security, the exporter doesn't require opening any additional inbound ports as the metrics are pushed out to a Prometheus push gateway, which can be hosted externally.</p> <p>Prometheus is an open-source systems monitoring and alerting toolkit. For a brief overview of everything it offers, see What is Prometheus?</p>  <p>Basic monitoring option</p> <p>For a simpler monitoring setup that is maintained by the Nano community and provides a public website to view details on, see the monitoring details on the Voting as a Representative page.</p>","title":"Advanced Monitoring"},{"location":"running-a-node/advanced-monitoring/#recommended-architecture","text":"<p>The diagram below illustrates a recommended architecture of components:</p> <p></p> <p>This configuration was recommended as it splits the concerns across two servers: one hosting the node and exporter, with another hosting the push gateway, Prometheus server and graphing/visualization tools. However, there are a variety of configuration options to allow separation of each component onto different servers, depending on the needs.</p>","title":"Recommended architecture"},{"location":"running-a-node/advanced-monitoring/#installation","text":"<p>The following provides the basic details for installing and connecting the components outlined above.</p>","title":"Installation"},{"location":"running-a-node/advanced-monitoring/#step-1-setup-and-configure-nano-node","text":"<p>These configuration options are set in the <code>config-node.toml</code> file.</p> <ul> <li>Get a Nano node setup with Docker or binaries</li> <li>Update config <code>node.rpc.enable</code> = <code>true</code></li> <li>If you want to gather <code>nano_stats_objects*</code> metrics, update config <code>rpc.enable_control</code> = <code>true</code></li> <li>Restart the node for settings to take effect</li> </ul>","title":"Step 1: Setup and configure Nano node"},{"location":"running-a-node/advanced-monitoring/#step-2-install-prometheus-push-gateway","text":"<p>For the best security, it is recommended to run this on a separate server. By default this will need to accept incoming connections from the exporter on TCP port <code>9091</code>.</p> <ul> <li>Requires python 3.7+</li> <li>Download and run the prometheus-pushgateway</li> <li>Accept incoming TCP port <code>9091</code> connections from the node/exporter server</li> </ul>","title":"Step 2: Install Prometheus push gateway"},{"location":"running-a-node/advanced-monitoring/#step-3-install-and-run-the-nano-node-exporter","text":"<p>Typical configurations will have the exporter running on the same server as the node. If so, <code>--rpchost</code> is local as noted below.</p> <p>Install via pip</p> <p><code>pip install nano-prom-exporter</code></p> <p>Example run command</p> <pre><code>nano-prom -h --rpchost ::1 \\\n             --rpcport 7076 \\\n             --datapath ~/Nano/Nano \\\n             --pushgateway your-exporter-and-node.server.org:9091 \\\n             --hostname MyNanoMetrics\n</code></pre> <p>See the README for more details on usage.</p>","title":"Step 3: Install and run the Nano node exporter"},{"location":"running-a-node/advanced-monitoring/#step-4-view-your-metrics","text":"<p>To validate data is available from the exporter, the <code>/targets</code> endpoint on port <code>9090</code> at the URL of the push gateway will show job health: <code>http://your-new.monitor.org:9090/targets</code>. The endpoint pushing the data should have <code>State</code> = <code>UP</code> if everything is working well.</p> <p>There is also a <code>/graph</code> endpoint to do some manual querying of available data: <code>http://your-new.monitor.org:9090/graph</code></p>","title":"Step 4: View your metrics"},{"location":"running-a-node/advanced-monitoring/#step-5-install-grafana","text":"<p>Once you've verified metrics are properly being captured, you can setup visualization amd analysis solutions. One popular option is Grafana, which can be installed from here: https://grafana.com/grafana/download.</p> <p>If Grafana is being installed on a different server from the Promethus push gateway TCP port <code>9090</code> will need to be opened as well.</p> <p>Once running, a sample file can be used from our repository to kickstart your dashboard setup: https://github.com/nanocurrency/nano_prom_exporter/blob/master/sample-grafana-dashboard.json.</p> <p>Other options can be explored in the Visualization section of the Prometheus site.</p>","title":"Step 5: Install Grafana"},{"location":"running-a-node/advanced-monitoring/#connecting-to-other-push-gateways","text":"<p>The exporter supports sending metrics to multiple push gateways using a <code>config.ini</code> file and the <code>--config_path</code> option in the command to accept the location.  Within this file the authentication can be managed between different endpoints and support for selecting specific metrics per push gateway will added soon. See the README for more details on usage.</p> <p>Although no public push gateways for node monitoring are available at this time, there may be opportunities in the future to share your node metrics with the community or other monitoring setups to provide a better view of network performance. Check back here and keep an eye out for these public gateways to become available.</p> <p>And if you know of any public push gateways available to send this useful node data to, please let us know.</p>","title":"Connecting to other push gateways"},{"location":"running-a-node/beta-network/","text":"<p>The beta network exists for the purpose of conducting certain network-wide activites including load testing and new node releases and features testing. These activities can cause the network to become unstable or inaccessible at times due to heavy traffic, occasional resetting of the genesis/ledger or the introduction of bugs due to new features. As a result, an alternative test network is also available which will be more stable and is a better fit for learning node setup and management, and testing out upgrades and other activities for Nano before moving to production.</p> <p>With those things in consideration, if you are interested in helping with testing on the beta network we are excited to help you out - so keep reading!</p>","title":"Joining the beta network"},{"location":"running-a-node/beta-network/#node-release-testing","text":"<p>The Nano Foundation maintains a few beta nodes on the network and various community members also setup nodes to help provide an environment more similar to the main network. During each development cycle Development Builds (DB) are prepared and shared in the Discord Beta Testing section of channels where early testing is coordinated. Once features are stabilized and included, release builds are published as Release Candidates (RC). Starting with RC1 and incrementing with each published build if needed (RC2, RC3, etc.). Final release of a version typically follows quickly once the RC is observed to be stable.</p>  <p>Warning</p> <p>Development Builds (DBs) are only recommended for use on the beta network, and Release Candidate builds (RCs) are only recommended for use on the test and beta networks</p>","title":"Node release testing"},{"location":"running-a-node/beta-network/#running-a-beta-node","text":"<p>Setting up a node on the beta network is similar to the main network. To start you should install docker and be familiar with the general setup and Docker management processes.</p>","title":"Running a beta node"},{"location":"running-a-node/beta-network/#network-ports","text":"Port Protocol Required? Purpose     54000 TCP Yes, open to all traffic For live network activity and bootstrap network activity.   55000 TCP No, recommended For communication with RPC server. Do not expose this outside of your production environment. Anyone with access to this port can control your node's RPC.   56000 TCP No, optional For communication via IPC (advanced). See IPC integration guide for more details.   57000 TCP No, optional For communication with websocket server. Depending on configuration, data throughput can be very high.","title":"Network ports"},{"location":"running-a-node/beta-network/#directory-locations","text":"OS Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\NanoBeta\\</code>   macOS <code>/Users/&lt;user&gt;/Library/NanoBeta/</code>   Linux <code>/home/&lt;user&gt;/NanoBeta/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/NanoBeta</code>","title":"Directory locations"},{"location":"running-a-node/beta-network/#pulling-the-docker-image","text":"<p></p> <p>Pulls the latest release of the Nano Node: <pre><code>docker pull nanocurrency/nano-beta\n</code></pre></p> <p>Pulls a specific version of the Nano node: <pre><code>docker pull nanocurrency/nano-beta:&lt;tag&gt;\n</code></pre></p> <p>A list of beta tags can be found at the official Nano Currency Docker Hub</p>","title":"Pulling the Docker image"},{"location":"running-a-node/beta-network/#starting-the-docker-container","text":"<pre><code>docker run --restart=unless-stopped -d \\\n  -p 54000:54000 \\\n  -p 127.0.0.1:55000:55000 \\ # (1)\n  -p 127.0.0.1:57000:57000 \\ # (2)\n  -v ${NANO_HOST_DIR}:/root \\\n  --name ${NANO_NAME} \\\n  nanocurrency/nano-beta:${NANO_TAG}\n</code></pre> <ol> <li>Port 55000 is optional, but recommended, for querying via RPC</li> <li>Port 57000 is optional for connecting via WebSockets</li> </ol>  <p>Tip</p> <ul> <li>For an explanation of the options included in the Docker <code>run</code> command, see Starting the Container details for the main network.</li> <li>See Docker management for other related commands</li> </ul>   <p>Separate host directories</p> <p>Be sure to use a different host directory for main network and beta network Docker node setups. Attempting to use the same directory will result in issues.</p>","title":"Starting the Docker container"},{"location":"running-a-node/beta-network/#additional-beta-resources","text":"URL Description     https://beta.nanocrawler.cc/ Beta Explorer   https://beta.nanoticker.info/ Beta node details and stats   https://b.repnode.org/ Beta node details and stats","title":"Additional beta resources"},{"location":"running-a-node/beta-network/#differences-from-the-main-network","text":"Parameter Main Network Beta Network Comment     Epoch 1 difficulty threshold <code>ffffffc000000000</code> <code>fffff00000000000</code> 64 times lower on the beta network   Epoch 2 send/change threshold <code>fffffff800000000</code> <code>fffff00000000000</code> Same as epoch 1 on the beta network   Epoch 2 receive threshold <code>fffffe0000000000</code> <code>ffffe00000000000</code> 2 times lower than epoch 1    <p>  </p>","title":"Differences from the main network"},{"location":"running-a-node/beta-network/#testing-builds","text":"<p>Most of the resources needed to participate on the beta network can be found within the <code>#beta-xxxxxxx</code> channels on our Discord server. As much of the discussion, planning and engagement happens here, all participants are highly encouraged to join there.</p>","title":"Testing Builds"},{"location":"running-a-node/beta-network/#binaries","text":"<p>In addition to the Docker details above, the latest binary builds of the node for the beta network are shared in the <code>#beta-announcements</code> channel on our Discord server. These assets are also available on the GitHub repository Releases page under <code>RC#</code> and <code>DB#</code> tags, which can also be used to manually build if necessary.</p>","title":"Binaries"},{"location":"running-a-node/beta-network/#beta-fund-distribution","text":"<p>The funds used for testing transactions on the beta network are generated from a new genesis block and distributed in bulk to various testers running nodes on the network. For small amounts suitable for most basic integration, you can get beta Nano from the <code>#beta-faucet</code> channel on Discord. If you plan to consistently run a node on beta and want to participate in consensus as a Representative, please connect with <code>argakiig#1783</code> in the <code>#beta-net</code> channel on our Discord server.</p>","title":"Beta fund distribution"},{"location":"running-a-node/beta-network/#beta-ledger-file","text":"<p>To help get beta nodes in sync more quickly it is recommended that an updated ledger file is downloaded and placed into the data directory. Often referred to as a \"fast sync\", more details around this approach can be found in the Ledger Management guide. Since the beta network contains no value, validating the blocks, voting weights and confirmation heights isn't necessary.</p> <p>The following command will download and unzip a recent ledger snapshot. Any existing ledger files should be backed up elswhere as this will override them. From within the data directory run:</p> <p><pre><code>curl -O https://s3.us-east-2.amazonaws.com/beta-snapshot.nano.org/data.tar.gz; tar -xzvf data.tar.gz; rm -fr data.tar.gz\n</code></pre> </p>","title":"Beta ledger file"},{"location":"running-a-node/beta-network/#build-contents-and-test-cases","text":"<p>With each DB a GitHub Project board will be created in the Nano GitHub Organization containing all the Pull Requests newly added in the DB, changes from previous DBs that still need network testing, and issues with the various test cases that are targeted to be run with that build. For those looking to assist with these tests, we encourage connecting with the other beta network participants in the <code>#beta-net</code> channel on our Discord server.</p>","title":"Build contents and test cases"},{"location":"running-a-node/beyond-the-node/","text":"","title":"Beyond the Node"},{"location":"running-a-node/beyond-the-node/#building-tools-and-services","text":"<p>Congrats! Now that you understand more about how Nano works and setup your own node to participate on the network, the next step is building tools and services on the node. Our Integration Guides are a great starting point to help you understand how you can leverage your node to create amazing applications that utilize the unique value transfer features of Nano.</p>","title":"Building tools and services"},{"location":"running-a-node/beyond-the-node/#need-some-inspiration","text":"<p>A big part of the Nano community is the Nano Center. Run by a group of Nano enthusiasts, their website helps manage requests for assistance and funding for Nano-related projects. Check out the in progress and past funded projects for some great ideas and opportunities to join in building on top of Nano!</p> <p>For even more details about the many projects that help make our ecosystem robust, head over to Nano.org for examples of wallets, services and more that have integrated Nano.</p>","title":"Need some inspiration?"},{"location":"running-a-node/beyond-the-node/#keep-learning","text":"<p>If you're ready to keep building with Nano, head over to The Basics of our Integration Guides.</p>","title":"Keep learning"},{"location":"running-a-node/configuration-https/","text":"<p>The RPC server supports TLS to allow HTTPS requests, as well as optional client certificates. To enable TLS, the node must first be built with the <code>NANO_SECURE_RPC</code> cmake cache flag set to <code>ON</code>.</p> <p>OpenSSL must be installed. When running cmake initially, you may need to set <code>-DOPENSSL_ROOT_DIR</code> as well, depending on your system.</p> <p>Support for secure WebSockets (<code>wss://</code>) is also available as of V23.0 with these build settings and configuration updates. See Secure Websockets for more details.</p>","title":"HTTPS Support"},{"location":"running-a-node/configuration-https/#configuration","text":"<p>The following section enables TLS in <code>config-rpc.toml</code> for V22.1 and earlier:</p> <pre><code>[secure]\nenable=true\nverbose_logging=true\nserver_cert_path=\"tls/server.cert.pem\"\nserver_key_path=\"tls/server.key.pem\"\nserver_key_passphrase=\"test\"\nserver_dh_path=\"tls/dh1024.pem\"\nclient_certs_path=\"tls/clients\"\n</code></pre> <p>or in <code>config-tls.toml</code> for V23.0 and later:</p> <pre><code>enable_https=true\nenable_wss=true\nverbose_logging=true\nserver_cert_path=\"/node/server.cert.pem\"\nserver_key_path=\"/node/server.key.pem\"\nserver_key_passphrase=\"test\"\nserver_dh_path=\"/node/dh1024.pem\"\n</code></pre>","title":"Configuration"},{"location":"running-a-node/configuration-https/#testing-with-a-self-signed-server-certificate","text":"<p>The <code>server_cert_path</code> setting can be a single server certificate, or a chain file if using an intermediate CA.</p> <p>In this test, we'll generate a self-signed certificate. There are many ways to do this, but here we use openssl's <code>req</code> command to generate a certificate and a password protected keyfile:</p> <p><code>openssl req -newkey rsa:2048 -keyout server.key.pem -x509 -days 3650 -out server.cert.pem</code></p> <p>The passphrase must match the <code>server_key_passphrase</code> toml config setting. Pass <code>-nodes</code> if you don't want a password.</p> <p>OpenSSL will now ask you for certification details. For the server cert, only Common Name is important. Make sure you set it to the fully qualified domain name. While testing, you should add this domain name to your hosts file. <pre><code>Country Name (2 letter code) []:US\nState or Province Name (full name) []:\nLocality Name (eg, city) []:\nOrganization Name (eg, company) []:MyNanoRPCServer\nOrganizational Unit Name (eg, section) []:MyNanoThing\nCommon Name (eg, fully qualified host name) []:www.example.com\nEmail Address []:\n</code></pre></p> <p>We also need to generate a Diffie-Hellman params file:</p> <p><code>openssl dhparam -out dh1024.pem 1024</code></p>","title":"Testing with a self-signed server certificate"},{"location":"running-a-node/configuration-https/#test-call","text":"<p>Create a POST request to <code>https://www.example.com:7076</code> with the following body: <pre><code>{\n    \"action\": \"block_count\"\n}\n</code></pre></p> <p>If using <code>curl</code>, self-signed certificates requires the --insecure flag.</p>","title":"Test call"},{"location":"running-a-node/configuration-https/#client-certificates-optional","text":"<p>If a directory is specified in <code>client_certs_path</code>, only clients with trusted client certificates will be able to connect. By trusted, we mean any client with a client certificate that's also installed in <code>client_certs_path</code>.</p> <p>Revoking access can be done by removing the client certificate file from the node.</p>","title":"Client certificates (optional)"},{"location":"running-a-node/configuration-https/#generate-and-install-client-certificates","text":"<p>Repeat the following process for each client/user you want to grant access:</p> <p><code>openssl req -newkey rsa:2048 -nodes -keyout rpcuser1.key.pem -x509 -days 365 -out rpcuser1.cert.pem</code></p> <p>The Common Name must be unique and should be something descriptive, like \"rpc.user.1\"</p> <p>For efficiency reasons, the client certificate must be renamed to its subject hash (or use a softlink)</p> <pre><code>openssl x509 -in rpcuser1.cert.pem -noout -subject_hash\n 0fb8533c\nln -s rpcuser1.cert.pem 0fb8533c.0\n</code></pre> <p>Distribute the client certificate and key file to the RPC user.</p>","title":"Generate and install client certificates"},{"location":"running-a-node/configuration-https/#testing-client-certificates-with-postman","text":"<p>Use the full version of Postman, not the Chrome extension. In settings, select the Certificates tab. Add the <code>cert.pem</code> and <code>key.pem</code> files.</p> <p>The hostname must be the same as the hostname used in Common Name when generating the server certificate. Add this hostname to your hosts file if it's different from the machine hostname.</p> <p>If you get an error, check the node log file. Make sure the client certificates are installed.</p>","title":"Testing client certificates with Postman"},{"location":"running-a-node/configuration-https/#single-pem-file","text":"<p>Some clients may want a single PEM file:</p> <p><code>cat rpcuser1.cert.pem rpcuser1.key.pem &gt; rpcuser1.pem</code></p>","title":"Single PEM file"},{"location":"running-a-node/configuration/","text":"<p>The Nano node software is designed to run with little or no configuration. All configuration options have defaults that can be changed using TOML configuration files, by passing configuration values via the command line, or a combination of the two methods.</p>  <p>Automatic migration and backups of JSON files</p> <p>Versions prior to 20 use JSON as the configuration file format, and these will be automatically migrated to TOML files on startup. Note that only non-default values are migrated.</p> <p>In version 19.0 when the node is upgraded between releases, including any beta releases, all config files will be backed up prior to the upgrade in the same directory for easy recovery if needed.</p> <p>As TOML files are never upgraded by the node, no backups are created for these.</p>   V19.0 and earlier config.json file <p>Below is a complete example of the config.json file used by V19.0 and earlier:</p> <pre><code>{\n    \"version\": \"(int)\", // Wallet version\n    \"wallet\": \"(string)\", // Default wallet to load on boot (only for GUI wallet)\n    \"account\": \"(string)\", // Default account to load on boot (only for GUI wallet)\n    \"node\": {\n        \"version\": \"(int)\", // Node version\n        \"peering_port\": \"7075\", // Default node port\n        \"bootstrap_fraction_numerator\": \"1\",\n        \"enable_voting\": \"false\", // Enable or disable voting for blocks. If disabled, saves some resources\n        \"receive_minimum\": \"1000000000000000000000000\", // Minimum import receivable, default 1 Rai\n        \"logging\": {\n            \"ledger\": \"false\", // Track incoming blocks\n            \"ledger_duplicate\": \"false\",\n            \"network\": \"true\", // Track general network info like forks\n            \"network_timeout\": \"false\", // Track TCP socket disconnections due to timeout\n            \"network_message\": \"false\",\n            \"network_publish\": \"false\", // Track blocks you publish to\n            \"network_packet\": \"false\", // Track packets origin\n            \"network_keepalive\": \"false\", // Track keepalive messages\n            \"network_node_id_handshake\": \"false\", // Track node_id messages\n            \"node_lifetime_tracing\": \"false\",\n            \"insufficient_work\": \"true\",\n            \"bulk_pull\": \"false\", // Bootstrap related logging\n            \"work_generation_time\": \"true\",\n            \"log_to_cerr\": \"false\",\n            \"max_size\": \"16777216\", // Max size of logs before old files deletion. Default is 16MB\n            \"rotation_size\": \"4194304\", // Size of Log File before rotation in bytes, Default is 4MB\n            \"version\": \"(int)\", // Logging config version\n            \"vote\": \"false\", // Track voting activities\n            \"flush\": \"true\",  // Setting this to false gives better performance, but may lose entries on crashes.\n            \"upnp_details\": \"false\", // Determines if upnp discovery details are logged (default off to avoid sharing device info when shipping logs)\n            \"timing\": \"false\", // Logs durations of key functions, such as batch verification, etc.\n            \"log_ipc\": \"true\", // Logging of IPC related messages\n            \"min_time_between_output\": \"5\", // Minimum time between log calls, in ms\n            \"single_line_record\": \"false\" // Log each record in single line (including block content &amp; election results with votes)\n        },\n        \"vote_minimum\": \"1000000000000000000000000000000000\",// Prevents voting if delegated weight is under this threshold\n        \"work_peers\": \"\", // Delegate a node your hash work, you need to get RPC access to that node\n        \"preconfigured_peers\": [ // List of defaults peers to connect on boot\n            \"peering.nano.org\",\n            \"::ffff:138.201.94.249\"\n        ],\n        \"preconfigured_representatives\": [ // List of defaults representatives, which you delegate voting weight, of your wallet\n            \"nano_3arg3asgtigae3xckabaaewkx3bzsh7nwz7jkmjos79ihyaxwphhm6qgjps4\",\n            \"nano_1stofnrxuz3cai7ze75o174bpm7scwj9jn3nxsn8ntzg784jf1gzn1jjdkou\",\n            \"nano_1q3hqecaw15cjt7thbtxu3pbzr1eihtzzpzxguoc37bj1wc5ffoh7w74gi6p\",\n            \"nano_3dmtrrws3pocycmbqwawk6xs7446qxa36fcncush4s1pejk16ksbmakis78m\",\n            \"nano_3hd4ezdgsp15iemx7h81in7xz5tpxi43b6b41zn3qmwiuypankocw3awes5k\",\n            \"nano_1awsn43we17c1oshdru4azeqjz9wii41dy8npubm4rg11so7dx3jtqgoeahy\",\n            \"nano_1anrzcuwe64rwxzcco8dkhpyxpi8kd7zsjc1oeimpc3ppca4mrjtwnqposrs\",\n            \"nano_1hza3f7wiiqa7ig3jczyxj5yo86yegcmqk3criaz838j91sxcckpfhbhhra1\"\n        ],\n        \"online_weight_minimum\": \"60000000000000000000000000000000000000\", // Online weight minimum required to confirm block\n        \"online_weight_quorum\": \"50\", // Percentage of votes required to rollback blocks\n        \"password_fanout\": \"1024\",\n        \"io_threads\": \"4\",\n        \"work_threads\": \"4\", // PoW work threads. By default all available CPU threads, set lower value for 24/7 services\n        \"callback_address\": \"::ffff:127.0.0.1\", // Callback IP address, in sample IPv4 localhost\n        \"callback_port\": \"17076\", // Callback port\n        \"callback_target\": \"/\", // Callback target, in sample root of callback listening server\n        \"bootstrap_connections\": \"16\", // Multi-connection bootstrap. Should be a power of 2.\n        \"bootstrap_connections_max\": \"4\", // Allowed incoming bootstrap connections count. Lower value save IOPS &amp; bandwidth. 64 recommended for high-end fast nodes, 0 for HDD home users,\n        \"lmdb_max_dbs\": \"128\", // Maximum open DBs (MAX_DBS https://lmdb.readthedocs.io/en/release/), increase default if more than 100 wallets required\n        \"block_processor_batch_max_time\": \"5000\", // Number of milliseconds the block processor works at a time\n        \"allow_local_peers\": \"false\", // To allow local host peering\n        \"signature_checker_threads\": \"1\", // Number of threads to use for verifying signatures\n        \"unchecked_cutoff_time\": \"14400\", // Number of seconds unchecked entry survives before being cleaned\n        \"tcp_io_timeout\": \"15\", // Timeout in seconds for TCP connect-, read- and write operations\n        \"pow_sleep_interval\": \"0\", // The amount to sleep after each batch of POW calculations. Reduces max CPU usage at the expensive of a longer workgeneration time.\n        \"external_address\": \"::\",\n        \"external_port\": \"0\",\n        \"tcp_incoming_connections_max\": \"1024\", // Allowed incoming TCP connections count\n        \"websocket\": {\n            \"enable\": \"false\",\n            \"address\": \"::1\", // Default IPv6 address to listen on. If using Docker, change address to ::ffff:0.0.0.0 to listen on all interfaces within the container.\n            \"port\": \"7078\"\n        },\n        \"ipc\": { // For more details about these options see the IPC section below\n            \"tcp\": {\n                \"enable\": \"false\",\n                \"port\": \"7077\",\n                \"io_timeout\": \"15\"\n            },\n            \"local\": {\n                \"version\": \"1\",\n                \"enable\": \"false\",\n                \"allow_unsafe\": \"false\",\n                \"path\": \"\\/tmp\\/nano\",\n                \"io_timeout\": \"15\"\n            }\n        },\n        \"diagnostics\": {\n                \"txn_tracking\": {\n                    \"enable\": \"false\", // Tracks lmdb transactions\n                    \"min_read_txn_time\": \"5000\", // Logs stacktrace when read transactions are held longer than this time (milliseconds)\n                    \"min_write_txn_time\": \"500\", // Logs stacktrace when write transactions are held longer than this time (milliseconds)\n                    \"ignore_writes_below_block_processor_max_time\": \"true\" // Ignore any block processor writes less than block_processor_max_time\n                }\n        },\n        \"use_memory_pools\": \"true\", // Improve performance by using memory pools (Note: Memory allocated will be reused but never reclaimed, if having memory issues then try turning this off)\n        \"confirmation_history_size\": \"2048\", // Controls confirmation history size, default setting preserves existing behavior\n        \"bandwidth_limit\": \"5242880\", // Outbound voting traffic limit in bytes/sec after which messages will be dropped\n        \"vote_generator_delay\": \"100\", // Delay in ms before votes are sent out to allow for better bundling of hashes in votes\n        \"vote_generator_threshold\": \"3\", // Defines the point at which the node will delay sending votes for another vote_generator_delay. Allows for more hashes to be bundled under load\n        \"active_elections_size\": \"50000\", // Limits number of active elections in container before dropping will be considered (other conditions must also be satisfied), minimum value allowed is 250.\n        \"conf_height_processor_batch_min_time\": \"50\", // Amount of time in ms to batch setting confirmation heights for accounts during high tps to reduce write I/O bottlenecks.\n        \"backup_before_upgrade\": \"false\", // Backup ledger &amp; wallet databases before each upgrade\n        \"work_watcher_period\": \"5\", // Time between checks for confirmation and re-generating higher difficulty work if unconfirmed, for blocks in the work watcher\n        \"max_work_generate_multiplier\": \"256.0\", // Maximum allowed difficulty multiplier for work generation (double). Used for work_generate RPC requests &amp; internal wallet work watcher\n        \"frontiers_confirmation\": \"auto\" // Mode for force frontiers confirmation. \"auto\" mode (default): If not Principal Representative, start frontier confirmation process every 15 minutes; if Principal Representative, start frontier confirmation process every 3 minutes. \"always\": Start frontier confirmation process every 3 minutes. \"disabled\": Do not start frontier confirmation process\n    },\n    \"rpc_enable\": \"true\", // Enable (in-process or child process) or disable RPC. Out of process rpc servers can still be used if launched manually.\n    \"rpc\": {\n        \"enable_sign_hash\": \"true\",\n        \"version\": \"1\",\n        \"child_process\": {\n            \"enable\": \"false\", // Whether the rpc server is run as a child process rather than in-process\n            \"rpc_path\": \"C:\\\\Users\\\\Wesley\\\\Documents\\\\raiblocks\\\\build\\\\Debug\\\\nano_rpc.exe\", // The nano_rpc executable to run if enabled (Windows example).\n        }\n    },\n    \"opencl_enable\": \"false\", // Enable GPU hashing\n    \"opencl\": {\n        \"platform\": \"0\", // Platform ID\n        \"device\": \"0\", // Device ID\n        \"threads\": \"1048576\"\n    }\n}\n</code></pre>","title":"Node Configuration"},{"location":"running-a-node/configuration/#configuration-file-locations","text":"<p>The node and its related processes will look for the files listed below, either in their default location or the location specified with <code>--data_path</code>. These files are optional. The table includes a command which can be used to generate a documented TOML file with defaults suitable for the system.</p>    Name Description Generated with     <code>config-node.toml</code> Node configuration <code>nano_node --generate_config node</code>   <code>config-rpc.toml</code> RPC configuration <code>nano_node --generate_config rpc</code>   <code>config-nano-pow-server.toml</code> Proof of work server configuration <code>nano_pow_server --generate_config</code>   <code>config-qtwallet.toml</code> Qt developer wallet configuration This file is maintained by the Qt wallet    <p>The default locations of the config files are listed in the table below.</p> Test networkMain networkBeta network      OS Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\NanoTest\\</code>   macOS <code>/Users/&lt;user&gt;/Library/NanoTest/</code>   Linux <code>/home/&lt;user&gt;/NanoTest/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/NanoTest</code>         OS/Build Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\Nano\\</code>   macOS <code>/Users/&lt;user&gt;/Library/Nano/</code>   Linux <code>/home/&lt;user&gt;/Nano/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/Nano</code>         OS Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\NanoBeta\\</code>   macOS <code>/Users/&lt;user&gt;/Library/NanoBeta/</code>   Linux <code>/home/&lt;user&gt;/NanoBeta/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/NanoBeta</code>","title":"Configuration file locations"},{"location":"running-a-node/configuration/#options-formatting","text":"<p>Config options are referred to in the documentation using the format <code>category.option</code> where <code>category</code> can be multiple levels. For example, the <code>node.enable_voting</code> option would correspond to the following entry in the TOML file:</p> <pre><code>[node]\n\n# Enable or disable voting. Enabling this option requires additional system resources, namely increased CPU, bandwidth and disk usage.\n# type:bool\nenable_voting = true\n</code></pre> <p>While a multiple category option like <code>node.websocket.enable</code> would correspond to this TOML file entry:</p> <pre><code>[node.websocket]\n\n# Enable or disable WebSocket server.\n# type:bool\nenable = false\n</code></pre>","title":"Options formatting"},{"location":"running-a-node/configuration/#passing-config-values-on-the-command-line","text":"<p>Instead of changing the config file, config values can be passed in via the <code>--config</code> option, which can be repeated multiple times.</p> <p>Example that enables the RPC and WebSocket servers:</p> <p><code>nano_node --config rpc.enable=true --config node.websocket.enable=true</code></p> <p>The way strings are passed is as follows: v22+ uses quotes (<code>\"</code>) such as:</p> <p><code>nano_node --config node.httpcallback.target=\"api/callback\"</code> Arrays must not have spaces inbetween entries.</p> <p>v21 and earlier must use escaped quotes (<code>\\\"</code>) such as:</p> <p><code>nano_node --config node.httpcallback.target=\\\"api/callback\\\"</code> For backwards compatibility this is also supported in v22+</p>  <p>Mixing config options on the command line and TOML files</p> <p>If a config file exists, config values passed in via the command line will take precedence.</p>","title":"Passing config values on the command line"},{"location":"running-a-node/configuration/#notable-configuration-options","text":"<p>As of V20.0 the sample TOML packaged with the binaries and available for generation via the command line are commented out with descriptions of each option. Where applicable the following integration areas have those options included along with additional context where necessary.</p>","title":"Notable configuration options"},{"location":"running-a-node/configuration/#work-generation","text":"<p>See the Work Generation guide.</p>","title":"Work generation"},{"location":"running-a-node/configuration/#websockets","text":"<p>See the WebSockets Integration guide.</p>","title":"WebSockets"},{"location":"running-a-node/configuration/#rpc","text":"","title":"RPC"},{"location":"running-a-node/configuration/#rpcenable","text":"<p>To enable communication via RPC, set this configuration option in the <code>config-node.toml</code> file.</p> <pre><code>[rpc]\n\n# Enable or disable RPC\n# type:bool\nenable = true\n</code></pre>","title":"rpc.enable"},{"location":"running-a-node/configuration/#enable_control","text":"<p>This configuration option is set in the <code>config-rpc.toml</code> file.</p> <p>Due to their sensitive or dangerous nature, certain RPC calls/options require this setting to be enabled before they can be used. Examples of RPC calls that require this include:</p> <ul> <li>stop: allows you to completely stop the node from running</li> <li>work_generate: allows potential consumption of CPU or GPU resources on the node or attached work peers to generate PoW</li> <li>send: can be used to transfer available funds in the wallet to another account</li> <li>Various other wallet and resource-heavy operations</li> </ul> <pre><code># Enable or disable control-level requests.\n# WARNING: Enabling this gives anyone with RPC access the ability to stop the node and access wallet funds.\n# type:bool\nenable_control = false\n</code></pre>  <p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>Due to the sensitive or dangerous nature of these calls, caution should be used when considering setting <code>enable_control</code> to <code>true</code> in your config file. It is highly recommended to only enable this when RPC ports are listening exclusively to local or loopback IP addresses or other measure are put in place outside the node to limit RPC access to dangerous calls. For more details see the Node Security page.</p>  <p>More advanced options for controlling the process the RPC server runs under can be found in the Running Nano as a service guide.</p>","title":"enable_control"},{"location":"running-a-node/configuration/#loggingstable_log_filename","text":"Known Issue Windows V21: Crash when using config <code>node.logging.stable_log_filename</code> <p>Setting <code>node.logging.stable_log_filename</code> configuration option to <code>true</code> results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to <code>false</code>.</p>  <p>This configuration option is set in the <code>config-node.toml</code> file.</p> <p>By default this option is set to <code>false</code> which results in all log files having a timestamp appended to them, even the currently active file. If set to <code>true</code> the currently active log file will have a static name at <code>log/node.log</code> for easier management.</p> <pre><code>[node.logging]\n\n# Append to log/node.log without a timestamp in the filename.\n# The file is not emptied on startup if it exists, but appended to.\n# type:bool\nstable_log_filename = true\n</code></pre>","title":"logging.stable_log_filename"},{"location":"running-a-node/configuration/#logginglog_rpc","text":"<p>This configuration option is set in the <code>config-rpc.toml</code> file.</p> <p>By default, all RPC calls and the time spent handling each one are logged. This can be optionally turned off by switching option <code>logging.log_rpc</code> to <code>false</code></p> <pre><code>[logging]\n\n# Whether to log RPC calls.\n# type:bool\nlog_rpc = true\n</code></pre>","title":"logging.log_rpc"},{"location":"running-a-node/configuration/#ipc","text":"<p>See the IPC Integration guide.</p>","title":"IPC"},{"location":"running-a-node/configuration/#voting","text":"<p>See the Voting as a Representative guide.</p>","title":"Voting"},{"location":"running-a-node/configuration/#ledger-backends","text":"<p>See the Ledger Management guide.</p>","title":"Ledger backends"},{"location":"running-a-node/configuration/#https-support","text":"<p>See the HTTPS Support guide.</p>","title":"HTTPS support"},{"location":"running-a-node/configuration/#http-callback","text":"<p>Tip</p> <p>When possible, using a WebSocket is recommended as it provides more efficiency, more options for types of information to receive and better control over the volume of notifications with filtering.</p>  <p>These configuration options are set in the <code>config-node.toml</code> file.</p> <pre><code>[node.httpcallback]\n\n# Callback address.\n# type:string,ip\n#address = \"\"\n\n# Callback port number.\n# type:uint16\n#port = 0\n\n# Callback target path.\n# type:string,uri\n#target = \"\"\n</code></pre> <p>JSON POST requests with every confirmed block are sent to the callback server as defined in the config values above: <code>http://callback_address:callback_port&lt;callback_target&gt;</code>. Callback target should include a leading slash.</p> <p>For details on how to integrate using the HTTP callback, see the HTTP Callback section of the Integration Guides.</p>","title":"HTTP callback"},{"location":"running-a-node/configuration/#network-details","text":"Port Type Default Details     7075 TCP Enabled <ul><li>Node bootstrapping server</li><li>Share port configuration in <code>config-node.toml</code>, option <code>node.peering_port</code></li><li>Binds to all adapters; unicast</li><li>Contents: Raw nano protocol stream</li><li>Transmits the ledger to new nodes in bulk</li><li>If blocked other nodes will not be able retrieve the ledger from this node</li></ul>   7076 TCP Disabled <ul><li>RPC server</li><li>Port configurable in <code>config-rpc.toml</code>, option <code>rpc.port</code></li><li>Enable in <code>config-node.toml</code>, option <code>rpc.enable</code> or by starting <code>nano_rpc</code> manually</li><li> Binds to localhost by default for security reasons, configurable in <code>config-rpc.toml</code>, option <code>rpc.address</code>; unicast</li><li>Contents: Unencrypted HTTP requests containing JSON object bodies</li><li>Allows the node to be queried or controlled through HTTP requests</li><li>If blocked the node will not be able to be queried or controlled by HTTP</li><li>WARNING: Exposing this port externally while setting <code>enable_control</code> option to <code>true</code> in configs could expose your wallet, allow the node to be stopped remotely and open your node up to other dangerous activity. See the Node Security page for more details.</li></ul>   7078 TCP Disabled <ul><li>Websocket server</li><li>Port configurable in <code>config-node.toml</code>, option <code>node.websocket.port</code></li><li>Enable in <code>config-node.toml</code>, option <code>node.websocket.enable</code></li><li>Binds to localhost by default due to data throughput potentially being very high; producer-subscriber broadcast</li><li>Contents: Standard websocket frames containing JSON-encoded objects</li><li>See WebSocket Support for details on configuration</li></ul>     <p>UDP disabled by default, deprecated</p> <p>As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined.</p>","title":"Network Details"},{"location":"running-a-node/docker-management/","text":"<p>Docker greatly simplifies node management.  Below we will go over some of the best practices for managing your Docker Image.</p>  <p>Docker Limitations</p> <p>Although Docker is a great choice for many setups, it is not recommended to run a *nix container, such as the officially provided one, on a Windows host - there are known issues with handling ports which prevent proper communication with peers.</p> <p>If planning to use <code>ufw</code> with Docker, note that you may need to prevent Docker from manipulating iptables to properly manage firewall settings.</p>","title":"Docker Management"},{"location":"running-a-node/docker-management/#nano-directory","text":"<p>The Nano directory contains:</p> <ul> <li>Node wallet files (<code>wallets.ldb</code>, <code>wallets.ldb-lock</code>)</li> <li>Configuration files</li> <li>Log files</li> <li>Ledger files (<code>data.ldb</code> and <code>data.ldb-lock</code> for default LMDB, or <code>rocksdb</code> directory with files for optional RocksDB backend)</li> <li>Directory for wallet backups (<code>backup</code>)</li> </ul>  <p>Protect wallet and backup files</p> <p>The built-in node wallet is for use in development and testing only. Those using it should take care in protecting access to the <code>wallets.ldb</code> file and backup files, whether encrypted or not, for added security.</p>  <p>For Docker setups, the <code>${NANO_HOST_DIR}</code> indicated in the steps below will be the location of these files on your host machine.</p>","title":"Nano Directory"},{"location":"running-a-node/docker-management/#managing-the-container","text":"","title":"Managing the Container"},{"location":"running-a-node/docker-management/#starting","text":"<p>The following command will start the node container. Either set the specified environment variables (i.e. <code>NANO_NAME=nano_node</code>) or substitute in explicit values to the <code>docker run</code> command.</p>  <ul> <li> <p><code>${NANO_NAME}</code> - The name that you would like to assign to the docker container.</p> </li> <li> <p><code>${NANO_TAG}</code> - The version of docker image you will be running.</p> </li> <li> <p><code>${NANO_HOST_DIR}</code> - Location on the host computer where the ledger, configuration files, and logs will be stored. The Docker container will directly store files such as config-node.toml and <code>data.ldb</code> into this directory.</p> </li> </ul>  <pre><code>docker run --restart=unless-stopped -d \\\n  -p 7075:7075 \\\n  -p 127.0.0.1:7076:7076 \\\n  -p 127.0.0.1:7078:7078 \\\n  -v ${NANO_HOST_DIR}:/root \\\n  --name ${NANO_NAME} \\\n  nanocurrency/nano:${NANO_TAG}\n</code></pre>    Option Purpose     <code>-d</code> Starts the docker container as a daemon   <code>-p 7075:7075</code> Maps the bootstrapping TCP port   <code>-v ${NANO_HOST_DIR}:/root</code> Maps the host's Nano directory to the guest <code>/root</code> directory   <code>--restart=unless-stopped</code> Restarts the container if it crashes   <code>nanocurrency/nano:${NANO_TAG}</code> Specifies the container to execute with tag   <code>-p 127.0.0.1:7076:7076</code>or <code>-p[::1]:7076:7076</code> Indicates that only RPC commands originating from the host will be accepted. WARNING: Without the proper IP configured here, anyone with access to your system's IP address can control your nano_node.   <code>-p 127.0.0.1:7078:7078</code>or <code>-p[::1]:7078:7078</code> Indicates that only the host can create a connection to the websocket server. Data throughput can be very high depending on configuration, which could slow down the node if available outside the host.    <p>If you wish to use different ports, change the host ports in the <code>docker run</code> command; do not change the ports in the config-node.toml file.</p> <p>This will start the docker container using host ports 7075 and 7076 and put the data in a permanent location in your hosts's home directory, outside the docker container. Upon successful startup, Docker will return the container's full ID. A typical ID will look something like the value below.</p> <pre><code>0118ad5b48489303aa9d195f8a45ddc74a90e8a7209fc67d5483aabf3170d619\n</code></pre>  <p>Note</p> <p>As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined.  For more information, see the network details.</p> <p>On port 7075, only TCP is required since V21.</p>   <p>Warning</p> <p>If you are running multiple nano_node Docker containers, DO NOT share the same <code>${NANO_HOST_DIR}</code>, each nano_node requires its own independent files.</p>","title":"Starting"},{"location":"running-a-node/docker-management/#stopping","text":"<p>To stop your Nano Node:</p> <pre><code>docker stop ${NANO_NAME}\n</code></pre>","title":"Stopping"},{"location":"running-a-node/docker-management/#restarting","text":"<p>If you need to restart your node for any reason:</p> <pre><code>docker restart ${NANO_NAME}\n</code></pre>","title":"Restarting"},{"location":"running-a-node/docker-management/#checking-status","text":"<p>A list of currently running containers can be found by issuing the following command.</p> <pre><code>docker ps\n</code></pre> <pre><code>CONTAINER ID        IMAGE               COMMAND                 CREATED             STATUS              PORTS                                                                      NAMES\n0118ad5b4848        nanocurrency/nano   \"/bin/bash /entry.sh\"   41 seconds ago      Up 56 seconds       0.0.0.0:7075-&gt;7075/tcp, 0.0.0.0:7075-&gt;7075/udp, 127.0.0.1:7076-&gt;7076/tcp   nano_node_1\n</code></pre>","title":"Checking Status"},{"location":"running-a-node/docker-management/#updating-the-docker-image","text":"<p>First, stop the container if it is running.</p> <pre><code>docker stop ${NANO_NAME}\n</code></pre> <p>Then we can download the specific version we need.</p> <p>Pull a version of the nano node <pre><code>docker pull nanocurrency/nano:V22.0\n</code></pre></p> <p>Lastly, we start up the docker container again using the same command but the with new version tag. Alteratively, you can use <code>docker-compose</code>.</p>","title":"Updating the Docker Image"},{"location":"running-a-node/docker-management/#updating-node-configuration","text":"<p>First, stop the container if it is running.</p> <pre><code>docker stop ${NANO_NAME}\n</code></pre>  <p>Warning</p> <p>Modifications made to configuration files while the Docker container is running have no effect until the container is restarted.</p>  <p>You may now edit the configuration files located in <code>${NANO_HOST_DIR}</code> using your preferred text editor.</p> <p>Once modifications are complete, start up the docker container again using the same command.</p>  <p>Enable Voting</p> <p>When setting up a new node, voting is disabled by default in the configuration file and must be manually enabled in order to participate in consensus. See enable_voting configuration option for more details.</p>","title":"Updating Node Configuration"},{"location":"running-a-node/docker-management/#docker-compose","text":"<p>A sample docker-compose.yml is provided to model the same behavior as the docker cli examples above</p> <pre><code>version: '3'\nservices:\n  node:\n    image: \"nanocurrency/nano:${NANO_TAG}\" # tag you wish to pull\n    restart: \"unless-stopped\"\n    ports:\n     - \"7075:7075/udp\"   #udp network traffic (deprecated since V21)\n     - \"7075:7075\"       #tcp network traffic\n     - \"127.0.0.1:7076:7076\" #rpc to localhost only\n     - \"127.0.0.1:7078:7078\" #websocket to localhost only\n    volumes:\n     - \"${NANO_HOST_DIR}:/root\" #path to host directory\n</code></pre>","title":"Docker Compose"},{"location":"running-a-node/docker-management/#docker-entrypoint-support","text":"<p>As of v20.0, the docker entry script has migrated to a command with default arguments: <pre><code>Usage:\n   /entry.sh nano_node [[--]daemon] [cli_options] [-l] [-v size]\n     [--]daemon\n       start as daemon either cli [--daemon] form or short form [daemon]\n     cli_options\n       nano_node cli options &lt;see nano_node --help&gt;\n     -l\n       log to console &lt;use docker logs {container}&gt;\n     -v&lt;size&gt;\n       vacuum database if over size GB on startup\n   /entry.sh bash [other]\n     other\n       bash pass through\n   /entry.sh [*]\n     *\n       usage\n default:\n   /entry.sh nano_node daemon -l\n</code></pre></p>","title":"Docker entrypoint support"},{"location":"running-a-node/docker-management/#docker-user-support","text":"<p>As of v20.0, the docker containers support the --user= and -w= flags.</p> <p>To maintain existing compatibility the Docker containers are being built with <code>USER ROOT</code> and <code>WORK_DIR /root</code></p> <p>The problem with this is that the container ends up writing files to your mounted path as root. Best practices would dictate that since there is no need for privilege escalation we can create a user and run under that context instead.</p> <p>In the event you wish to use the <code>--user=nanocurrency -w=/home/nanocurrency</code> flags the directory you mount should have permissions changed for uid:guid 1000:1000 using <code>sudo chown -R 1000:1000 &lt;local_path&gt;</code> and your mount flag will become <code>-v &lt;local_path&gt;:/home/nanocurrency</code></p> <p>This will be changed to default to <code>USER nanocurrency</code> and <code>WORK_DIR /home/nanocurrency</code> in a future release</p>","title":"Docker USER Support"},{"location":"running-a-node/docker-management/#rpc-calls-to-the-node","text":"<p>You can use the RPC interface on the local host via <code>curl</code> to interact with the node.</p> <p>For example the version of the node:</p> <pre><code>curl -d '{\n  \"action\": \"version\"\n}' http://127.0.0.1:17076\n</code></pre> <p>Or the blockcount:</p> <pre><code>curl -d '{\n  \"action\": \"block_count\"\n}' http://127.0.0.1:17076\n</code></pre>  <p>Tip</p> <p>On some systems it may be necessary to replace <code>127.0.0.1</code> with IPv6 equivalent of <code>[::1]</code> when mapping Docker ports</p>  <p>In addition, you can make use of command-line JSON utilities such as jq to parse and manipulate the structured data retrieved from <code>curl</code>. For example the account information associated with certain block:</p> <pre><code>curl -s -d '{\n  \"action\": \"blocks_info\",\n  \"hashes\": [\"87434F8041869A01C8F6F263B87972D7BA443A72E0A97D7A3FD0CCC2358FD6F9\"],\n  \"json_block\": \"true\" \n}' http://127.0.0.1:7076 | jq \".blocks[].block_account\"\n</code></pre> <p>For other commands, review the RPC Protocol details.</p>","title":"RPC calls to the node"},{"location":"running-a-node/docker-management/#troubleshooting","text":"<p>If you get <code>Error starting userland proxy: port is not a proto:IP:port: 'tcp:[:'.</code> or want to expose IPv4 port, use <code>-p 127.0.0.1:7076:7076</code>. Likewise, if you get <code>curl: (7) Couldn't connect to server</code> when interacting with the node, replace <code>[::1]:7076</code> with <code>127.0.0.1:7076</code>.</p> <p>If you get <code>create ~: volume name is too short, names should be at least two alphanumeric characters.</code> replace the <code>~</code> with the full pathname such as <code>/Users/someuser</code>.</p>","title":"Troubleshooting"},{"location":"running-a-node/ledger-management/","text":"<p>Default and experimental backends available</p> <p>By default the node uses LMDB as the ledger backend, which the first part of this guide is focused on. The second part of the guide covers RocksDB, which is an experimental option available as of v20.0+.</p>","title":"Ledger Management"},{"location":"running-a-node/ledger-management/#ledger-file","text":"<p>The node automatically manages the full Nano ledger in the <code>data.ldb</code> file which can be found in the data directory at these locations:</p> Test networkMain networkBeta network      OS Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\NanoTest\\</code>   macOS <code>/Users/&lt;user&gt;/Library/NanoTest/</code>   Linux <code>/home/&lt;user&gt;/NanoTest/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/NanoTest</code>         OS/Build Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\Nano\\</code>   macOS <code>/Users/&lt;user&gt;/Library/Nano/</code>   Linux <code>/home/&lt;user&gt;/Nano/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/Nano</code>         OS Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\NanoBeta\\</code>   macOS <code>/Users/&lt;user&gt;/Library/NanoBeta/</code>   Linux <code>/home/&lt;user&gt;/NanoBeta/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/NanoBeta</code>       <p>This file will grow in size as the ledger does. As of September 2020 there are over 56 million blocks in the ledger which requires at least 29GB of free space. See hardware recommendations for more preferred node specs.</p>  <p>RocksDB uses many files</p> <p>The above details are for the default LMDB database setup. If using RocksDB, please note that it uses potentially 100s of SST files to manage the ledger so details should be followed from the RocksDB Ledger Backend section below.</p>   <p>Updating the node may require a lengthy ledger upgrade</p> <p>Read the guide further down this page for some tips on how to minimize downtime during an update.</p>","title":"Ledger file"},{"location":"running-a-node/ledger-management/#configuration","text":"<p>Available in Version 21.0+ only</p>  <p>Within the <code>node.lmdb</code> section of the <code>config-node.toml</code> file, the following options can be set to better tune LMDB performance for the available resources.</p>    Option name Details     <code>map_size</code> Allows the map size to be changed (default value is 128GB). This only affects the ledger database.   <code>max_databases</code> Maximum open LMDB databases. Increase default if more than 100 wallets is required. External management is recommended when a large amounts of wallets are required.   <code>sync</code> LMDB environment flags. Applies to ledger, not wallet:<ul><li><code>always</code>: Default (MDB_NOSUBDIR | MDB_NOTLS | MDB_NORDAHEAD).</li><li><code>nosync_safe</code>: Do not flush meta data eagerly. This may cause loss of transactions, but maintains integrity (MDB_NOSUBDIR | MDB_NOTLS | MDB_NORDAHEAD | MDB_NOMETASYNC).</li><li><code>nosync_unsafe</code>: Let the OS decide when to flush to disk. On filesystems with write ordering, this has the same guarantees as nosync_safe, otherwise corruption may occur on system crash (MDB_NOSUBDIR | MDB_NOTLS | MDB_NORDAHEAD | MDB_NOSYNC).</li><li><code>nosync_unsafe_large_memory</code>: Use a writeable memory map. Let the OS decide when to flush to disk, and make the request asynchronous. This may give better performance on systems where the database fits entirely in memory, otherwise it may be slower. Note that this option will expand the file size logically to map_size. It may expand the file physically on some file systems. (MDB_NOSUBDIR | MDB_NOTLS | MDB_NORDAHEAD | MDB_NOSYNC | MDB_WRITEMAP | MDB_MAPASYNC).</li></ul>","title":"Configuration"},{"location":"running-a-node/ledger-management/#bootstrapping","text":"<p>When starting a new node the ledger must be downloaded and kept updated in order to participate on the network properly. This is done automatically via bootstrapping - the node downloads and verifies blocks from other nodes across the network. This process can take hours to days to complete depending on network conditions and hardware specifications.</p>  <p>Restarting node during bootstrapping not recommended</p> <p>It is highly recommended to avoid restarting the node during bootstrapping as this can cause extra delays in the syncing process. An exception can be made when it is very clear from calls to the <code>block_count</code> RPC that block counts are stuck for multiple hours.</p>","title":"Bootstrapping"},{"location":"running-a-node/ledger-management/#tuning-options","text":"<p>Depending on machine and networking resources, the bootstrap performance can be improved by updating the following configuration values in the <code>config-node.toml</code> file:</p> <ul> <li><code>node.bootstrap_connections_max</code>: up to max of <code>128</code></li> <li><code>node.bootstrap_connections</code>: up to max of <code>16</code></li> <li><code>node.bootstrap_initiator_threads</code>: set to <code>2</code></li> </ul> <p>The additional resource usage these options cause should be considered, especially if left during normal operation (after initial bootstrap is complete).</p>","title":"Tuning options"},{"location":"running-a-node/ledger-management/#downloaded-ledger-files","text":"<p>Always backup your ledgers file</p> <p>Whenever you are attempting to change the ledger, it is highly recommended you create backups of the existing <code>data.ldb</code> file to ensure you have a rollback point if issues are encountered.</p>  <p>To avoid bootstrapping times, a ledger file (<code>data.ldb</code>) can be downloaded off-network and added to the data file used by the node. This process is sometimes referred to as a \"fast sync\". The Nano Foundation uploads a new ledger file every other day for downloading in the <code>#ledger-download</code> channel of our Discord server. This is posted by the robot <code>Nano Snapshots Uploader</code> and contains checksums for validation.</p> <p>Before using this method there are a few considerations to ensure it is done safely:</p>","title":"Downloaded ledger files"},{"location":"running-a-node/ledger-management/#data-source","text":"<p>Make sure you trust the source providing the data to you. If you are unfamiliar with the individual or organization providing the ledger, consider other options for the data or fallback to the default of bootstrapping from the network.</p>","title":"Data source"},{"location":"running-a-node/ledger-management/#validating-blocks-and-voting-weights","text":"<p>Blocks are confirmed using the voting weight of representatives and these weights are determined by the account balances assigned to those representatives. In addition, the node releases contain a hard-coded set of representative weights captured at the time of the node release to help this process during bootstrapping.</p> <p>If looking to use a downloaded ledger there is a risk of it providing inaccurate representative voting weights. Although the potential impacts of this are minimal, below are some recommended steps to take which can help provide additional confidence the ledger can be used.</p> <ol> <li>Scan the ledger for integrity using the <code>--debug_validate_blocks</code> CLI command. If issues are found they should be inspected carefully and alternative sources of a ledger may need to be considered as failures with this command have a high chance of indicating potentially malicious behavior.</li> <li>Review the differences in representative voting weights by running the <code>--compare_rep_weights</code> CLI command (v21.0+ only) with the new ledger in the default data directory (old ledger backed up) or in a different data directory by using the optional <code>--data_path</code> argument. This will compare the new ledger voting weights against the hardcoded values in the node (set at the time of release). See the CLI command for details on the output with special attention paid to entries in the <code>outliers</code> and <code>newcomers</code> sections. By inspecting those addresses in public explorers such as Nanocrawler.cc, this can help to determine if voting weight may have been manipulated in the downloaded ledger.</li> </ol> <p>If you need support with this process or need help in evaluating some of the CLI command results, join the Node and Representative Management category on the Nano Forums.</p>","title":"Validating blocks and voting weights"},{"location":"running-a-node/ledger-management/#confirmation-data","text":"<p>Within each account on the ledger a confirmation height is set. This indicates the height of the last block on that chain where quorum was observed on the network. This is set locally by the node and a new ledger file may include this information with it. If the ledger is from a trusted source this confirmation data can be kept, which will save bandwidth and resources on the network by not querying for votes to verify these confirmations.</p> <p>If confirmation data for the ledger is not trusted the --confirmation_height_clear CLI can be used to clear these out.</p>","title":"Confirmation data"},{"location":"running-a-node/ledger-management/#updating-the-node","text":"<p>Occasionally, updating to the latest node version requires upgrading the existing ledger which can have the following effects:</p> <ul> <li>Significant downtime, from a few minutes to several hours, during which the node RPC is not accessible and no voting occurs. The upgrade is especially slower if the ledger is not on an SSD.</li> <li>Temporary increased disk space usage - up to 3x the current ledger size in total (e.g. 60GB for a 20GB ledger)</li> </ul> <p>In order to minimize downtime, consider performing the update in a different machine, and replacing the ledger file once complete. Note the following instructions, where Machine A has the node and ledger, and Machine B will be updating it.</p> <ol> <li>Create a directory <code>/home/&lt;user&gt;/Nano_Update</code> on Machine B.</li> <li>Stop the node on Machine A.</li> <li>If enough free space (at least <code>data.ldb</code> size) is available on Machine A:<ul> <li>Make a local copy of <code>data.ldb</code> in any directory.</li> <li>Start the node again on Machine A, resuming operation.</li> <li>Move the local copy of the ledger from Machine A to <code>/home/&lt;user&gt;/Nano_Update/data.ldb</code> on Machine B.</li> <li>Skip the next step.</li> </ul> </li> <li>If there is not enough free space on Machine A:<ul> <li>Copy <code>data.ldb</code> from Machine A to <code>/home/&lt;user&gt;/Nano_Update/data.ldb</code> on Machine B.</li> <li>Start the node again on Machine A, resuming operation.</li> </ul> </li> <li>Download the latest node version to Machine B. For the purposes of this guide, using a binary is easier.</li> <li>Run the following command on Machine B (varies based on your operating system): <code>./nano_node --debug_block_count --data_path /home/&lt;user&gt;/Nano_Update --config node.logging.log_to_cerr=true</code></li> <li>The message \"Upgrade in progress...\" will be displayed if a ledger upgrade is required. Wait until the command finishes and do not stop the upgrade preemptively.</li> <li>Copy <code>/home/&lt;user&gt;/Nano_Update/data.ldb</code> from Machine B to a temporary location on Machine A. do not overwrite data.ldb on Machine A while the node is running.</li> <li>Stop the node on Machine A.</li> <li>Replace <code>/home/&lt;user&gt;/Nano/data.ldb</code> with the transferred file.</li> <li>Upgrade to the latest node version on Machine A as you would do normally.</li> </ol> <p>In the event that you are unable to upgrade the ledger on another machine but would still like to minimize downtime, consider obtaining the ledger from another source as a last resource.</p>","title":"Updating the node"},{"location":"running-a-node/ledger-management/#rocksdb-ledger-backend","text":"<pre><code>If you are testing RocksDB and want to discuss results, configurations, etc. please join the forum topic here: https://forum.nano.org/t/rocksdb-ledger-backend-testing/111\n</code></pre> <p>The node ledger currently uses LMDB (Lightning memory-mapped database) by default as the data store. As of v20+ the option to use RocksDB became available as an experimental option. In v22+ it is now suitable for production environments. This document will not go into much detail about theses key-value data stores as there is a lot of information available online.</p>","title":"RocksDB Ledger Backend"},{"location":"running-a-node/ledger-management/#enable-rocksdb","text":"<p>This can be enabled by adding the following to the <code>config-node.toml</code> file:</p> <pre><code>[node.rocksdb]\nenable = true\n</code></pre> <p>The other options are: <pre><code>io_threads = 4\nmemory_multiplier = 2\n</code></pre> It shouldn't be necessary to update these variables manually. See TOML comments in the generated file for more information on what these do.</p>","title":"Enable RocksDB"},{"location":"running-a-node/ledger-management/#migrating-existing-ledger-from-lmdb-to-rocksdb","text":"<p>An existing LMDB ledger can be upgraded by running the --migrate_database_lmdb_to_rocksdb CLI command. This process can take some time, estimates range from 20 minutes to 1 hour depending on node hardware specs. There are some internal checks which are made to determine if the migration was successful, however it is recommended to run the node first (after enabling RocksDB) for a period of time to make sure things are working as expected. After which the <code>data.ldb</code> file can be deleted if no longer required to save on disk space. Please also note the limitations most notably is that the <code>unchecked_count</code> from the <code>block_count</code> RPC will only be an estimate.</p> <p>Ledger backend comparison:</p>    LMDB RocksDB     Tested with the node for many years Recently implemented   1 file (data.ldb) 100+ SST files   Ledger size won't shrink without manual vacuum Will shrink automatically when using pruning   Unlikely to be further optimized More likely to be optimized in future   - Less file I/O (writes are flushed in bulk)   - More CPU heavy    <p>* At the time of writing (Oct 2019)</p>","title":"Migrating existing ledger from LMDB to RocksDB"},{"location":"running-a-node/ledger-management/#rocksdb-limitations","text":"<ul> <li>Automatic backups not currently supported</li> <li>Database transaction tracker is not supported</li> <li>Cannot execute CLI commands which require writing to the database while a node is running, such as <code>nano_node --peer_clear</code>, these must be executed when the node is stopped</li> <li>The <code>unchecked_count</code> from the <code>block_count</code> RPC &amp; telemetry from RocksDB nodes will only be an estimate.</li> </ul>  <p>Snapshotting with RocksDB</p> <p>When backing up using the --snapshot CLI option, it is currently set up to do incremental backups, which reduces the need to copy the whole database. However if the original files are deleted, then the backup directory should also be deleted otherwise there can be inconsistencies.</p>","title":"RocksDB Limitations:"},{"location":"running-a-node/node-setup/","text":"<p>The following guide will help you get started running a nano node on the various network available. If you haven't already, reviewing both the overview and security pages of this running a node section is highly encouraged.</p>","title":"Node Setup"},{"location":"running-a-node/node-setup/#overview-and-node-lifecycle","text":"<p>The simplest process for setting up a node includes configuring a machine with the proper TCP port open to the internet for your chosen network and running a build of the node software you generated or which was published by the Nano Foundation. Beyond that there are various methods for monitoring, querying and integrating with the node for specific cases.</p> <p>The lifecycle of a new node is helpful to understand at a high level, with plenty of additional detail to be discovered here in the documentation:</p> <ul> <li>On startup the node will discover other nodes on the network through the peering process, becoming aware of and establishing connections to hundreds of them.</li> <li>Before a new node can fully participate on the network, it must bootstrap the ledger from its peers by requesting chains of blocks starting from the genesis block up to more recent blocks.</li> <li>As the ledger is built out the node works to gain consensus on blocks by requesting votes from representatives on the network - once enough voting weight is received for a block it is considered confirmed and unchangeable in the ledger.</li> <li>Before the ledger is built out and blocks are confirmed, the node can be queried but may return partial data, and it will only participate in certain activities. Once the ledger is synced with the rest of the network and stays synced, it can fully participate.</li> </ul> <p>In addition to the lifecycle details and processes mentioned above, it can be helpful to know the different between accounts, keys, seeds and wallet IDs in nano and how they are used. Also understanding the different blocks and transaction types is useful as you work with the node.</p>","title":"Overview and node lifecycle"},{"location":"running-a-node/node-setup/#choose-a-network","text":"<p>There are three networks the Nano Foundations published builds for:</p>    Network name Purpose Do funds have value?     Test network Used for basic integration testing, no load testing No, test nano has no value   Main network Primary network that exchanges and services integrate with Yes   Beta network Experimental network used to test new features and do load and performance testing No, beta nano has no value    <p>If you are just looking to try out and experiment with basic node setup, we recommend setting up on the test network first and then exploring the beta and main networks after.</p> <p>At this point if you know which network you want to setup a node for, have a machine with the proper hardware specifications, understand how to manage ports and firewall settings on it and are comfortable with the maintenance requirements, you should be ready to get started!</p>","title":"Choose a network"},{"location":"running-a-node/node-setup/#configure-network-ports","text":"<p>The node has a few configurable ports it may use throughout its lifecycle, but at a minimum the port for the live network and bootstrap traffic over TCP must be open to the internet for proper connectivity. The port numbers vary based on the network being joined:</p> Test networkMain networkBeta network      Port Protocol Required? Purpose     17075 TCP Yes, open to all traffic For live network activity and bootstrap network activity.   17076 TCP No, recommended For communication with RPC server. Do not expose this outside of your production environment. Anyone with access to this port can control your node's RPC.   17077 TCP No, optional For communication via IPC (advanced). See IPC integration guide for more details.   17078 TCP No, optional For communication with websocket server. Depending on configuration, data throughput can be very high.         Port Protocol Required? Purpose     7075 TCP Yes, open to all traffic For live network activity and bootstrap network activity.   7076 TCP No, recommended For communication with RPC server. Do not expose this outside of your production environment. Anyone with access to this port can control your node's RPC.   7077 TCP No, optional For communication via IPC (advanced). See IPC integration guide for more details.   7078 TCP No, optional For communication with websocket server. Depending on configuration, data throughput can be very high.         Port Protocol Required? Purpose     54000 TCP Yes, open to all traffic For live network activity and bootstrap network activity.   55000 TCP No, recommended For communication with RPC server. Do not expose this outside of your production environment. Anyone with access to this port can control your node's RPC.   56000 TCP No, optional For communication via IPC (advanced). See IPC integration guide for more details.   57000 TCP No, optional For communication with websocket server. Depending on configuration, data throughput can be very high.        <p>By default the node will attempt to use UPnP. Troubleshooting information can be found here</p>","title":"Configure network ports"},{"location":"running-a-node/node-setup/#get-a-build","text":"<p>There are three main options for nano node builds:</p> <ul> <li>Generating your own build (advanced)</li> <li>Using a binary build published by the Nano Foundation (see below)</li> <li>Running a Docker container published by the Nano Foundation (see below)</li> </ul> <p>Using Docker is recommended for most implementations due to the ease of upgrading and maintenance, so this guide will focus on setting up a node using that method. If you are not familiar with Docker, we recommend checkout out the official Docker documentation and other related resources to gain some knowledge before moving forward.</p>  <p>Docker Limitations</p> <p>Although Docker is a great choice for many setups, it is not recommended to run a *nix container, such as the officially provided one, on a Windows host - there are known issues with handling ports which prevent proper communication with peers.</p> <p>If planning to use <code>ufw</code> with Docker, note that you may need to prevent Docker from manipulating iptables to properly manage firewall settings.</p>  Test networkMain networkBeta network      OS Download link/command     Universal Linux https://repo.nano.org/test/binaries/nano-node-V23.0-Linux.tar.bz2   Debian https://repo.nano.org/test/binaries/nano-node-V23.0-Linux.deb   macOS https://repo.nano.org/test/binaries/nano-node-V23.0-Darwin.dmg   Windows (exe) https://repo.nano.org/test/binaries/nano-node-V23.0-win64.exe   Windows (zip) https://repo.nano.org/test/binaries/nano-node-V23.0-win64.zip   Docker <code>docker pull nanocurrency/nano-test:V23.0</code>   RHEL/CentOS rpm Not available for the test network         OS Download link/command Verification     Universal Linux https://repo.nano.org/live/binaries/nano-node-V23.0-Linux.tar.bz2 SHA256 Checksum   Debian https://repo.nano.org/live/binaries/nano-node-V23.0-Linux.deb SHA256 Checksum   macOS https://repo.nano.org/live/binaries/nano-node-V23.0-Darwin.dmg SHA256 Checksum   Windows (exe) https://repo.nano.org/live/binaries/nano-node-V23.0-win64.exe SHA256 Checksum   Windows (zip) https://repo.nano.org/live/binaries/nano-node-V23.0-win64.zip SHA256 Checksum   Docker <code>docker pull nanocurrency/nano:V23.0</code>See Pulling the Docker Image for more details.    RHEL/CentOS rpm <code>sudo rpm -iUvh https://repo.nano.org/live/binaries/nanocurrency-23.0-26.el7.x86_64.rpm</code>This installs <code>nano_node</code> and <code>nano_rpc</code> to <code>/usr/bin</code>. SHA256 Checksum      <p>Join the nano Discord server and head to the <code>#beta-announcements</code> channel for the latest build details.</p>","title":"Get a build"},{"location":"running-a-node/node-setup/#docker-setup","text":"","title":"Docker setup"},{"location":"running-a-node/node-setup/#step-1-install-docker","text":"<p>Docker must be installed on the host machine and instructions can be found here: https://docs.docker.com/install/. We recommend installing the latest stable version available.</p>","title":"Step 1: Install Docker"},{"location":"running-a-node/node-setup/#step-2-pull-the-docker-image","text":"<p></p> <p>The Docker image can be downloaded via <code>docker pull</code> for a specific version/tag.</p> Test networkMain networkBeta network   <pre><code>docker pull nanocurrency/nano-test:V22.1\n</code></pre>   <pre><code>docker pull nanocurrency/nano:V22.1\n</code></pre>   <pre><code>docker pull nanocurrency/nano-beta:V22.1\n</code></pre> <p>Please see the Beta Network page if you plan to join this network.</p>     <p>Warning - Multiple Node Setups</p> <p>Never use the same seed on multiple running nano node instances at the same time.</p> <ul> <li>Multiple nano nodes using the same seed can result in network race conditions that degrade performance for your personal accounts.</li> <li>In addition, publishing transactions from two nodes with the same account at the same time may cause an account fork which requires a slower representative voting process.</li> <li>Similarly, if you are running a representative account on multiple nodes, they may publish conflicting votes, causing your representative to be ignored by the network.</li> <li>Performance degradation in enterprise environments may be significant.</li> </ul>","title":"Step 2: Pull the Docker Image"},{"location":"running-a-node/node-setup/#step-3-start-the-node","text":"<p>The following command will start the node container. Either set the specified environment variables (i.e. <code>NANO_NAME=nano_node_container</code>) or substitute in explicit values to the <code>docker run</code> command.</p> <p><code>${NANO_NAME}</code> - The name that you would like to assign to the docker container, <code>nano_node_container</code> can be used to avoid ambiguity with the commands made to the <code>nano_node</code> process.</p> <p><code>${NANO_TAG}</code> - The version you will be running from the Docker tag section above (i.e. <code>V22.1</code>).</p> <p><code>${NANO_HOST_DIR}</code> - Location on the host computer where the ledger, configuration files, and logs will be stored. The Docker container will directly store files such as <code>config-node.toml</code>, <code>config-rpc.toml</code> and <code>data.ldb</code> into this directory.</p> Test networkMain networkBeta network   <pre><code>docker run --restart=unless-stopped -d \\\n  -p 17075:17075 \\\n  -p 127.0.0.1:17076:17076 \\ # (1)\n  -p 127.0.0.1:17078:17078 \\ # (2)\n  -v ${NANO_HOST_DIR}:/root \\\n  --name ${NANO_NAME} \\\n  nanocurrency/nano-test:${NANO_TAG}\n</code></pre> <ol> <li>Port 17076 is optional, but recommended, for querying via RPC</li> <li>Port 17078 is optional for connecting via WebSockets</li> </ol>   <pre><code>docker run --restart=unless-stopped -d \\\n  -p 7075:7075 \\\n  -p 127.0.0.1:7076:7076 \\ # (1)\n  -p 127.0.0.1:7078:7078 \\ # (2)\n  -v ${NANO_HOST_DIR}:/root \\\n  --name ${NANO_NAME} \\\n  nanocurrency/nano:${NANO_TAG}\n</code></pre> <ol> <li>Port 7076 is optional, but recommended, for querying via RPC</li> <li>Port 7078 is optional for connecting via WebSockets</li> </ol>   <pre><code>docker run --restart=unless-stopped -d \\\n  -p 54000:54000 \\\n  -p 127.0.0.1:55000:55000 \\ # (1)\n  -p 127.0.0.1:57000:57000 \\ # (2)\n  -v ${NANO_HOST_DIR}:/root \\\n  --name ${NANO_NAME} \\\n  nanocurrency/nano-beta:${NANO_TAG}\n</code></pre> <ol> <li>Port 55000 is optional, but recommended, for querying via RPC</li> <li>Port 57000 is optional for connecting via WebSockets</li> </ol> <p>See the Beta Network page for further details.</p>     <p>Tip</p> <p>On some systems it may be necessary to replace <code>127.0.0.1</code> with IPv6 equivalent of <code>[::1]</code> when mapping Docker ports</p>","title":"Step 3: Start the Node"},{"location":"running-a-node/node-setup/#step-4-check-the-logs","text":"<p>When the node starts up it will generate log files in the <code>${NANO_HOST_DIR}</code> defined in the <code>docker run</code> command above. All lines will have a date and time prefix such as <code>[2021-Jun-24 08:26:49.331844]:</code>. Below are some common messages seen on startup with brief descriptions of their meanings. The date and time prefixes have been removed from examples below for simplicity.</p> <p><pre><code>Node starting, version: V22.1\n</code></pre>  Verify you are running the correct version Appears at each startup to indicate version number</p> <p><pre><code>Build information: d91016b \"Clang version \" \"12.0.0 (clang-1200.0.32.29)\" \"BOOST 107000\" BUILT \"Jun 21 2021\"\n</code></pre> Various build information starting with the abbreviated git hash of latest commit, Clang and BOOST version information and build date.</p> <p><pre><code>Database backend: LMDB 0.9.25\n</code></pre> Database used for the backend - default LMDB but RocksDB can also be configured.</p> <p><pre><code>Active network: test\n</code></pre>  Verify you are running on the correct network Indicates which of the three network (test, main, beta) the node is running on.</p> <p><pre><code>Work pool running 12 threads \n</code></pre> Number of threads available for generating Proof of Work.</p> <p><pre><code>0 work peers configured\n</code></pre> Work peers setup in the <code>config-node.toml</code> file, option <code>node.work_peers</code>. This is not required if doing local work generation, but is encouraged if planning to do large transaction volumes. See the work generation integration guide for further details.</p> <p><pre><code>Outbound Voting Bandwidth limited to 10485760 bytes per second, burst ratio 3\n</code></pre> Bandwidth limit set in the <code>config-node.toml</code> file, options <code>node.bandwidth_limit</code> and <code>node.bandwidth_limit_burst_ratio</code>.</p> <p><pre><code>Node ID: node_1gh7ghwwquxp9kw7r3p5634p3n8goyf49a3xyzcnbykxge44gjjonmhexd6h\n</code></pre> Ephemeral and unique node ID created on each startup and only used for network communications with other nodes. This is not a valid nano address (notice prefix of <code>node_</code>).</p> <p><pre><code>Starting legacy bootstrap attempt with ID auto_bootstrap_0\n...\nExiting legacy bootstrap attempt with ID auto_bootstrap_0\n</code></pre> Indicates attempts at starting bootstrap activities from other nodes on the network.</p> <p><pre><code>UPnP local address: 10.0.0.115, discovery: 0, IGD search: 1\nUPNP_GetSpecificPortMappingEntry failed 714: NoSuchEntryInArray\nUPnP leasing time getting old, remaining time: 0, lease time: 1787, below the threshold: 893\nUPnP TCP 24.17.20.184:17075 mapped to 17075\n</code></pre> Details of UPnP attempts at mapping ports. See UPnP troubleshooting for further details.</p> <p><pre><code>Found a representative at [::ffff:168.119.169.220]:17075\n</code></pre> Indicates the IP address of a new representative discovered on the network.</p> <p><pre><code>Wallet unlocked\n</code></pre> Certain activities performed by the node, including signing votes, requires unlocking the wallet during operation.</p> <p>The above examples are subset of potential entries in logging.</p>","title":"Step 4: Check the logs"},{"location":"running-a-node/node-setup/#step-5-query-rpc","text":"<p>Once the node is up and running you can query via RPC. Below is a basic command example to return the block counts on the node and example responses. If you are unable to connect to the server, it may be worth trying IPv6 <code>[::1]</code> or <code>localhost</code> instead of <code>http://127.0.0.1</code>.</p> Test networkMain networkBeta network   <p>Request</p> <pre><code>curl -d '{\n  \"action\": \"block_count\"\n}' http://127.0.0.1:17076\n</code></pre> <p>Response <pre><code>{\n    \"count\": \"16599\",\n    \"unchecked\": \"0\",\n    \"cemented\": \"12456\"\n}\n</code></pre></p>   <p>Request</p> <pre><code>curl -d '{\n  \"action\": \"block_count\"\n}' http://127.0.0.1:7076\n</code></pre> <p>Response</p> <pre><code>{\n    \"count\": \"122301952\",\n    \"unchecked\": \"89\",\n    \"cemented\": \"122301952\"\n}\n</code></pre>   <p>Request</p> <pre><code>curl -d '{\n  \"action\": \"block_count\"\n}' http://127.0.0.1:55000\n</code></pre> <p>Response</p> <pre><code>{\n    \"count\": \"48983527\",\n    \"unchecked\": \"0\",\n    \"cemented\": \"48983527\"\n}\n</code></pre>    <p>The <code>count</code> indicates how many blocks are in the ledger total (confirmed and unconfirmed). The <code>unchecked</code> is how many blocks have been downloaded but haven't been verified and inserted into the ledger. These <code>unchecked</code> blocks may or may not be valid and having a count here typically does not indicate any issue. The <code>cemented</code> count is how many blocks have been confirmed.</p> <p>After your node has been running or a few minutes you should see the <code>count</code> increasing. The <code>cemented</code> will being increasing also as resources are available for the node to confirm blocks, but will go up at a slower rate.</p>","title":"Step 5: Query RPC"},{"location":"running-a-node/node-setup/#step-6-monitor-sync-status","text":"<p>It is important to wait for your node to be synced with the network before attempting to setup a representative or send and receive transactions from a wallet it uses. In order to determine when the node should be able to carry out these activities you will want to use the above <code>block_count</code> RPC to see your local <code>count</code> and <code>cemented</code> values, and compare those to other nodes on the network.</p> <p>The fastest way compare is using the 'telemetry' RPC. This will return average/median/mode values from all peers for each of the values nodes share with each other.</p> Test networkMain networkBeta network   <p>Request</p> <pre><code>curl -d '{\n  \"action\": \"telemetry\"\n}' http://127.0.0.1:17076\n</code></pre> <p>Response <pre><code>{\n    \"block_count\": \"16599\",\n    \"cemented_count\": \"16599\",\n    \"unchecked_count\": \"0\",\n    \"account_count\": \"413\",\n    \"bandwidth_cap\": \"10485760\",\n    \"peer_count\": \"8\",\n    \"protocol_version\": \"18\",\n    \"uptime\": \"928162\",\n    \"genesis_block\": \"B1D60C0B886B57401EF5A1DAA04340E53726AA6F4D706C085706F31BBD100CEE\",\n    \"major_version\": \"22\",\n    \"minor_version\": \"1\",\n    \"patch_version\": \"0\",\n    \"pre_release_version\": \"0\",\n    \"maker\": \"0\",\n    \"timestamp\": \"1624923328669\",\n    \"active_difficulty\": \"ffffffe300000000\"\n}\n</code></pre></p>   <p>Request</p> <pre><code>curl -d '{\n  \"action\": \"telemetry\"\n}' http://127.0.0.1:7076\n</code></pre> <p>Response <pre><code>{\n    \"block_count\": \"122270697\",\n    \"cemented_count\": \"122206279\",\n    \"unchecked_count\": \"13045\",\n    \"account_count\": \"25682295\",\n    \"bandwidth_cap\": \"10485760\",\n    \"peer_count\": \"266\",\n    \"protocol_version\": \"18\",\n    \"uptime\": \"1234166\",\n    \"genesis_block\": \"991CF190094C00F0B68E2E5F75F6BEE95A2E0BD93CEAA4A6734DB9F19B728948\",\n    \"major_version\": \"22\",\n    \"minor_version\": \"1\",\n    \"patch_version\": \"0\",\n    \"pre_release_version\": \"0\",\n    \"maker\": \"0\",\n    \"timestamp\": \"1624924581283\",\n    \"active_difficulty\": \"fffffff800000000\"\n}\n</code></pre></p>   <p>Request</p> <pre><code>curl -d '{\n  \"action\": \"telemetry\"\n}' http://127.0.0.1:55000\n</code></pre> <p>Response <pre><code>{\n    \"block_count\": \"48983527\",\n    \"cemented_count\": \"48979917\",\n    \"unchecked_count\": \"81\",\n    \"account_count\": \"3701404\",\n    \"bandwidth_cap\": \"10485760\",\n    \"peer_count\": \"18\",\n    \"protocol_version\": \"18\",\n    \"uptime\": \"2186034\",\n    \"genesis_block\": \"01A92459E69440D5C1088D3B31F4CA678BE944BAB3776C2E6B7665E9BD99BD5A\",\n    \"major_version\": \"22\",\n    \"minor_version\": \"1\",\n    \"patch_version\": \"0\",\n    \"pre_release_version\": \"1\",\n    \"maker\": \"0\",\n    \"timestamp\": \"1624924823965\",\n    \"active_difficulty\": \"fffff00000000000\"\n}\n</code></pre></p>    <p>Although the threshold for being synced can vary based on the level of network activity, typically if your node has <code>count</code> and <code>cemented</code> each within 1% of the network telemetry values, you can consider it in sync. In the example above from the test network the local node has 100% of <code>count</code> vs. other nodes, but only ~75% of <code>cemented</code>. This means it is still working to confirm all available blocks to get in sync.</p> <p>This is a common situation when starting a new node, as it takes time to bootstrap all the blocks and confirm them. As you check the counts over time you should see them both getting closer to the 99% mark, although there may be interruptions in progress lasting minutes to hours or longer.</p> <p>If your node stops making progress on syncing for over 24 hours, try connecting with the nano community for troubleshooting assistance on Discord or the Forum.</p>","title":"Step 6: Monitor sync status"},{"location":"running-a-node/node-setup/#next-steps","text":"<p>Congratulations on getting your node setup and running! We'd recommend joining our mailing list to ensure you get all the latest updates about the protocol and node:</p>  <p>  Technical Update Mailing List Sign up for email updates on the latest protocol/node releases and other technical details including network upgrades. Join Mailing List       </p>  <p>Below are resources to help you take the next step to use your node to interact with and participate on the network:</p> <ul> <li>Get a wallet setup with a seed and accounts</li> <li>Learn more about managing the node in a Docker container</li> <li>Update your node configuration options to enable various features</li> <li>Start voting as a representative</li> <li>Find out how to best manage your ledger file</li> </ul>","title":"Next steps"},{"location":"running-a-node/overview/","text":"<p>Running a node is a key way to help decentralize the network and provide a network access point for systems built on top of nano. Before setting up a node we recommend reviewing the following details in order to understand more about the motivations for running, required upkeep, types and recommended specifications for nodes.</p>","title":"Running a Node Overview"},{"location":"running-a-node/overview/#why-run-a-node","text":"<p>By design, the incentives for running a nano node are not built into the network itself, but instead are external. This is an important difference compared to nearly all other cryptocurrency networks and allows nano to operate securely without transaction fees.12 These indirect, external incentives include the following and more:</p> <ul> <li>Advertising exposure from their representative showing up on curated representative lists</li> <li>Transaction fee savings for businesses and organizations accepting nano as payment</li> <li>Helping support and further decentralize a global payment network</li> <li>Having a trusted access point for building additional software on the network</li> </ul> <p>Regardless of the motivation for running a node, it will only benefit the network if proper care is taken to ensure it is run on correctly provisioned machines and ongoing maintenance of the node, OS and any supporting systems are routinely done.</p>","title":"Why run a node?"},{"location":"running-a-node/overview/#node-types","text":"<p>Dedicated Representative nodes recommended</p> <p>Due to the resources needed to participate in the voting process, it is recommended that any node setup as a Representative should be dedicated to generating consensus. If the resources of the Representative are used for other activities, such as application integrations, it reduces the potential benefit that node brings to the network.</p>   <p>Review Node security guide</p> <p>Regardless of the type of node you are planning to run, make sure to review the Node security guide to ensure best practice with configuration, firewalls and more.</p>","title":"Node types"},{"location":"running-a-node/overview/#non-voting-nodes","text":"<p>When first setting up a node it will not be configured to participate in consensus by voting on traffic. This type of node is common and is recommended for all integrations. If your goal in setting up a node is to learn how to integrate and use nano for payments, this is the best starting point. If you want to dedicate resources to help secure consensus on the network, then a Representative node should be explored.</p>  <p>Representatives and voting</p> <p>For a very brief overview of how representatives and voting works in the nano network, see the What is nano? page. If you're looking to dig deeper, the ORV consensus section of the living whitepaper helps explain further how consensus works.</p>","title":"Non-voting nodes"},{"location":"running-a-node/overview/#representative-nodes","text":"<p>If a node is setup with a Representative account, is configured to vote and has less than 0.1% of online voting weight delegated to them, they are a considered Representative node. These nodes will validate and vote on transactions seen on the network. Their votes will be directly sent to a subset of their peers, but other nodes on the network will not rebroadcast their votes.</p>","title":"Representative nodes"},{"location":"running-a-node/overview/#principal-representative-nodes","text":"<p>Representative nodes with at least 0.1% of the online voting weight delegated to them participate more broadly in network consensus because votes they send to their peers are then rebroadcasted by those nodes as well. These \"PR\" nodes have the most impact to the security and availability of the network so keeping them secure and following maintenance recommendations should be taken seriously.</p>  <p>Becoming a Principal Representative</p> <p>With the ability for any user on the network to redelegate their voting weight, even an account with no weight today can become a Principal Representative over time.</p>","title":"Principal Representative nodes"},{"location":"running-a-node/overview/#hardware-recommendations","text":"<p> Nodes consume CPU, RAM, disk IO and bandwidth IO resources, all of which come at a cost. In order to keep the node participating and in-sync, the recommended specifications for machines based on node type below should be followed.</p>","title":"Hardware recommendations"},{"location":"running-a-node/overview/#principal-representative-nodes_1","text":"<p>The following are minimum recommended specifications for nodes with more than 0.1% of the online voting weight (Principal Representatives):</p> <ul> <li>16GB RAM</li> <li>Quad-Core or higher CPU</li> <li>500 Mbps bandwidth (8TB or more of available monthly bandwidth)</li> <li>SSD-based hard drive with 400GB+ of free space</li> </ul>","title":"Principal Representative Nodes"},{"location":"running-a-node/overview/#non-voting-and-representative-nodes","text":"<p>The following are minimum recommended specifications for non-voting nodes and Representative nodes with less than 0.1% of the online voting weight (regular Representatives):</p> <ul> <li>8GB RAM</li> <li>Quad-Core CPU</li> <li>250 Mbps bandwidth (4TB or more of available monthly bandwidth)</li> <li>SSD-based hard drive with 400GB+ of free space</li> </ul> <p>These lower specifications are also valid for any type of node run on the Beta network and Test network.</p>  <p>Varied resource usage</p> <p>Various factors affect resource usage including how often RPC calls are made, other applications running on the machine, etc. These recommendations should be evaluated along with other considerations.</p>   <p>Work Generation guide</p> <p>For nodes being used with services requiring regular or high volume sending and receiving of transactions, special considerations must be made for handling Proof-of-Work generation activities. Find details on configuring a GPU, external work services and more for the perfect setup in the Work Generation guide.</p>","title":"Non-voting and Representative Nodes"},{"location":"running-a-node/overview/#maintenance","text":"<p>  Technical Update Mailing List Sign up for email updates on the latest protocol/node releases and other technical details including network upgrades. Join Mailing List       </p>  <p>With any system, ongoing maintenance must be taken into account to avoid issues. The following are a few examples of regular activities that should be committed to, especially when running a Representative or Principal Representative node:</p> <ul> <li>Performing OS-level updates and security patches regularly applied</li> <li>Upgrading to the latest node versions as they are available</li> <li>Following best practices for securing passwords or other sensitive data related to the node</li> </ul> <p>Without taking care of the security and maintenance of systems hosting the node, any benefit to the network could be lost. Continue learning about how best to keep the node secure in our Node security guide.</p>   <ol> <li> <p>https://medium.com/nanocurrency/the-incentives-to-run-a-node-ccc3510c2562 \u21a9</p> </li> <li> <p>https://medium.com/@clemahieu/emergent-centralization-due-to-economies-of-scale-83cc85a7cbef \u21a9</p> </li> </ol>","title":"Maintenance"},{"location":"running-a-node/security/","text":"<p>There are many reasons to run a Nano node on the network. Nodes are the participants that help vote on transaction validity, assist other nodes with bootstrapping blocks in the ledger and providing an access point to all accounts. But those who choose to run them should be making a long-term commitment to run them on proper hardware, keep them updated with the latest release and, most importantly, keep their setup as secure as possible.</p>  <p>  Technical Update Mailing List Sign up for email updates on the latest protocol/node releases and other technical details including network upgrades. Join Mailing List       </p>  <p>The details below are guidelines on things to watch out for when setting up and securing your Nano node. As the node can be run on many different operating systems, some of these guidelines have been kept more general. There are plenty of resources online for learning how to apply these guidelines to more specific setups and additional details will be included in the docs here as they are appropriate.</p>","title":"Node Security"},{"location":"running-a-node/security/#node-configuration","text":"","title":"Node configuration"},{"location":"running-a-node/security/#enabling-control","text":"<p>Various RPC calls are marked as requiring the <code>enable_control</code> option to be turned on before they can be called. This extra level of permission to use these RPCs was put in place because the calls can be dangerous in a couple ways:</p> <ul> <li>They can potentially allow access to wallet funds</li> <li>They can consume extra node resources compared to other calls, such as using more disk space or requiring additional computation to complete</li> </ul> <p>By turning <code>enable_control</code> on, anyone with access to your RPC can run these potentially dangerous commands, so it is only recommended with port configurations where RPC access is restricted to local and loopback addresses only. If your RPC is exposed to external or non-loopback addresses, the node will print out warnings to <code>stdout</code> and your logs to help make you aware of potential exposure.</p>","title":"Enabling control"},{"location":"running-a-node/security/#port-configuration","text":"<p>Opening default port <code>7075</code> on TCP is required for the node to participate on the main network and this should be done unrestricted. The default port for RPC access is <code>7076</code> and should only be available to those you wish to have control of the node. Verifying the configuration in <code>config-rpc.toml</code> file for <code>address</code> and <code>enable_control</code> should be done on all nodes, alonside other access verifications outlined below.</p>  <p>Opening RPC port externally and enabling control is potentially dangerous</p> <p>As mentioned above, enabling control allows anyone with RPC access to make potentially dangerous calls to your node. If turning on <code>enable_control</code>, you must carefully review any access granted to the RPC port (default <code>7076</code>) to ensure it is as secure as possible.</p>","title":"Port configuration"},{"location":"running-a-node/security/#firewalls","text":"<p>There are various firewall options available across operating systems. IPTables, PeerBlock, Windows Firewall and others allow you to better control access to your host machine and thus your node. By having a firewall in place you can completely block unused and unnecessary ports, as well as whitelist other ports for access only from trusted IP addresses. Using this in combination with good server access and port configuration practices helps harden your node setup even further.</p>","title":"Firewalls"},{"location":"running-a-node/security/#server-access","text":"<p>Due to the node currently processing all transactions, keeping them running and online as much as possible is recommended, so many operators use dedicated servers or shared servers, often in data centers or cloud providers. When running node on a remote machine, access to that machine should be tightened up in various ways. Some common tips are included below which may or may not apply to your specific system:</p> <ul> <li>Use private/public key pairs exclusively for authentication over SSH, which involves disabling password-based authentication</li> <li>Disable root login entirely</li> <li>Disable remote logins for accounts with an empty password</li> <li>Change default SSH port</li> <li>Use a firewall to whitelist IP access to SSH connections</li> <li>Set timeouts for idle SSH connections</li> <li>Get setup to block SSH brute force attempts automatically with tools like Fail2ban</li> <li>Limit the maximimum authentication attempts allowed</li> <li>Setup alerts and monitoring for SSH connections</li> </ul> <p>Using a variety of these control measures for server access can increase your resistance to unauthorized access to your host machine and help protect your node from interference.</p>","title":"Server access"},{"location":"running-a-node/security/#maintenance","text":"<p>As always the machine hosting the node should have regular maintenance done such as security patches, updates, etc. See Maintenance for more details.</p>","title":"Maintenance"},{"location":"running-a-node/security/#docker-considerations","text":"<p>When running a node in Docker there is an extra layer of port controls between the node in the Docker container and the host machine. The default node configuration provided with Docker images in Docker hub, along with examples in our documentation for commands such as <code>docker run</code>, result in allowing RPC access only to the machine hosting the container. This is the recommended setup for most nodes.</p> <p>To make sure Docker security is understood by any node operator and the setup used is as secure as possible, we recommend reading up on general best practices for using Docker, consider running Docker with non-root USER and verifying external access to RPC calls are controlled sufficiently by the Docker host machine.</p>","title":"Docker considerations"},{"location":"running-a-node/test-network/","text":"<p>The test network exists primarily for the purpose of conducting general integration and node upgrade testing in light volumes. By providing a network with similar parameters to the main network (work difficulty, etc.) this is the best environment for connecting test or staging versions of services and applications to for small scale tests. In order to keep the network as stable as possible, the Nano Foundation will maintain nodes on this network on the latest Release Candidate (RC) or release version, it will not be updated with beta or development features.</p> <p>For load testing and new node releases and features testing, head over to the beta network page where details on how to conduct those types of network-wide testing exist.</p>","title":"Test network"},{"location":"running-a-node/test-network/#running-a-test-node","text":"<p>Setting up a node on the test network is similar to the beta network. To start you should install docker and be familiar with the general setup and Docker management processes.</p>","title":"Running a test node"},{"location":"running-a-node/test-network/#network-ports","text":"Port Protocol Required? Purpose     17075 TCP Yes, open to all traffic For live network activity and bootstrap network activity.   17076 TCP No, recommended For communication with RPC server. Do not expose this outside of your production environment. Anyone with access to this port can control your node's RPC.   17077 TCP No, optional For communication via IPC (advanced). See IPC integration guide for more details.   17078 TCP No, optional For communication with websocket server. Depending on configuration, data throughput can be very high.","title":"Network ports"},{"location":"running-a-node/test-network/#directory-locations","text":"OS Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\NanoTest\\</code>   macOS <code>/Users/&lt;user&gt;/Library/NanoTest/</code>   Linux <code>/home/&lt;user&gt;/NanoTest/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/NanoTest</code>","title":"Directory locations"},{"location":"running-a-node/test-network/#binaries","text":"<p>In addition to the Docker details above, the latest binary builds of the node for the test network can be found below. These will only change when Release Candidates (RC) builds are ready, or when final releases are done. However, the first build available today is actually a development build since the changes to enable this network were recently introduced.</p>    OS Download link/command     Universal Linux https://repo.nano.org/test/binaries/nano-node-V23.0-Linux.tar.bz2   Debian https://repo.nano.org/test/binaries/nano-node-V23.0-Linux.deb   macOS https://repo.nano.org/test/binaries/nano-node-V23.0-Darwin.dmg   Windows (exe) https://repo.nano.org/test/binaries/nano-node-V23.0-win64.exe   Windows (zip) https://repo.nano.org/test/binaries/nano-node-V23.0-win64.zip   Docker <code>docker pull nanocurrency/nano-test:V23.0</code>   RHEL/CentOS rpm Not available for the test network    <p>If manual builds are needed, see the build options page for details.</p>","title":"Binaries"},{"location":"running-a-node/test-network/#pulling-the-docker-image","text":"<p></p> <p>Pulls the latest test release of the nano Node: <pre><code>docker pull nanocurrency/nano-test\n</code></pre></p> <p>Pulls a specific test version of the nano node: <pre><code>docker pull nanocurrency/nano-test:&lt;tag&gt;\n</code></pre></p> <p>A list of test tags can be found at the official Nano Currency Docker Hub</p>","title":"Pulling the Docker image"},{"location":"running-a-node/test-network/#starting-the-docker-container","text":"<pre><code>docker run --restart=unless-stopped -d \\\n  -p 17075:17075 \\\n  -p 127.0.0.1:17076:17076 \\ # (1)\n  -p 127.0.0.1:17078:17078 \\ # (2)\n  -v ${NANO_HOST_DIR}:/root \\\n  --name ${NANO_NAME} \\\n  nanocurrency/nano-test:${NANO_TAG}\n</code></pre> <ol> <li>Port 17076 is optional, but recommended, for querying via RPC</li> <li>Port 17078 is optional for connecting via WebSockets</li> </ol>  <p>Tip</p> <ul> <li>For an explanation of the options included in the Docker <code>run</code> command, see Starting the Container details for the main network.</li> <li>See Docker management for other related commands</li> </ul>   <p>Separate host directories</p> <p>Be sure to use a different host directory for main network, beta network and test network Docker node setups. Attempting to use the same directory will result in issues.</p>","title":"Starting the Docker container"},{"location":"running-a-node/test-network/#getting-test-funds","text":"<p>One you have a node up and running the ledger should bootstrap from the network quickly, and then you just need some test network specific Nano funds. We are currently working on a faucet setup to enable self-service options, but for now please reach out to <code>argakiig#1783</code> on Discord or email infrastructure@nano.org with the account number you would like funds distributed to for the test network.</p>","title":"Getting test funds"},{"location":"running-a-node/troubleshooting/","text":"","title":"Troubleshooting"},{"location":"running-a-node/troubleshooting/#log-files","text":"<p>The default location of standard node log files for various systems:</p>    OS Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\Nano\\log</code> -or- <code>%LOCALAPPDATA%\\Nano\\log</code>   macOS <code>/Users/&lt;user&gt;/Library/Nano/log</code>   Linux <code>/home/&lt;user&gt;/Nano/log</code>     <p>To get a static file name for the currently active log file, see the stable_log_filename configuration option</p>","title":"Log Files"},{"location":"running-a-node/troubleshooting/#what-to-do-if-the-node-crashes-linux","text":"<p>Do not restart the node</p> <p>If your node crashes, please follow this guide before attempting to run it again.</p>  <p>If the node crashes, the most commonly seen message is \"Segmentation fault (core dumped)\". When using docker, this message will only show up in the docker logs. In any case, this is often not enough to go on in terms of figuring out what went wrong. The next steps detail what you should do to provide us with as much information as possible about the problem.</p> <p>When you are done gathering all information, please create a new Github issue, or reach us on Discord in the #support channel, detailing your issue as much as possible.</p>  <p>Getting the latest node log</p> <p>The following command will order the log files such that the first one in the output is the most recent. If you restarted the node since the crash, then the relevant log file is not the latest one. Please be careful to give us the relevant log file.</p> <pre><code># Nano -&gt; NanoBeta if debugging a beta node\nls -dlt ~/Nano/log/* | head\n</code></pre> <p>Please provide the complete log file.</p>  <p>Please follow the steps below for the corresponding node version you are using. Should there be an error obtaining the information in a newer version, the older version steps should then be attempted.</p>","title":"What to do if the node crashes (Linux)"},{"location":"running-a-node/troubleshooting/#v21-nodes","text":"<p>Step 1: Make sure addr2line is installed</p> <p>It is likely installed already, consult documentation for your linux distribution if it is not mentioned below: Ubuntu/Debian <code>apt-get install binutils</code></p> <p>Fedora 22+ <code>dnf install binutils</code></p>   <p>(Optional) Step 2: Save crash dump files</p> <p>The next step will clean up the dump files generated during the crash, if you wish to keep these then save <code>nano_node_backtrace.dump</code>, and all <code>nano_node_crash_load_address_dump_*.txt</code> files.</p>   <p>Step 3: Generate crash report</p> <p>Run: <code>./nano_node --debug_generate_crash_report</code></p> <p>This will generate a text file <code>nano_node_crash_report.txt</code> please send us the contents of this file.</p>","title":"v21+ nodes"},{"location":"running-a-node/troubleshooting/#v20-nodes","text":"<p>Step 1: Getting dmesg information</p> <p>Depending on the error, it is possible you do not find any useful information in this step, in which case please move on to Step 3. Run the following command and look for <code>nano_node</code> at the end. If you see a relevant message, gather all messages with a similar timestamp - the number within brackets on the left.</p> <pre><code>dmesg\n</code></pre> <p>Example output: <pre><code>[    6.336071] IPv6: ADDRCONF(NETDEV_CHANGE): wlp2s0: link becomes ready\n[    6.375123] wlp2s0: Limiting TX power to 23 (23 - 0) dBm as advertised by **:**:**:**:**:**\n[ 6141.711993] show_signal_msg: 23 callbacks suppressed\n[ 6141.711995] I/O[14487]: segfault at 1 ip 000055c69d3a1634 sp 00007f6e9332df10 error 6 in nano_node[55c69d25f000+70b000]\n[ 6141.711999] Code: 24 70 48 83 c5 10 48 89 c3 48 39 ef 74 b6 e8 e3 b8 39 00 eb af 90 41 57 41 56 41 55 41 54 49 89 fc 55 53 48 81 ec a8 00 00 00 &lt;c6&gt; 04 25 01 00 00 00 31 64 48 8b 04 25 28 00 00 00 48 89 84 24 98\n</code></pre></p> <p>From this output, only the last 3 lines are relevant.</p>   <p>Step 2: Getting syslog information</p> <p>More information might be available in syslog. Run the following command and look for the time the crash ocurred.</p> <pre><code>cat /var/log/syslog\n</code></pre> <p>Example output: <pre><code>Aug 15 11:56:07 ubuntu-server kernel: [6141.711993] show_signal_msg: 23 callbacks suppressed\nAug 15 11:56:07 ubuntu-server kernel: [6141.711995] I/O[25975]: segfault at 1 ip 000055b2960e2d24 sp 00007fcff50f6fc0 error 6 in nano_node[55b295f9b000+6d8000]\nAug 15 11:56:07 ubuntu-server kernel: [6141.711999] Code: 24 70 48 83 c5 10 48 89 c3 48 39 ef 74 b6 e8 e3 b8 39 00 eb af 90 41 57 41 56 41 55 41 54 49 89 fc 55 53 48 81 ec a8 00 00 00 &lt;c6&gt; 04 25 01 00 00 00 31 64 48 8b 04 25 28 00 00 00 48 89 84 24 98\n</code></pre></p> <p>Include the relevant lines from the output. In this example, the log is similar to the one from Step 2.</p>   <p>Step 3: Getting a backtrace dump</p> <p>This command will produce some basic information about the error.</p> <p>Not using docker: <pre><code>./nano_node --debug_output_last_backtrace_dump &gt; nano_node_backtrace_output.txt\n</code></pre></p> <p>Using docker: <pre><code>mkdir -p /tmp/nano_node_crash &amp;&amp; cd $_\ndocker exec ${NANO_NAME} nano_node --debug_output_last_backtrace_dump &gt; nano_node_backtrace_output.txt\ndocker exec ${NANO_NAME} sh -c 'mkdir -p crash_files; mv nano_node_crash*.txt crash_files/'\ndocker cp ${NANO_NAME}:/crash_files/ . &amp;&amp; mv crash_files/* .\n</code></pre></p>   <p>Step 4: Producing the archive file</p> <p>See the output of this command for the name of the file you should include in your report. <pre><code>FILE=\"nano_node_crash_$(date +\"%Y-%m-%d_%H-%M-%S.tar.gz\")\" &amp;&amp; tar czf $FILE --exclude=*.tar.gz nano_node_* &amp;&amp; echo \"Created archive $FILE\"\n</code></pre></p>","title":"v20 nodes"},{"location":"running-a-node/troubleshooting/#statistics-from-rpc","text":"<p>The \"stats\" RPC command can be used by external processes to query statistics, such as traffic counters. This is useful for diagnostics, monitoring and display in admin consoles. </p> <p>Statistics are optionally logged to separate text files.</p> <p>For implementations details, please see Statistics API</p>  <p>Duplicate observer stats</p> <p>Under certain conditions, confirmations seen through the observer type stat can be duplicates. In order to get accurate data, block hashes must be tracked and validated against previously seen hashes.</p>","title":"Statistics from RPC"},{"location":"running-a-node/troubleshooting/#configuration","text":"<p>All configuration nodes and values are optional, with the default values shown in comments below:</p> <pre><code>\"node\": {\n    ...\n    \"statistics\": {\n\n        // Sampling configuration (optional)\n        // Only activate if you need sampling information, as there's some overhead associated with this feature.\n        \"sampling\": {\n            \"enabled\": \"true\",                // If sampling is enabled. Default false.\n            \"capacity\": \"5\",                  // How many samples to keep. Must be set if sampling is enabled.\n            \"interval\": \"1000\"                // Sample interval in milliseconds. Must be set if sampling is enabled.\n        },\n\n        // File logging (optional)\n        \"log\": {                              \n            \"interval_counters\": \"5000\",      // How often to write counters to file in milliseconds. Default 0 (off)\n            \"interval_samples\": \"5000\",       // How often to write samples to file, milliseconds. Default 0 (off)\n            \"rotation_count\": \"5\",            // Rotate file after writing statistics this many times. Default 100.\n            \"headers\": \"true\",                // Write header containing log\n            \"filename_counters\": \"counters.stat\",\n            \"filename_samples\": \"samples.stat\"\n        }\n    }\n}\n</code></pre>","title":"Configuration"},{"location":"running-a-node/troubleshooting/#available-type-detail-and-direction-values","text":"<pre><code>type:\n    traffic_udp\n    traffic_tcp\n    error\n    message\n    block\n    ledger\n    rollback\n    bootstrap\n    vote\n    election\n    http_callback\n    peering\n    ipc\n    tcp\n    udp\n    confirmation_height\n    confirmation_observer\n    drop\n    aggregator\n    requests\n    filter\n    telemetry\n\ndetails:\n    all\n\n    // error specific\n    bad_sender\n    insufficient_work\n    http_callback\n    unreachable_host\n\n    // confirmation_observer specific\n    active_quorum\n    active_conf_height\n    inactive_conf_height\n\n    // ledger block bootstrap\n    send\n    receive\n    open\n    change\n    state_block\n    epoch_block\n    fork\n    old\n    gap_previous\n    gap_source\n\n    // message specific\n    keepalive\n    publish\n    republish_vote\n    confirm_req\n    confirm_ack\n    node_id_handshake\n    telemetry_req\n    telemetry_ack\n\n    // bootstrap callback\n    initiate\n    initiate_lazy\n    initiate_wallet_lazy\n\n    // bootstrap specific\n    bulk_pull\n    bulk_pull_account\n    bulk_pull_deserialize_receive_block\n    bulk_pull_error_starting_request\n    bulk_pull_failed_account\n    bulk_pull_receive_block_failure\n    bulk_pull_request_failure\n    bulk_push\n    frontier_req\n    frontier_confirmation_failed\n    frontier_confirmation_successful\n    error_socket_close\n\n    // vote specific\n    vote_valid\n    vote_replay\n    vote_indeterminate\n    vote_invalid\n    vote_overflow\n\n    // election specific\n    vote_new\n    vote_cached\n    late_block\n    late_block_seconds\n    election_non_priority\n    election_priority\n    election_block_conflict\n    election_difficulty_update\n    election_drop\n    election_restart\n\n    // udp\n    blocking\n    overflow\n    invalid_magic\n    invalid_network\n    invalid_header\n    invalid_message_type\n    invalid_keepalive_message\n    invalid_publish_message\n    invalid_confirm_req_message\n    invalid_confirm_ack_message\n    invalid_node_id_handshake_message\n    invalid_telemetry_req_message\n    invalid_telemetry_ack_message\n    outdated_version\n\n    // tcp\n    tcp_accept_success\n    tcp_accept_failure\n    tcp_write_drop\n    tcp_write_no_socket_drop\n    tcp_excluded\n\n    // ipc\n    invocations\n\n    // peering\n    handshake\n\n    // confirmation height\n    blocks_confirmed\n    blocks_confirmed_unbounded\n    blocks_confirmed_bounded\n    invalid_block\n\n    // [request] aggregator\n    aggregator_accepted\n    aggregator_dropped\n\n    // requests\n    requests_cached_hashes\n    requests_generated_hashes\n    requests_cached_votes\n    requests_generated_votes\n    requests_cannot_vote\n    requests_unknown\n\n    // duplicate\n    duplicate_publish\n\n    // telemetry\n    invalid_signature\n    different_genesis_hash\n    node_id_mismatch\n    request_within_protection_cache_zone\n    no_response_received\n    unsolicited_telemetry_ack\n    failed_send_telemetry_req\n\ndir (direction) :\n    in\n    out\n</code></pre>","title":"Available type, detail and direction values"},{"location":"running-a-node/troubleshooting/#rpc-command","text":"","title":"RPC Command"},{"location":"running-a-node/troubleshooting/#counters-query","text":"<pre><code>{\n    \"action\": \"stats\",\n    \"type\": \"counters\"\n}\n</code></pre>","title":"Counters query:"},{"location":"running-a-node/troubleshooting/#counters-response","text":"<pre><code>{\n    \"type\": \"counters\",\n    \"created\": \"2018.03.29 01:46:36\",\n    \"entries\": [\n        {\n            \"time\": \"01:46:36\",\n            \"type\": \"traffic\",\n            \"detail\": \"all\",\n            \"dir\": \"in\",\n            \"value\": \"3122792\"\n        },\n        {\n            \"time\": \"01:46:36\",\n            \"type\": \"traffic\",\n            \"detail\": \"all\",\n            \"dir\": \"out\",\n            \"value\": \"203184\"\n        },\n        {\n            \"time\": \"01:46:36\",\n            \"type\": \"message\",\n            \"detail\": \"all\",\n            \"dir\": \"in\",\n            \"value\": \"12494\"\n        },\n        {\n            \"time\": \"01:46:36\",\n            \"type\": \"message\",\n            \"detail\": \"all\",\n            \"dir\": \"out\",\n            \"value\": \"1380\"\n        },\n        {\n            \"time\": \"01:46:36\",\n            \"type\": \"message\",\n            \"detail\": \"keepalive\",\n            \"dir\": \"in\",\n            \"value\": \"172\"\n        },\n        ...\n    ]\n}\n</code></pre>","title":"Counters response"},{"location":"running-a-node/troubleshooting/#samples-query","text":"<pre><code>{\n    \"action\": \"stats\",\n    \"type\": \"samples\"\n}\n</code></pre>","title":"Samples query:"},{"location":"running-a-node/troubleshooting/#samples-response","text":"<pre><code>{\n    \"type\": \"samples\",\n    \"created\": \"2018.03.29 01:47:08\",\n    \"entries\": [\n        {\n            \"time\": \"01:47:04\",\n            \"type\": \"traffic\",\n            \"detail\": \"all\",\n            \"dir\": \"in\",\n            \"value\": \"59480\"\n        },\n        {\n            \"time\": \"01:47:05\",\n            \"type\": \"traffic\",\n            \"detail\": \"all\",\n            \"dir\": \"in\",\n            \"value\": \"44496\"\n        },\n        {\n            \"time\": \"01:47:06\",\n            \"type\": \"traffic\",\n            \"detail\": \"all\",\n            \"dir\": \"in\",\n            \"value\": \"44136\"\n        },\n        {\n            \"time\": \"01:47:07\",\n            \"type\": \"traffic\",\n            \"detail\": \"all\",\n            \"dir\": \"in\",\n            \"value\": \"18784\"\n        },\n        {\n            \"time\": \"01:47:08\",\n            \"type\": \"traffic\",\n            \"detail\": \"all\",\n            \"dir\": \"in\",\n            \"value\": \"22680\"\n        },\n        {\n            \"time\": \"01:47:03\",\n            \"type\": \"traffic\",\n            \"detail\": \"all\",\n            \"dir\": \"out\",\n            \"value\": \"4128\"\n        },\n        {\n            \"time\": \"01:47:04\",\n            \"type\": \"message\",\n            \"detail\": \"all\",\n            \"dir\": \"out\",\n            \"value\": \"17\"\n        },\n        {\n            \"time\": \"01:47:05\",\n            \"type\": \"message\",\n            \"detail\": \"all\",\n            \"dir\": \"out\",\n            \"value\": \"10\"\n        },\n        ...\n    ]\n}\n</code></pre>","title":"Samples response"},{"location":"running-a-node/troubleshooting/#log-file-example","text":"<p><code>counters.stat</code></p> <p>As specified in the example config, sampling interval is 1 second, stats are logged every 5 seconds, and the file rotates after 5 log cycles.</p> <pre><code>counters,2018.03.29 01:45:36\n01:44:56,bootstrap,all,out,1\n01:45:36,bootstrap,initiate,out,2\ncounters,2018.03.29 01:45:41\n01:45:41,traffic,all,in,456344\n01:45:41,traffic,all,out,189520\n01:45:41,message,all,in,1925\n01:45:41,message,all,out,1289\n01:45:38,message,keepalive,in,165\n01:45:41,message,keepalive,out,1027\n01:45:41,message,publish,in,34\n01:45:38,message,confirm_req,in,164\n01:45:41,message,confirm_req,out,262\n01:45:41,message,confirm_ack,in,1562\n01:45:36,bootstrap,all,out,2\n01:45:41,bootstrap,initiate,out,3\n</code></pre> <p><code>samples.stat</code></p> <p>As specified in the example config, logging is done every 5 seconds and the sampling capacity is 5 (how many samplings are kept)</p> <pre><code>samples,2018.03.29 01:45:36\n01:45:36,bootstrap,initiate,out,2\nsamples,2018.03.29 01:45:41\n01:45:37,traffic,all,in,322608\n01:45:38,traffic,all,in,37064\n01:45:39,traffic,all,in,38752\n01:45:40,traffic,all,in,25632\n01:45:38,traffic,all,out,185072\n01:45:39,traffic,all,out,3072\n01:45:41,traffic,all,out,920\n01:45:37,message,all,in,1387\n01:45:38,message,all,in,126\n01:45:39,message,all,in,179\n01:45:40,message,all,in,101\n01:45:37,message,all,out,1254\n01:45:38,message,all,out,10\n01:45:39,message,all,out,16\n01:45:41,message,all,out,6\n01:45:38,message,keepalive,in,165\n01:45:38,message,keepalive,out,1011\n01:45:39,message,keepalive,out,12\n01:45:41,message,keepalive,out,3\n01:45:37,message,publish,in,19\n01:45:38,message,publish,in,8\n01:45:40,message,publish,in,3\n01:45:41,message,publish,in,4\n01:45:38,message,confirm_req,in,164\n01:45:37,message,confirm_req,out,249\n01:45:38,message,confirm_req,out,3\n01:45:39,message,confirm_req,out,6\n01:45:41,message,confirm_req,out,3\n01:45:37,message,confirm_ack,in,1046\n01:45:38,message,confirm_ack,in,141\n01:45:39,message,confirm_ack,in,150\n01:45:40,message,confirm_ack,in,100\n01:45:36,bootstrap,all,out,2\n01:45:36,bootstrap,initiate,out,2\n01:45:41,bootstrap,initiate,out,1\n</code></pre>","title":"Log file example"},{"location":"running-a-node/troubleshooting/#troubleshooting-upnp","text":"","title":"Troubleshooting UPnP"},{"location":"running-a-node/troubleshooting/#ensure-upnp-is-enabled","text":"<p>UPnP will be enabled unless the external port is set in either the config <pre><code>[node]\n...\n# The external address of this node (NAT). If not set, the node will request this information via UPnP.\n# type:string,ip\nexternal_address = \"::ffff:&lt;some_public_ipv4&gt;\"\n</code></pre> or via cli flag <pre><code>--config node.external_address=\"::ffff:&lt;some_public_ipv4&gt;\"\n</code></pre></p>","title":"Ensure UPnP is enabled"},{"location":"running-a-node/troubleshooting/#enable-upnp-logging","text":"<p>Appending this to your launch command will enable upnp logging. <pre><code>--config node.logging.upnp_details=true\n</code></pre></p>","title":"Enable UPnP logging"},{"location":"running-a-node/troubleshooting/#error-upnp-messages","text":"<p>Check the beginning of the logs for UPNP_* messages</p>  <p>Port Mapping Conflict</p> <p>Check for static routes <pre><code>[2019-Oct-29 11:06:56.641389]: UPnP failed 718: ConflictInMappingEntry\n[2019-Oct-29 11:06:56.644387]: UPnP failed 718: ConflictInMappingEntry\n</code></pre></p>","title":"Error UPnP Messages"},{"location":"running-a-node/troubleshooting/#normal-upnp-messages","text":"<p><pre><code>[2019-Oct-29 11:06:56.641389]: UPNP_GetSpecificPortMappingEntry failed 714: NoSuchEntryInArray\n[2019-Oct-29 11:06:56.644387]: UPNP_GetSpecificPortMappingEntry failed 714: NoSuchEntryInArray\n</code></pre> This message is expected when starting the node and will go away after the UPnP has mappeded the port</p>","title":"Normal UPnP Messages"},{"location":"running-a-node/voting-as-a-representative/","text":"<p>The default node setup guide provides instructions for getting a non-voting node setup, but if you're looking to run a Representative node, and perhaps hoping to become a Principal Representative, the node will need to be configured to vote and be setup with a Representative account.</p>  <p>  Technical Update Mailing List Sign up for email updates on the latest protocol/node releases and other technical details including network upgrades. Join Mailing List       </p>  <p>Before getting into the setup instructions, there are a few important considerations:</p>","title":"Voting as a Representative"},{"location":"running-a-node/voting-as-a-representative/#commitment-security-and-maintenance","text":"<p>Running a Nano Representative is a commitment to helping secure the network. This can only be done if the operation of the node is taken seriously.</p> <ul> <li>Prepare for the necessary maintenance on the node and host machine</li> <li>Carefully review the security guide and follow general security best practices at all times</li> <li>Ensure you are prepared for the time and cost commitments of maintaining the node over the long term to help maximize the benefits</li> </ul>","title":"Commitment, security and maintenance"},{"location":"running-a-node/voting-as-a-representative/#hardware-recommendations","text":"","title":"Hardware recommendations"},{"location":"running-a-node/voting-as-a-representative/#principal-representative-nodes","text":"<p>The following are minimum recommended specifications for nodes with more than 0.1% of the online voting weight (Principal Representatives):</p> <ul> <li>16GB RAM</li> <li>Quad-Core or higher CPU</li> <li>500 Mbps bandwidth (8TB or more of available monthly bandwidth)</li> <li>SSD-based hard drive with 400GB+ of free space</li> </ul>","title":"Principal Representative Nodes"},{"location":"running-a-node/voting-as-a-representative/#non-voting-and-representative-nodes","text":"<p>The following are minimum recommended specifications for non-voting nodes and Representative nodes with less than 0.1% of the online voting weight (regular Representatives):</p> <ul> <li>8GB RAM</li> <li>Quad-Core CPU</li> <li>250 Mbps bandwidth (4TB or more of available monthly bandwidth)</li> <li>SSD-based hard drive with 400GB+ of free space</li> </ul> <p>These lower specifications are also valid for any type of node run on the Beta network and Test network.</p>  <p>Varied resource usage</p> <p>Various factors affect resource usage including how often RPC calls are made, other applications running on the machine, etc. These recommendations should be evaluated along with other considerations.</p>   <p>Work Generation guide</p> <p>For nodes being used with services requiring regular or high volume sending and receiving of transactions, special considerations must be made for handling Proof-of-Work generation activities. Find details on configuring a GPU, external work services and more for the perfect setup in the Work Generation guide.</p>","title":"Non-voting and Representative Nodes"},{"location":"running-a-node/voting-as-a-representative/#synced-ledger","text":"<p>In order to open a new account to become a representative, the local node ledger must be in sync with the rest of the network. If you are starting a fresh node and bootstrapping, this process can take days to complete, depending on the network conditions, hardware specifications, etc. To speed this up, a downloaded ledger can be used if necessary.</p>","title":"Synced ledger"},{"location":"running-a-node/voting-as-a-representative/#step-1-enable-voting","text":"<p>For the node to start voting, the following configuration options need to be updated:</p>","title":"Step 1: Enable voting"},{"location":"running-a-node/voting-as-a-representative/#nodeenable_voting","text":"<p>Newly setup nodes have voting disabled by default. In order to participate in network consensus, this value must be updated in the <code>config-node.toml</code> file.</p> <pre><code>[node]\n\n# Enable or disable voting. Enabling this option requires additional system resources, namely increased CPU, bandwidth and disk usage.\n# type:bool\nenable_voting = true\n</code></pre>","title":"node.enable_voting"},{"location":"running-a-node/voting-as-a-representative/#rpcenable","text":"<p>To enable communication via RPC, set this configuration option in the <code>config-node.toml</code> file.</p> <pre><code>[rpc]\n\n# Enable or disable RPC\n# type:bool\nenable = true\n</code></pre>","title":"rpc.enable"},{"location":"running-a-node/voting-as-a-representative/#enable_control","text":"<p>This configuration option, which is needed for certain sensitive RPC calls such as those for creating wallets and accounts, is set in the <code>config-rpc.toml</code> file. Please make sure you are aware of the sensitive RPC calls opened up by enabling this option (detailed in the configuration guide).</p> <pre><code># Enable or disable control-level requests.\n# WARNING: Enabling this gives anyone with RPC access the ability to stop the node and access wallet funds.\n# type:bool\nenable_control = true\n</code></pre>","title":"enable_control"},{"location":"running-a-node/voting-as-a-representative/#step-2-setup-representative-account","text":"<p>Add a representative account to a wallet:</p> <ol> <li>Use wallet_create RPC, optionally with <code>seed</code> if you already know your representative account\u2019s seed</li> <li>One of the following:<ul> <li>wallet_add RPC, if you have a private key and didn\u2019t have a seed before</li> <li>account_create RPC if you had a seed or are creating a new representative account</li> </ul> </li> <li>Verify the account is in the wallet with account_list</li> </ol> <p>Open the account - until you do account_info and others will fail:</p> <ol> <li>Send some funds to the account, at least 0.01 Nano</li> <li>Use search_pending to make the wallet open the account automatically</li> <li>Use account_info to verify the state of the account<ul> <li>If the account is still not open, use receive as a backup</li> </ul> </li> </ol>","title":"Step 2: Setup Representative account"},{"location":"running-a-node/voting-as-a-representative/#step-3-restart-the-node-and-check-voting","text":"<p>Before the node will vote, the representative account configured above must have at least 1000 Nano delegated to it. This is done by changing the representative of other accounts in your wallet with account_representative_set. If you do not control over 1000 Nano, you will need to have others delegate their weight to your representative.</p> <p>Once you have enough weight, after a few minutes you can search for your representative account on the mynano.ninja site to verify it is voting.</p>  <p>Warning - Multiple Node Setups</p> <p>Never use the same seed on multiple running nano node instances at the same time.</p> <ul> <li>Multiple nano nodes using the same seed can result in network race conditions that degrade performance for your personal accounts.</li> <li>In addition, publishing transactions from two nodes with the same account at the same time may cause an account fork which requires a slower representative voting process.</li> <li>Similarly, if you are running a representative account on multiple nodes, they may publish conflicting votes, causing your representative to be ignored by the network.</li> <li>Performance degradation in enterprise environments may be significant.</li> </ul>","title":"Step 3: Restart the node and check voting"},{"location":"running-a-node/voting-as-a-representative/#step-4-optional-disable-rpc-control-commands-for-more-security","text":"<p><code>enable_control</code> was only needed to create the account which the Representative uses to vote. It is not actually needed for voting. Therefore there is no need to actually keep it active after the node is prepared for voting.</p> <p>In the <code>config-rpc.toml</code> file, you can disable the control commands again by setting <code>enable_control</code> back to false.</p> <pre><code># Enable or disable control-level requests.\n# WARNING: Enabling this gives anyone with RPC access the ability to stop the node and access wallet funds.\n# type:bool\nenable_control = false\n</code></pre>","title":"Step 4 (Optional): Disable RPC control commands for more security"},{"location":"running-a-node/voting-as-a-representative/#step-5-monitoring-and-more","text":"<p>Congratulations on getting your representative setup! If you are able to do a good job maintaining the node and keeping it performing well, you may have a chance at becoming a Principal Representative. To reach this higher level of participation in consensus, you must get at least 0.1% of online voting weight delegated to your node. After that any votes you send for transactions will be rebroadcast by other nodes to help with consensus even more.</p> <p>Once you are comfortable with your node setup and want to connect it to the broader Nano ecosystem, there are a few recommended options:</p>","title":"Step 5: Monitoring and more"},{"location":"running-a-node/voting-as-a-representative/#setup-monitoring","text":"<p>Details for setting up a popular monitoring service for the node can be found at https://github.com/NanoTools/nanoNodeMonitor. Not only can this provide a website for viewing the status and promoting your representative, but it also provides metrics to popular services in the ecosystem who help monitor the broader network status and performance, such as NanoCrawler.cc and MyNano.ninja.</p>","title":"Setup monitoring"},{"location":"running-a-node/voting-as-a-representative/#connect-with-community-services","text":"<p>At MyNano.ninja you can also verify your representative and share additional details about your social accounts. Many community members use this service to evaluate representatives which can help you get additional weight if your setup is reliable and well maintained.</p>","title":"Connect with community services"},{"location":"running-a-node/voting-as-a-representative/#ongoing-maintenance-and-support","text":"<p>As you continue maintaining your representative there are great community resources available for support:</p> <ul> <li>Ask questions in the Node and Representative Management category of the Nano Forum</li> <li>Connect on the Nano Discord server for discussion around node maintenance</li> <li>Join our Technical Updates Mailing List to stay updated on releases, network upgrade details and more</li> </ul>","title":"Ongoing maintenance and support"},{"location":"running-a-node/wallet-setup/","text":"<p>In order to transact or participate in consensus on the network the node must have a method of storing and managing private/public keys. There are a few options worth considering.</p>","title":"Wallet Setup"},{"location":"running-a-node/wallet-setup/#third-party-wallets","text":"<p>There are a variety of third-party wallets dedicated to just nano, as well as other multi-coin options. Although many are intended for end users with full GUIs, some expose APIs for programmatic use and integration. Some good resources for the latest wallets can be found at:</p> <p>Nano.org developer tools Nanowallets.guide</p>","title":"Third-party wallets"},{"location":"running-a-node/wallet-setup/#custom-key-management","text":"<p>If none of the third-party offerings work for your integration needs, the best option can be to create your own custom key management setup. This is the most time consuming but is also as flexible as you need it to be. For some of the main considerations and procedures for handling private keys, manually creating transactions and properly tracking confirmations, see the key management guide.</p>","title":"Custom key management"},{"location":"running-a-node/wallet-setup/#node-wallet","text":"<p>The published binary builds and Docker images will have an internal node wallet included. The <code>node_wallet</code> process runs alongside <code>nano_node</code> by default and provides a wallet for use by Representatives on the network, as well as for development activities. If you are building the node manually, make sure to review the QT wallet section of the build guide for how to include and run this wallet.</p>  <p>Node wallet not for production use</p> <p>The node wallet is not supported for use in production environments. Use third-party or custom key management for production applications.</p>  <p>Below is a basic walkthrough on how to setup a wallet and make a transaction using the built-in node wallet. It is important to understand the differences between accounts, private and public keys, seeds and wallet IDs before going much further. If you aren't comfortable with these concepts yet, see this guide. Creating a wallet with a seed and generating accounts from that seed will be the focus of this guide.</p>","title":"Node wallet"},{"location":"running-a-node/wallet-setup/#update-configuration","text":"<p>A configuration update is required to complete this guide. If you aren't familiar with configuring the node, see the configuration guide which includes configuration file locations for various operating systems and other useful details.</p> <p>This configuration option, which is needed for certain sensitive RPC calls such as those for creating wallets and accounts, is set in the <code>config-rpc.toml</code> file. Please make sure you are aware of the sensitive RPC calls opened up by enabling this option (detailed in the configuration guide).</p> <pre><code># Enable or disable control-level requests.\n# WARNING: Enabling this gives anyone with RPC access the ability to stop the node and access wallet funds.\n# type:bool\nenable_control = true\n</code></pre> <p>Once the change is made, make sure to reset your node for it to take effect. At the end of this guide you will remove this option if it is no longer needed.</p>","title":"Update configuration"},{"location":"running-a-node/wallet-setup/#create-a-wallet","text":"<p>In order to manage accounts, you first have to create a wallet to hold the seed or private keys for the accounts. If you started the node from the published binary builds or Docker images a wallet will have already been created. There will also be a cryptographically secure seed and the first private key (derived from the seed at index <code>0</code>) added to the wallet.</p> <p>For the purposes of this guide we will proceed as if these didn't exist, which will be the case for self-built nodes. We will instead use various commands to create the wallet and seed, backup seed details and add accounts. But before these RPC commands can be called a configuration option is needed.</p>","title":"Create a wallet"},{"location":"running-a-node/wallet-setup/#run-command","text":"<p>After this configuration change you can create a wallet using the 'wallet_create' RPC. During this call not only will a wallet be created, but a cryptographically secure seed will also be created and added to the wallet. If you wish to use an existing seed instead of have one generated, make sure to include it using the optional <code>seed</code> parameter.</p> Test networkMain networkBeta network   <p>Request <pre><code>curl -d '{\n  \"action\": \"wallet_create\"\n}' http://127.0.0.1:17076\n</code></pre></p>   <p>Request <pre><code>curl -d '{\n  \"action\": \"wallet_create\"\n}' http://127.0.0.1:7076\n</code></pre></p>   <p>Request <pre><code>curl -d '{\n  \"action\": \"wallet_create\"\n}' http://127.0.0.1:55000\n</code></pre></p>    <p>Response <pre><code>{ \n  \"wallet\": \"E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\"\n}\n</code></pre></p> <p>The wallet ID provided in the response is an ID local to the node and only available from the <code>wallet_create</code> RPC response or from CLI commands. This provides an extra layer of security if RPC access to sensitive calls exists: without direct access to the server to run CLI commands to get the wallet ID, remote calls to RPC won't be able to send funds or take other types of actions. </p> <p>Make sure to backup this wallet ID as this will be needed for other calls (you can recover your wallet ID later too if needed).</p>","title":"Run command"},{"location":"running-a-node/wallet-setup/#backup-or-import-your-seed","text":"<p>Note that the seed generated in the wallet isn't returned in the RPC response. This is also for security reasons. The node will only output the wallet seed to stdout via the <code>--wallet_decrypt_unsafe</code> CLI command. Run this command and backup your seed now (see backing up seed for more details).</p> DockerOther builds   <p>Request <pre><code>docker exec ${NANO_CONTAINER_NAME} nano_node --wallet_decrypt_unsafe --wallet E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\n</code></pre></p>   <p>Request <pre><code>/path/to/nano_node --wallet_decrypt_unsafe --wallet E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\n</code></pre></p>    <p>Response <pre><code>Seed: A7EA09F17C914AE8BA1B7FD1747DB8942DF551C271A7085187B8A20C21898CC6\n</code></pre></p> <p>If you would like to replace the wallet's automatically generated seed with your own, you can use the <code>wallet_change_seed</code> RPC command:</p>  wallet_change_seed replaces the previous seed <p>This command replaces the existing seed and clears all deterministic accounts in the wallet! Backup the old seed first if necessary.</p> Test network     <p>Request <pre><code>curl -d '{\n    \"action\": \"wallet_change_seed\",\n    \"wallet\": \"E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\", \n    \"seed\": \"A7EA09F17C914AE8BA1B7FD1747DB8942DF551C271A7085187B8A20C21898CC6\" \n}' http://127.0.0.1:17076\n</code></pre></p> Main network     <p>Request <pre><code>curl -d '{\n    \"action\": \"wallet_change_seed\",\n    \"wallet\": \"E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\", \n    \"seed\": \"A7EA09F17C914AE8BA1B7FD1747DB8942DF551C271A7085187B8A20C21898CC6\" \n}' http://127.0.0.1:7076\n</code></pre></p> Beta network     <p>Request <pre><code>curl -d '{\n    \"action\": \"wallet_change_seed\",\n    \"wallet\": \"E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\", \n    \"seed\": \"A7EA09F17C914AE8BA1B7FD1747DB8942DF551C271A7085187B8A20C21898CC6\" \n}' http://127.0.0.1:55000\n</code></pre></p>","title":"Backup or import your seed"},{"location":"running-a-node/wallet-setup/#set-wallet-password","text":"<p>It is a best practice to set the wallet password for additional security. Use the 'password_change' RPC to change from the empty default to a secure password. When looking to interact with the wallet it must first be unlocked, so use 'password_enter' RPC to ensure it is unlocked after setting.</p>","title":"Set wallet password"},{"location":"running-a-node/wallet-setup/#create-accounts","text":"<p>By default a newly created wallet with a seed will not have any accounts in it, but they are easy to add by simply calling the 'account_create' RPC. By default this will derive the private key for index <code>0</code> first from the seed and return the related public address. See the seed section for more information about private key derivation.</p> Test networkMain networkBeta network   <p>Request <pre><code>curl -d '{\n  \"action\": \"account_create\",\n  \"wallet\": \"E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\"\n}' http://127.0.0.1:17076\n</code></pre></p>   <p>Request <pre><code>curl -d '{\n  \"action\": \"account_create\",\n  \"wallet\": \"E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\"\n}' http://127.0.0.1:7076\n</code></pre></p>   <p>Request <pre><code>curl -d '{\n  \"action\": \"account_create\",\n  \"wallet\": \"E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\"\n}' http://127.0.0.1:55000\n</code></pre></p>    <p>Response <pre><code>{\n    \"account\": \"nano_3z3ntcdh5st3mtsogwip7kys1mgp6febnk3pwtex7acggykdkc9kexj4j87b\"\n}\n</code></pre></p> <p>If the optional <code>index</code> parameter is included the private key for that specific index will be added. Any subsequent calls to 'account_create' RPC without the <code>index</code> parameter will return to incrementing one from the lowest derived index above 0. Test out the command by generating a few accounts and then using the <code>account_list</code> RPC to see them all.</p> Test networkMain networkBeta network   <p>Request <pre><code>curl -d '{\n  \"action\": \"account_list\",\n  \"wallet\": \"E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\"\n}' http://127.0.0.1:17076\n</code></pre></p>   <p>Request <pre><code>curl -d '{\n  \"action\": \"account_list\",\n  \"wallet\": \"E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\"\n}' http://127.0.0.1:7076\n</code></pre></p>   <p>Request <pre><code>curl -d '{\n  \"action\": \"account_list\",\n  \"wallet\": \"E3E67B1B3FFA46F606240F1D0B964873D42E9C6D0B7A0BF376A2E128541CC446\"\n}' http://127.0.0.1:55000\n</code></pre></p>    <p>Response <pre><code>{\n    \"accounts\": [\n        \"nano_1wxyhf5xupfzwpu5fhsuudh1zcx3jtgaf3yiby9yh6oixdgad5e1u17oxaof\",\n        \"nano_3x6c688rp87dhh5rywezxqqct6q8t431hh7xux9h9pmqonpyd5oh8ipod7df\",\n        \"nano_3xu3rsd5krf6xxzn6jzubnd9asmpuk6bxoh98br5bqio4fy5yf3fkr5697gb\",\n        \"nano_3z3ntcdh5st3mtsogwip7kys1mgp6febnk3pwtex7acggykdkc9kexj4j87b\"\n    ]\n}\n</code></pre></p>","title":"Create accounts"},{"location":"running-a-node/wallet-setup/#revert-configuration","text":"<p>In the <code>config-rpc.toml</code> file, you can disable the control commands again by setting <code>enable_control</code> back to false.</p> <pre><code># Enable or disable control-level requests.\n# WARNING: Enabling this gives anyone with RPC access the ability to stop the node and access wallet funds.\n# type:bool\nenable_control = false\n</code></pre> <p>Make sure the node is restarted after making this change.</p>","title":"Revert configuration"},{"location":"running-a-node/wallet-setup/#next-steps","text":"<p>At this point you have a functioning wallet setup with some accounts for use on the network. There are other details about the node wallet that can be explored further in the internal key management guide, as well as many additional wallet RPCs available for use.</p> <p>For most new node operators learning how to receive and send funds or start voting as a Representative is next on the list. Other useful resources include:</p> <ul> <li>Ledger management guide for more details about bootstrapping, managing the database files, and updating the node</li> <li>Docker management guide with additional commands and examples for those running Docker containers</li> <li>Simple and advanced monitoring for options to keep an eye on node operations</li> <li>Many other integration and configuration options in the integration guides</li> </ul>","title":"Next steps"},{"location":"snippets/community-links/","text":"<p>Nano.org | Forum | GitHub | Twitter | Discord | Reddit | Medium</p> <p>Facebook | LinkedIn | YouTube | Instagram</p>","title":"Community links"},{"location":"snippets/config-node-option-node-enable-voting-true/","text":"","title":"Config node option node enable voting true"},{"location":"snippets/config-node-option-node-enable-voting-true/#nodeenable_voting","text":"<p>Newly setup nodes have voting disabled by default. In order to participate in network consensus, this value must be updated in the <code>config-node.toml</code> file.</p> <pre><code>[node]\n\n# Enable or disable voting. Enabling this option requires additional system resources, namely increased CPU, bandwidth and disk usage.\n# type:bool\nenable_voting = true\n</code></pre>","title":"node.enable_voting"},{"location":"snippets/config-node-option-rpc-enable-control-false/","text":"<p>In the <code>config-rpc.toml</code> file, you can disable the control commands again by setting <code>enable_control</code> back to false.</p> <pre><code># Enable or disable control-level requests.\n# WARNING: Enabling this gives anyone with RPC access the ability to stop the node and access wallet funds.\n# type:bool\nenable_control = false\n</code></pre>","title":"Config node option rpc enable control false"},{"location":"snippets/config-node-option-rpc-enable-control-true/","text":"<p>This configuration option, which is needed for certain sensitive RPC calls such as those for creating wallets and accounts, is set in the <code>config-rpc.toml</code> file. Please make sure you are aware of the sensitive RPC calls opened up by enabling this option (detailed in the configuration guide).</p> <pre><code># Enable or disable control-level requests.\n# WARNING: Enabling this gives anyone with RPC access the ability to stop the node and access wallet funds.\n# type:bool\nenable_control = true\n</code></pre>","title":"Config node option rpc enable control true"},{"location":"snippets/config-node-option-rpc-enable-true/","text":"","title":"Config node option rpc enable true"},{"location":"snippets/config-node-option-rpc-enable-true/#rpcenable","text":"<p>To enable communication via RPC, set this configuration option in the <code>config-node.toml</code> file.</p> <pre><code>[rpc]\n\n# Enable or disable RPC\n# type:bool\nenable = true\n</code></pre>","title":"rpc.enable"},{"location":"snippets/contributing-code/","text":"<p>Contributing to the code</p> <p>If you are interested in helping develop the C++ based Nano node we will help you out! Check out our details on contributing code to the Nano node to get started.</p>","title":"Contributing code"},{"location":"snippets/current-build-links-all/","text":"Test networkMain networkBeta network      OS Download link/command     Universal Linux https://repo.nano.org/test/binaries/nano-node-V23.0-Linux.tar.bz2   Debian https://repo.nano.org/test/binaries/nano-node-V23.0-Linux.deb   macOS https://repo.nano.org/test/binaries/nano-node-V23.0-Darwin.dmg   Windows (exe) https://repo.nano.org/test/binaries/nano-node-V23.0-win64.exe   Windows (zip) https://repo.nano.org/test/binaries/nano-node-V23.0-win64.zip   Docker <code>docker pull nanocurrency/nano-test:V23.0</code>   RHEL/CentOS rpm Not available for the test network         OS Download link/command Verification     Universal Linux https://repo.nano.org/live/binaries/nano-node-V23.0-Linux.tar.bz2 SHA256 Checksum   Debian https://repo.nano.org/live/binaries/nano-node-V23.0-Linux.deb SHA256 Checksum   macOS https://repo.nano.org/live/binaries/nano-node-V23.0-Darwin.dmg SHA256 Checksum   Windows (exe) https://repo.nano.org/live/binaries/nano-node-V23.0-win64.exe SHA256 Checksum   Windows (zip) https://repo.nano.org/live/binaries/nano-node-V23.0-win64.zip SHA256 Checksum   Docker <code>docker pull nanocurrency/nano:V23.0</code>See Pulling the Docker Image for more details.    RHEL/CentOS rpm <code>sudo rpm -iUvh https://repo.nano.org/live/binaries/nanocurrency-23.0-26.el7.x86_64.rpm</code>This installs <code>nano_node</code> and <code>nano_rpc</code> to <code>/usr/bin</code>. SHA256 Checksum      <p>Join the nano Discord server and head to the <code>#beta-announcements</code> channel for the latest build details.</p>","title":"Current build links all"},{"location":"snippets/current-build-links-beta/","text":"<p>Join the nano Discord server and head to the <code>#beta-announcements</code> channel for the latest build details.</p>","title":"Current build links beta"},{"location":"snippets/current-build-links-main/","text":"OS Download link/command Verification     Universal Linux https://repo.nano.org/live/binaries/nano-node-V23.0-Linux.tar.bz2 SHA256 Checksum   Debian https://repo.nano.org/live/binaries/nano-node-V23.0-Linux.deb SHA256 Checksum   macOS https://repo.nano.org/live/binaries/nano-node-V23.0-Darwin.dmg SHA256 Checksum   Windows (exe) https://repo.nano.org/live/binaries/nano-node-V23.0-win64.exe SHA256 Checksum   Windows (zip) https://repo.nano.org/live/binaries/nano-node-V23.0-win64.zip SHA256 Checksum   Docker <code>docker pull nanocurrency/nano:V23.0</code>See Pulling the Docker Image for more details.    RHEL/CentOS rpm <code>sudo rpm -iUvh https://repo.nano.org/live/binaries/nanocurrency-23.0-26.el7.x86_64.rpm</code>This installs <code>nano_node</code> and <code>nano_rpc</code> to <code>/usr/bin</code>. SHA256 Checksum","title":"Current build links main"},{"location":"snippets/current-build-links-test/","text":"OS Download link/command     Universal Linux https://repo.nano.org/test/binaries/nano-node-V23.0-Linux.tar.bz2   Debian https://repo.nano.org/test/binaries/nano-node-V23.0-Linux.deb   macOS https://repo.nano.org/test/binaries/nano-node-V23.0-Darwin.dmg   Windows (exe) https://repo.nano.org/test/binaries/nano-node-V23.0-win64.exe   Windows (zip) https://repo.nano.org/test/binaries/nano-node-V23.0-win64.zip   Docker <code>docker pull nanocurrency/nano-test:V23.0</code>   RHEL/CentOS rpm Not available for the test network","title":"Current build links test"},{"location":"snippets/dedicated-representative-nodes/","text":"<p>Dedicated Representative nodes recommended</p> <p>Due to the resources needed to participate in the voting process, it is recommended that any node setup as a Representative should be dedicated to generating consensus. If the resources of the Representative are used for other activities, such as application integrations, it reduces the potential benefit that node brings to the network.</p>","title":"Dedicated representative nodes"},{"location":"snippets/deprecation-info-pending/","text":"<p>The term <code>pending</code> is being deprecated in favor of <code>receivable</code>. For compatibility reasons both terms are still available for many calls and in responses. For more details see: https://docs.nano.org/releases/release-v23-0/#pendingreceivable-term-rpc-updates.</p>","title":"Deprecation info pending"},{"location":"snippets/directory-contents/","text":"<p>The Nano directory contains:</p> <ul> <li>Node wallet files (<code>wallets.ldb</code>, <code>wallets.ldb-lock</code>)</li> <li>Configuration files</li> <li>Log files</li> <li>Ledger files (<code>data.ldb</code> and <code>data.ldb-lock</code> for default LMDB, or <code>rocksdb</code> directory with files for optional RocksDB backend)</li> <li>Directory for wallet backups (<code>backup</code>)</li> </ul>  <p>Protect wallet and backup files</p> <p>The built-in node wallet is for use in development and testing only. Those using it should take care in protecting access to the <code>wallets.ldb</code> file and backup files, whether encrypted or not, for added security.</p>","title":"Directory contents"},{"location":"snippets/directory-locations-all/","text":"Test networkMain networkBeta network      OS Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\NanoTest\\</code>   macOS <code>/Users/&lt;user&gt;/Library/NanoTest/</code>   Linux <code>/home/&lt;user&gt;/NanoTest/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/NanoTest</code>         OS/Build Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\Nano\\</code>   macOS <code>/Users/&lt;user&gt;/Library/Nano/</code>   Linux <code>/home/&lt;user&gt;/Nano/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/Nano</code>         OS Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\NanoBeta\\</code>   macOS <code>/Users/&lt;user&gt;/Library/NanoBeta/</code>   Linux <code>/home/&lt;user&gt;/NanoBeta/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/NanoBeta</code>","title":"Directory locations all"},{"location":"snippets/directory-locations-beta/","text":"OS Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\NanoBeta\\</code>   macOS <code>/Users/&lt;user&gt;/Library/NanoBeta/</code>   Linux <code>/home/&lt;user&gt;/NanoBeta/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/NanoBeta</code>","title":"Directory locations beta"},{"location":"snippets/directory-locations-main/","text":"OS/Build Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\Nano\\</code>   macOS <code>/Users/&lt;user&gt;/Library/Nano/</code>   Linux <code>/home/&lt;user&gt;/Nano/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/Nano</code>","title":"Directory locations main"},{"location":"snippets/directory-locations-test/","text":"OS Location     Windows <code>C:\\Users\\&lt;user&gt;\\AppData\\Local\\NanoTest\\</code>   macOS <code>/Users/&lt;user&gt;/Library/NanoTest/</code>   Linux <code>/home/&lt;user&gt;/NanoTest/</code>   Docker As defined by the <code>-v</code> flag in the <code>docker run</code> command   .deb/rpm <code>/var/nanocurrency/NanoTest</code>","title":"Directory locations test"},{"location":"snippets/docker-ipv6-tip/","text":"<p>Tip</p> <p>On some systems it may be necessary to replace <code>127.0.0.1</code> with IPv6 equivalent of <code>[::1]</code> when mapping Docker ports</p>","title":"Docker ipv6 tip"},{"location":"snippets/docker-run-command-beta/","text":"<pre><code>docker run --restart=unless-stopped -d \\\n  -p 54000:54000 \\\n  -p 127.0.0.1:55000:55000 \\ # (1)\n  -p 127.0.0.1:57000:57000 \\ # (2)\n  -v ${NANO_HOST_DIR}:/root \\\n  --name ${NANO_NAME} \\\n  nanocurrency/nano-beta:${NANO_TAG}\n</code></pre> <ol> <li>Port 55000 is optional, but recommended, for querying via RPC</li> <li>Port 57000 is optional for connecting via WebSockets</li> </ol>","title":"Docker run command beta"},{"location":"snippets/docker-run-command-main/","text":"<pre><code>docker run --restart=unless-stopped -d \\\n  -p 7075:7075 \\\n  -p 127.0.0.1:7076:7076 \\ # (1)\n  -p 127.0.0.1:7078:7078 \\ # (2)\n  -v ${NANO_HOST_DIR}:/root \\\n  --name ${NANO_NAME} \\\n  nanocurrency/nano:${NANO_TAG}\n</code></pre> <ol> <li>Port 7076 is optional, but recommended, for querying via RPC</li> <li>Port 7078 is optional for connecting via WebSockets</li> </ol>","title":"Docker run command main"},{"location":"snippets/docker-run-command-test/","text":"<pre><code>docker run --restart=unless-stopped -d \\\n  -p 17075:17075 \\\n  -p 127.0.0.1:17076:17076 \\ # (1)\n  -p 127.0.0.1:17078:17078 \\ # (2)\n  -v ${NANO_HOST_DIR}:/root \\\n  --name ${NANO_NAME} \\\n  nanocurrency/nano-test:${NANO_TAG}\n</code></pre> <ol> <li>Port 17076 is optional, but recommended, for querying via RPC</li> <li>Port 17078 is optional for connecting via WebSockets</li> </ol>","title":"Docker run command test"},{"location":"snippets/enable-voting/","text":"<p>Enable Voting</p> <p>When setting up a new node, voting is disabled by default in the configuration file and must be manually enabled in order to participate in consensus. See enable_voting configuration option for more details.</p>","title":"Enable voting"},{"location":"snippets/hardware-recommendations/","text":"","title":"Hardware recommendations"},{"location":"snippets/hardware-recommendations/#principal-representative-nodes","text":"<p>The following are minimum recommended specifications for nodes with more than 0.1% of the online voting weight (Principal Representatives):</p> <ul> <li>16GB RAM</li> <li>Quad-Core or higher CPU</li> <li>500 Mbps bandwidth (8TB or more of available monthly bandwidth)</li> <li>SSD-based hard drive with 400GB+ of free space</li> </ul>","title":"Principal Representative Nodes"},{"location":"snippets/hardware-recommendations/#non-voting-and-representative-nodes","text":"<p>The following are minimum recommended specifications for non-voting nodes and Representative nodes with less than 0.1% of the online voting weight (regular Representatives):</p> <ul> <li>8GB RAM</li> <li>Quad-Core CPU</li> <li>250 Mbps bandwidth (4TB or more of available monthly bandwidth)</li> <li>SSD-based hard drive with 400GB+ of free space</li> </ul> <p>These lower specifications are also valid for any type of node run on the Beta network and Test network.</p>  <p>Varied resource usage</p> <p>Various factors affect resource usage including how often RPC calls are made, other applications running on the machine, etc. These recommendations should be evaluated along with other considerations.</p>   <p>Work Generation guide</p> <p>For nodes being used with services requiring regular or high volume sending and receiving of transactions, special considerations must be made for handling Proof-of-Work generation activities. Find details on configuring a GPU, external work services and more for the perfect setup in the Work Generation guide.</p>","title":"Non-voting and Representative Nodes"},{"location":"snippets/join-technical-mailing-list/","text":"<p>  Technical Update Mailing List Sign up for email updates on the latest protocol/node releases and other technical details including network upgrades. Join Mailing List       </p>","title":"Join technical mailing list"},{"location":"snippets/known-issue-macos-too-many-open-files/","text":"Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>","title":"Known issue macos too many open files"},{"location":"snippets/known-issue-peers-stake-reporting/","text":"Known Issue V20: Peers stake reporting inaccurate (Windows only) <ul> <li> <p>Issue: For Windows builds only, when calling confirmation_quorum RPC the <code>peers_stake_total</code> amount returned may be inaccurate, returning a range from the correct full peer stake amount down to 0.</p> </li> <li> <p>Solution: A solution to the issue has been found and as this is a reporting issue only, the fix will be included in the next released version. For those manually building the node, patching the fix pull request onto the V20.0 tag can resolve the issue now. Or alternatively, building on the V20.0 tag with <code>RelWithDebInfo</code> option, see Build Instructions for Windows.</p> </li> </ul>","title":"Known issue peers stake reporting"},{"location":"snippets/known-issue-unable-to-find-libboost/","text":"Known Issue Linux V21: 'unable to find libboost' <p>If you are on Linux and unable to get V21.0 to start, <code>unable to find libboost...</code> https://github.com/nanocurrency/nano-node/releases/download/V21.0/nano-node-V21.0.1-Linux.tar.bz2 has been added to the release artifacts with the correct lib rpath. Please use this if you do not wish to move the lib folder into the bin folder after extraction.</p>","title":"Known issue unable to find libboost"},{"location":"snippets/known-issue-unchecked-keys-rpc-rocksdb/","text":"Known issue with RocksDB: RPC <code>unchecked_keys</code> not working properly <p>Issue: The RPC <code>unchecked_keys</code> is returning <code>0</code> for all calls when used with the RocksDB backend. This known issue will be resolved in a future release.</p> <p>Solution: Until the issue is resolved any integrations using this command should remain on the existing LMDB backend</p>","title":"Known issue unchecked keys rpc rocksdb"},{"location":"snippets/known-issue-windows-logging-stable/","text":"Known Issue Windows V21: Crash when using config <code>node.logging.stable_log_filename</code> <p>Setting <code>node.logging.stable_log_filename</code> configuration option to <code>true</code> results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to <code>false</code>.</p>","title":"Known issue windows logging stable"},{"location":"snippets/network-details-simple-beta/","text":"Port Protocol Required? Purpose     54000 TCP Yes, open to all traffic For live network activity and bootstrap network activity.   55000 TCP No, recommended For communication with RPC server. Do not expose this outside of your production environment. Anyone with access to this port can control your node's RPC.   56000 TCP No, optional For communication via IPC (advanced). See IPC integration guide for more details.   57000 TCP No, optional For communication with websocket server. Depending on configuration, data throughput can be very high.","title":"Network details simple beta"},{"location":"snippets/network-details-simple-main/","text":"Port Protocol Required? Purpose     7075 TCP Yes, open to all traffic For live network activity and bootstrap network activity.   7076 TCP No, recommended For communication with RPC server. Do not expose this outside of your production environment. Anyone with access to this port can control your node's RPC.   7077 TCP No, optional For communication via IPC (advanced). See IPC integration guide for more details.   7078 TCP No, optional For communication with websocket server. Depending on configuration, data throughput can be very high.","title":"Network details simple main"},{"location":"snippets/network-details-simple-test/","text":"Port Protocol Required? Purpose     17075 TCP Yes, open to all traffic For live network activity and bootstrap network activity.   17076 TCP No, recommended For communication with RPC server. Do not expose this outside of your production environment. Anyone with access to this port can control your node's RPC.   17077 TCP No, optional For communication via IPC (advanced). See IPC integration guide for more details.   17078 TCP No, optional For communication with websocket server. Depending on configuration, data throughput can be very high.","title":"Network details simple test"},{"location":"snippets/network-details/","text":"","title":"Network details"},{"location":"snippets/network-details/#network-details","text":"Port Type Default Details     7075 TCP Enabled <ul><li>Node bootstrapping server</li><li>Share port configuration in <code>config-node.toml</code>, option <code>node.peering_port</code></li><li>Binds to all adapters; unicast</li><li>Contents: Raw nano protocol stream</li><li>Transmits the ledger to new nodes in bulk</li><li>If blocked other nodes will not be able retrieve the ledger from this node</li></ul>   7076 TCP Disabled <ul><li>RPC server</li><li>Port configurable in <code>config-rpc.toml</code>, option <code>rpc.port</code></li><li>Enable in <code>config-node.toml</code>, option <code>rpc.enable</code> or by starting <code>nano_rpc</code> manually</li><li> Binds to localhost by default for security reasons, configurable in <code>config-rpc.toml</code>, option <code>rpc.address</code>; unicast</li><li>Contents: Unencrypted HTTP requests containing JSON object bodies</li><li>Allows the node to be queried or controlled through HTTP requests</li><li>If blocked the node will not be able to be queried or controlled by HTTP</li><li>WARNING: Exposing this port externally while setting <code>enable_control</code> option to <code>true</code> in configs could expose your wallet, allow the node to be stopped remotely and open your node up to other dangerous activity. See the Node Security page for more details.</li></ul>   7078 TCP Disabled <ul><li>Websocket server</li><li>Port configurable in <code>config-node.toml</code>, option <code>node.websocket.port</code></li><li>Enable in <code>config-node.toml</code>, option <code>node.websocket.enable</code></li><li>Binds to localhost by default due to data throughput potentially being very high; producer-subscriber broadcast</li><li>Contents: Standard websocket frames containing JSON-encoded objects</li><li>See WebSocket Support for details on configuration</li></ul>     <p>UDP disabled by default, deprecated</p> <p>As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined.</p>","title":"Network Details"},{"location":"snippets/release-details-v18-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links     18.0 16 13 2019-02-21  Release - Milestone - Changelog","title":"Release details v18 0"},{"location":"snippets/release-details-v19-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links     19.0 17 14 2019-07-11 V19.0 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>","title":"Release details v19 0"},{"location":"snippets/release-details-v20-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links     20.0 17 15 2019-11-12 V20.0 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>   Known Issue V20: Peers stake reporting inaccurate (Windows only) <ul> <li> <p>Issue: For Windows builds only, when calling confirmation_quorum RPC the <code>peers_stake_total</code> amount returned may be inaccurate, returning a range from the correct full peer stake amount down to 0.</p> </li> <li> <p>Solution: A solution to the issue has been found and as this is a reporting issue only, the fix will be included in the next released version. For those manually building the node, patching the fix pull request onto the V20.0 tag can resolve the issue now. Or alternatively, building on the V20.0 tag with <code>RelWithDebInfo</code> option, see Build Instructions for Windows.</p> </li> </ul>","title":"Release details v20 0"},{"location":"snippets/release-details-v21-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links     21.0 18 18 2020-06-16 V21.0 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>   Known Issue Linux V21: 'unable to find libboost' <p>If you are on Linux and unable to get V21.0 to start, <code>unable to find libboost...</code> https://github.com/nanocurrency/nano-node/releases/download/V21.0/nano-node-V21.0.1-Linux.tar.bz2 has been added to the release artifacts with the correct lib rpath. Please use this if you do not wish to move the lib folder into the bin folder after extraction.</p>   Known Issue Windows V21: Crash when using config <code>node.logging.stable_log_filename</code> <p>Setting <code>node.logging.stable_log_filename</code> configuration option to <code>true</code> results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to <code>false</code>.</p>","title":"Release details v21 0"},{"location":"snippets/release-details-v21-1/","text":"Node Protocol Database Release Date Release Notes GitHub Links     21.1 18 18 2020-07-14 V21.1 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>   Known Issue Windows V21: Crash when using config <code>node.logging.stable_log_filename</code> <p>Setting <code>node.logging.stable_log_filename</code> configuration option to <code>true</code> results in a node crash on Windows in V21.0 and V21.1, after a node restart. This must be set to <code>false</code>.</p>","title":"Release details v21 1"},{"location":"snippets/release-details-v21-2/","text":"Node Protocol Database Release Date Release Notes GitHub Links     21.2 18 18 2020-09-03 V21.2 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>","title":"Release details v21 2"},{"location":"snippets/release-details-v21-3/","text":"Node Protocol Database Release Date Release Notes GitHub Links     21.3 18 18 2021-03-18 V21.3 Release - Milestone - Changelog     Known Issue V19+: 'Too many open files' <ul> <li> <p>Issue: The following error, or a similar one, can be seen when attempting to run a full node on some versions of macOS, Linux and possibly other operating systems. This is most common when using the built-in Qt wallet or other GUI-based wallets: \"Exception while running wallet: open: Too many open files\" or other errors containing \"Too many open files\". This is due to some systems having a very low default file descriptor limit and V19.0+ uses more of them after the move to TCP.</p> </li> <li> <p>Solution: Increasing the file limits is needed to resolve this. See this known issue for more details on resolution.</p> </li> </ul>","title":"Release details v21 3"},{"location":"snippets/release-details-v22-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links     22.0 18 21 2021-05-14 V22.0 Release - Milestone - Changelog     Known issue with RocksDB: RPC <code>unchecked_keys</code> not working properly <p>Issue: The RPC <code>unchecked_keys</code> is returning <code>0</code> for all calls when used with the RocksDB backend. This known issue will be resolved in a future release.</p> <p>Solution: Until the issue is resolved any integrations using this command should remain on the existing LMDB backend</p>","title":"Release details v22 0"},{"location":"snippets/release-details-v22-1/","text":"Node Protocol Database Release Date Release Notes GitHub Links     22.1 18 21 2021-06-11 V22.1 Release - Milestone - Changelog","title":"Release details v22 1"},{"location":"snippets/release-details-v23-0/","text":"Node Protocol Database Release Date Release Notes GitHub Links     23.0 18 21 2021-01-17 V23.0 Release - Milestone - Changelog","title":"Release details v23 0"},{"location":"snippets/security-vulnerability-reporting/","text":"<p>Submit vulnerabilities privately</p> <p>Do NOT discuss potential security vulnerabilities on the issue tracker, public forums or open discussion channels. Submit sensitive issues privately to the Nano Foundation for review.</p>  <p>If you discover a bug you believe to pose a security risk to the Nano network, please contact security@nano.org with a proof of concept with full details of the bug including:</p> <ul> <li>Repository of the bug</li> <li>High-level summary</li> <li>Detailed description</li> <li>Steps to reproduce</li> <li>Supporting material/references</li> <li>The potential security impact of the bug</li> </ul> <p>It is strongly recommended to encrypt the email using GPG and the pubkeys for this purpose can be found on the SECURITY file in the node repository. The Nano Foundation will work to determine potential impacts and coordinate resolution in a node release.</p>","title":"Security vulnerability reporting"},{"location":"snippets/setup-beta-test-testing/","text":"<p>Setup for testing on beta or test network</p> <p>If you are looking to test the latest version of the node ahead of release, check out the Beta Network and Test Network pages for more details about how to get setup on the appropriate network. Typically general integration and node upgrades are tested on the public test network, while new feature and load testing are conducted on the beta network.</p>","title":"Setup beta test testing"},{"location":"snippets/terms-block-transaction-transfer/","text":"<ul> <li> <p>block is the digital encoding of the transaction details.</p> </li> <li> <p>transaction is the action of creating and publishing a block to the network. Depending on the type of transaction, the block will have different requirements.</p> </li> <li> <p>transfer is the completion of both a send transaction and the corresponding receive transaction, representing the movement of funds which can be sent again by the recipient.</p> </li> </ul>","title":"Terms block transaction transfer"},{"location":"snippets/toml-config-commands/","text":"Name Description Generated with     <code>config-node.toml</code> Node configuration <code>nano_node --generate_config node</code>   <code>config-rpc.toml</code> RPC configuration <code>nano_node --generate_config rpc</code>   <code>config-nano-pow-server.toml</code> Proof of work server configuration <code>nano_pow_server --generate_config</code>   <code>config-qtwallet.toml</code> Qt developer wallet configuration This file is maintained by the Qt wallet","title":"Toml config commands"},{"location":"snippets/unconfirmed-information/","text":"<p>Unconfirmed information</p> <p>This call returns information that may be based on unconfirmed blocks. These details should not be relied on for any process or integration that requires confirmed blocks.  </p>","title":"Unconfirmed information"},{"location":"snippets/warning-alternative-work-generation-setup-preferred/","text":"<p>Alternative work generation setup preferred</p> <p>Due to potential performance impacts to nodes participating on the network (voting, staying in sync, etc.), when possible this option should be updated to a value of <code>0</code> to turn off local work generation. Please see the Work Generation guide for best practices.</p>","title":"Warning alternative work generation setup preferred"},{"location":"snippets/warning-debug-only-command/","text":"<p>Debug purposes only</p> <p>This call is for internal diagnostics/debug purposes only. Do not rely on this interface being stable and do not use in a production system.</p>","title":"Warning debug only command"},{"location":"snippets/warning-docker-limitations/","text":"<p>Docker Limitations</p> <p>Although Docker is a great choice for many setups, it is not recommended to run a *nix container, such as the officially provided one, on a Windows host - there are known issues with handling ports which prevent proper communication with peers.</p> <p>If planning to use <code>ufw</code> with Docker, note that you may need to prevent Docker from manipulating iptables to properly manage firewall settings.</p>","title":"Warning docker limitations"},{"location":"snippets/warning-enable-control/","text":"<p>Dangerous RPC calls controlled by <code>enable_control</code></p> <p>This RPC command/option requires <code>enable_control</code> to be enabled within the RPC config file. Enabling this means that anyone with access to the RPC port could potentially access wallet funds, stop the node from running and take other dangerous actions. Use caution when enabling this option, especially with external RPC access available. For more details see the Node Security page.</p>","title":"Warning enable control"},{"location":"snippets/warning-external-libraries/","text":"<p>External libraries, review before using</p> <p>The linked resources below contain code dealing with private key management and/or execution of transactions. The Nano Foundation does not control this code, does not endorse it and is not responsible for its use. Use of this code requires review and is at your own discretion.</p>","title":"Warning external libraries"},{"location":"snippets/warning-includes-unconfirmed/","text":"<p>Includes unconfirmed blocks</p> <p>This call may return results that include unconfirmed blocks, so it should not be used in any processes or integrations requiring only details from blocks confirmed by the network.</p>","title":"Warning includes unconfirmed"},{"location":"snippets/warning-multiple-confirmation-notifications/","text":"<p>Multiple notifications for blocks</p> <p>Depending on the node setup and sync status, multiple confirmation notifications for the same block hash may be sent by a single tracking mechanism. In order to prevent potential issues, integrations must track these block hashes externally to the node and prevent any unwanted actions based on multiple notifications.</p>","title":"Warning multiple confirmation notifications"},{"location":"snippets/warning-multiple-node-setups/","text":"<p>Warning - Multiple Node Setups</p> <p>Never use the same seed on multiple running nano node instances at the same time.</p> <ul> <li>Multiple nano nodes using the same seed can result in network race conditions that degrade performance for your personal accounts.</li> <li>In addition, publishing transactions from two nodes with the same account at the same time may cause an account fork which requires a slower representative voting process.</li> <li>Similarly, if you are running a representative account on multiple nodes, they may publish conflicting votes, causing your representative to be ignored by the network.</li> <li>Performance degradation in enterprise environments may be significant.</li> </ul>","title":"Warning multiple node setups"},{"location":"snippets/warning-node-wallet-not-for-prod-use/","text":"<p>Node wallet not for production use</p> <p>The node wallet is not supported for use in production environments. Use third-party or custom key management for production applications.</p>","title":"Warning node wallet not for prod use"},{"location":"snippets/warning-only-official-builds-supported/","text":"<p>Only Official Builds Supported</p> <ul> <li>The fastest and most recommended method of installation is through Docker management</li> <li>Only official release builds are recommended and supported for use on the main network</li> <li>Builds created from git should be done using the available release tags (<code>V21.2</code> etc.)</li> </ul>","title":"Warning only official builds supported"},{"location":"snippets/warning-process-sub-type-recommended/","text":"<p>Including <code>subtype</code> in <code>process</code> RPC calls highly recommended</p> <p>In order to avoid potential incorrect sends including the optional <code>subtype</code> parameter on all <code>process</code> RPC calls is highly recommended. In the next version of the RPC this parameter will be required.</p>","title":"Warning process sub type recommended"},{"location":"snippets/warning-security-vulnerability-reporting/","text":"<p>Submit vulnerabilities privately</p> <p>Do NOT discuss potential security vulnerabilities on the issue tracker, public forums or open discussion channels. Submit sensitive issues privately to the Nano Foundation for review.</p>  <p>If you discover a bug you believe to pose a security risk to the Nano network, please contact security@nano.org with a proof of concept with full details of the bug including:</p> <ul> <li>Repository of the bug</li> <li>High-level summary</li> <li>Detailed description</li> <li>Steps to reproduce</li> <li>Supporting material/references</li> <li>The potential security impact of the bug</li> </ul> <p>It is strongly recommended to encrypt the email using GPG and the pubkeys for this purpose can be found on the SECURITY file in the node repository. The Nano Foundation will work to determine potential impacts and coordinate resolution in a node release.</p>","title":"Warning security vulnerability reporting"},{"location":"snippets/warning-telemetry-can-be-forged/","text":"<p>Telemetry can be forged</p> <p>Although the telemetry messages are signed by nodes, the data provided by other peers can be forged by malicious nodes so they cannot be guaranteed as accurate. All details in these messages should be used as rough indicators of peer and broad network situations, but not exclusively relied on for any key integration or network activities.</p>","title":"Warning telemetry can be forged"},{"location":"snippets/warning-udp-deprecated/","text":"<p>UDP disabled by default, deprecated</p> <p>As of V21 peering and communicating via UDP has been disabled by default and is deprecated. The ability to use UDP will be removed from the node in a future release yet to be determined.</p>","title":"Warning udp deprecated"},{"location":"snippets/warning-unsupported-configuration/","text":"<p>Unsupported configuration</p> <ul> <li>This documentation is intended only for developers of the Nano Node software, and will not result in a supported configuration.  End-users are advised to use releases.</li> <li>The fastest and most recommended method of installation is through Docker.</li> <li>Running node as a service.</li> <li>To manage a node, use RPC commands or the CLI.</li> </ul>","title":"Warning unsupported configuration"},{"location":"snippets/wip-living-whitepaper/","text":"Part of work in progress Living Whitepaper <p>This page is part of the Living Whitepaper revisions currently underway to replace the original static whitepaper. These efforts include the Protocol Design and Node Implementation sections of the docs, which will cover and expand on details and topics covered in the original whitepaper.</p> <p>See the bottom of the page for related whitepaper sections and other related details. Some of the sections and headers on this page may be in draft form or just suggestions/framework for later consideration. If you are interested in helping with revisions please connect with us on the <code>#documentation</code> channel on our Discord server.</p>","title":"Wip living whitepaper"},{"location":"what-is-nano/overview/","text":"<p>Nano is a digital payment protocol designed to be accessible and lightweight, with a focus on removing inefficiencies present in other cryptocurrencies. With ultrafast transactions and zero fees on a secure, green and decentralized network, this makes Nano ideal for everyday transactions.</p>","title":"What is nano?"},{"location":"what-is-nano/overview/#how-do-transactions-work","text":"<p>Nano utilizes the Block Lattice, a data-structure in which individual accounts control their own blockchain. This allows blocks to be added quickly without conflict and sent to the network for confirmation.</p> <p>Transactions occur between accounts with two separate actions:</p> <ol> <li>The sender publishes a block debiting their own account for the amount to be sent to the receiving account</li> <li>The receiver publishes a matching block crediting their own account for the amount sent</li> </ol> <p>Once a block sending funds is confirmed by the network, the transaction goes into a receivable state and cannot be reversed. The receiver can be offline and safely leave the funds in this state until they are ready to publish a matching block receiving the funds to their account.</p>","title":"How do transactions work?"},{"location":"what-is-nano/overview/#lightweight-stateful-blocks","text":"<p>Nano uses a structure for each block which contains all the information about an account at that point in time: account number, balance, representative.</p> <p>Every block must also contain a small, user-generated Proof-of-Work value which is a Quality-of-Service prioritization mechanism allowing occasional, average user transactions to process quickly and consistently. The PoW computation for a transaction typically takes a few seconds on a modern desktop CPU.</p> <p>For more details, see the Blocks and Proof-of-Work specifications in our Integration Guides.</p>","title":"Lightweight, stateful blocks"},{"location":"what-is-nano/overview/#representatives-and-voting","text":"<p>Nano has a unique consensus mechanism called Open Representative Voting (ORV). Every account can freely choose a Representative at any time to vote on their behalf, even when the delegating account itself is offline. These Representative accounts are configured on nodes that remain online and vote on the validity of transactions they see on the network. Their voting weight is the sum of balances for accounts delegating to them, and if they have enough voting weight they become a Principal Representative. The votes these Principal Representatives send out will subsequently be rebroadcasted by other nodes.</p> <p>As these votes are shared and rebroadcasted between nodes, they are tallied up and compared against the online voting weight available. Once a node sees a block get enough votes to reach quorum, that block is confirmed. Due to the lightweight nature of blocks and votes, the network is able to reach confirmation for transaction ultrafast, often in under a couple seconds. Also note that delegation of voting weight does not mean staking of any funds - the account delegating can still spend all their available funds at any time without restrictions.</p> <p>Because Nano accounts can freely delegate their voting weight to representatives at any time, the users have more control over who has power with consensus and how decentralized the network is. This is a key advantage to the design of Open Representative Voting (ORV). With no direct monetary incentive for nodes, this removes emergent centralization forces for longer-term trending toward decentralization of the network.1</p>","title":"Representatives and Voting"},{"location":"what-is-nano/overview/#design-advantages","text":"<p>Nano was designed with new data structures, consensus mechanisms and other features to gain some key advantages over competing digital currencies:</p> <ul> <li>Minimal block size allows for lightweight communication resulting in ultrafast transaction confirmation times</li> <li>Without traditional Proof-of-Work and mining, nodes use significantly less energy per transaction than other popular networks</li> <li>Emergent centralization forces for node operators are reduced due to the near zero marginal cost of producing consensus in Nano 1</li> </ul>","title":"Design Advantages"},{"location":"what-is-nano/overview/#exploring-more","text":"<ul> <li>Looking for technical details of the protocol and node design? Check out the Living Whitepaper</li> <li>Ready to participate on the network? Try running a node, review integration options or find commands via RPC and CLI</li> <li>Want to know the future of Nano? See the upcoming features for the node or help shape the future by contributing to the development of the protocol if you can!</li> <li>Want to explore less technical aspects of Nano or join our community? Head over to Nano.org</li> </ul>   <ol> <li> <p>https://medium.com/@clemahieu/emergent-centralization-due-to-economies-of-scale-83cc85a7cbef \u21a9\u21a9</p> </li> </ol>","title":"Exploring More"},{"location":"whitepaper/english/","text":"<p>Last updated: November 2017</p>  <p>Info</p> <p>This original whitepaper contains details about the protocol which are no longer accurate, such as voting only being performed on blocks for which forks were detected, but is being left intact for historical reference purposes. For more accurate details, head over to the Living Whitepaper section.</p>","title":"Original RaiBlocks/Nano Whitepaper"},{"location":"whitepaper/english/#introduction","text":"<p>Since the implementation of Bitcoin in 2009, there has been a growing shift away from traditional, government-backed currencies and financial systems towards modern payments systems based on cryptography, which offer the ability to store and transfer funds in a trustless and secure manner 1. In order to function effectively, a currency must be easily transferable, non-reversible, and have limited or no fees. The increased transaction times, large fees, and questionable network scalability have raised questions about the practicality of Bitcoin as an everyday currency.</p> <p>In this paper, we introduce RaiBlocks, a low-latency cryptocurrency built on an innovative block-lattice data structure offering unlimited scalability and no transaction fees. RaiBlocks by design is a simple protocol with the sole purpose of being a high-performance cryptocurrency. The RaiBlocks protocol can run on low-power hardware, allowing it to be a practical, decentralized cryptocurrency for everyday use.</p> <p>Cryptocurrency statistics reported in this paper are accurate as of publication date.</p>","title":"Introduction"},{"location":"whitepaper/english/#background","text":"<p>In 2008, an anonymous individual under the pseudonym Satoshi Nakamoto published a whitepaper outlining the world's first decentralized cryptocurrency, Bitcoin 1. A key innovation brought about by Bitcoin was the blockchain, a public, immutable and decentralized data-structure which is used as a ledger for the currency's transactions. Unfortunately, as Bitcoin matured, several issues in the protocol made Bitcoin prohibitive for many applications:</p> <ol> <li> <p>Poor scalability: Each block in the blockchain can store a limited     amount of data, which means the system can only process so many     transactions per second, making spots in a block a commodity.     Currently the median transaction fee is $10.38 2.</p> </li> <li> <p>High latency: The average confirmation time is 164 minutes     3.</p> </li> <li> <p>Power inefficient: The Bitcoin network consumes an estimated     27.28TWh per year, using on average 260KWh per transaction     4.</p> </li> </ol> <p>Bitcoin, and other cryptocurrencies, function by achieving consensus on their global ledgers in order to verify legitimate transactions while resisting malicious actors. Bitcoin achieves consensus via an economic measure called Proof of Work (PoW). In a PoW system, participants compete in computing a number, called a nonce, such that the hash of the entire block is in a target range. This valid range is inversely proportional to the cumulative computation power of the entire Bitcoin network in order to maintain a consistent average time taken to find a valid nonce. The finder of a valid nonce is then allowed to add the block to the blockchain; therefore, those who exhaust more computational resources to compute a nonce play a greater role in the state of the blockchain. PoW provides resistance against a Sybil attack, where an entity behaves as multiple entities to gain additional power in a decentralized system, and also greatly reduces race conditions that inherently exist while accessing a global data-structure.</p> <p>An alternative consensus protocol, Proof of Stake (PoS), was first introduced by Peercoin in 2012 5. In a PoS system, participants vote with a weight equivalent to the amount of wealth they possess in a given cryptocurrency. With this arrangement, those who have a greater financial investment are given more power and are inherently incentivized to maintain the honesty of the system or risk losing their investment. PoS does away with the wasteful computation power competition, only requiring light-weight software running on low power hardware.</p> <p>The original RaiBlocks paper and first beta implementation were published in December, 2014, making it one of the first Directed Acyclic Graph (DAG) based cryptocurrencies 6. Soon after, other DAG cryptocurrencies began to develop, most notably DagCoin/Byteball and IOTA 78. These DAG-based cryptocurrencies broke the blockchain mold, improving system performance and security. Byteball achieves consensus by relying on a \"main-chain\" comprised of honest, reputable and user-trusted \"witnesses\", while IOTA achieves consensus via the cumulative PoW of stacked transactions. RaiBlocks achieves consensus via a balance-weighted vote on conflicting transactions. This consensus system provides quicker, more deterministic transactions while still maintaining a strong, decentralized system. RaiBlocks continues this development and has positioned itself as one of the highest performing cryptocurrencies.</p>","title":"Background"},{"location":"whitepaper/english/#raiblocks-components","text":"<p>Before describing the overall RaiBlocks architecture, we define the individual components that make up the system.</p>","title":"RaiBlocks Components"},{"location":"whitepaper/english/#account","text":"<p>An account is the public-key portion of a digital signature key-pair. The public-key, also referred to as the address, is shared with other network participants while the private-key is kept secret. A digitally signed packet of data ensures that the contents were approved by the private-key holder. One user may control many accounts, but only one public address may exist per account.</p>","title":"Account"},{"location":"whitepaper/english/#blocktransaction","text":"<p>The term \"block\" and \"transaction\" are often used interchangeably, where a block contains a single transaction. Transaction specifically refers to the action, while block refers to the digital encoding of the transaction. Transactions are signed by the private-key belonging to the account on which the transaction is performed.</p>","title":"Block/Transaction"},{"location":"whitepaper/english/#ledger","text":"<p>The ledger is the global set of accounts where each account has its own transaction chain. This is a key design component that falls under the category of replacing a run-time agreement with a design-time agreement; everyone agrees via signature checking that only an account owner can modify their own chain. This converts a seemingly shared data-structure, a distributed ledger, into a set of non-shared ones.</p> graph TB     subgraph Account C     A[\"Block &lt;i&gt;N&lt;sub&gt;C&lt;/sub&gt;&lt;/i&gt;\"]--&gt;B[\"Block &lt;i&gt;N&lt;sub&gt;C&lt;/sub&gt;&lt;/i&gt;  - 1\"]     B--&gt;C[\"...\"]     C--&gt;D[\"Block 1\"]     D--&gt;E[\"Block 0\"]     end         subgraph Account B     F[\"Block &lt;i&gt;N&lt;sub&gt;B&lt;/sub&gt;&lt;/i&gt;\"]--&gt;G[\"Block &lt;i&gt;N&lt;sub&gt;B&lt;/sub&gt;&lt;/i&gt;  - 1\"]     G--&gt;H[\"...\"]     H--&gt;I[\"Block 1\"]     I--&gt;J[\"Block 0\"]     end     subgraph Account A     K[\"Block &lt;i&gt;N&lt;sub&gt;A&lt;/sub&gt;&lt;/i&gt;\"]--&gt;L[\"Block &lt;i&gt;N&lt;sub&gt;A&lt;/sub&gt;&lt;/i&gt; - 1\"]     L--&gt;M[\"...\"]     M--&gt;N[\"Block 1\"]     N--&gt;O[\"Block 0\"]     end","title":"Ledger"},{"location":"whitepaper/english/#node","text":"<p>A node is a piece of software running on a computer that conforms to the RaiBlocks protocol and participates in the RaiBlocks network. The software manages the ledger and any accounts the node may control, if any. A node may either store the entire ledger or a pruned history containing only the last few blocks of each account's blockchain. When setting up a new node it is recommended to verify the entire history and prune locally.</p>","title":"Node"},{"location":"whitepaper/english/#system-overview","text":"<p>Unlike blockchains used in many other cryptocurrencies, RaiBlocks uses a block-lattice structure. Each account has its own blockchain (account-chain) equivalent to the account's transaction/balance history Each account-chain can only be updated by the account's owner; this allows each account-chain to be updated immediately and asynchronously to the rest of the block-lattice, resulting in quick transactions. RaiBlocks' protocol is extremely light-weight; each transaction fits within the required minimum UDP packet size for being transmitted over the internet. Hardware requirements for nodes are also minimal, since nodes only have to record and rebroadcast blocks for most transactions.</p> graph BT     subgraph Account C     idc4[Receive]--&gt;idc5((\"...\"))     idc3[Receive]---idc4     idc2[Receive]---idc3     idc1[Send]---idc2     end     subgraph Account B     idb4[Send]--&gt;idb5((\"...\"))     idb3[Send]---idb4     idb2[\"&amp;nbsp;\"]---idb3     idb1[Send]---idb2     end     subgraph Account A     ida4[Receive]--&gt;ida5((\"...\"))     ida3[Receive]---ida4     ida2[Send]---ida3     ida1[\"&amp;nbsp;\"]---ida2     end     idb1-.-&gt;idc4     ida2-.-&gt;idc3     idb3-.-&gt;ida4     idc1-.-&gt;ida3 <p>The system is initiated with a genesis account containing the genesis balance. The genesis balance is a fixed quantity and can never be increased. The genesis balance is divided and sent to other accounts via send transactions registered on the genesis account-chain. The sum of the balances of all accounts will never exceed the initial genesis balance which gives the system an upper bound on quantity and no ability to increase it.</p> <p>This section will walk through how different types of transactions are constructed and propagated throughout the network.</p>","title":"System Overview"},{"location":"whitepaper/english/#transactions","text":"<p>Transaction Flow</p> graph LR;   Receive--&gt;Repeat;   Repeat--&gt;Observe;   Observe--&gt;Quorum;   Quorum--&gt;Confirm; <p>(a) When no conflict is detected, no further overhead is required.</p> graph LR;   Receive--&gt;Repeat;   Repeat--&gt;Observe;   Observe--&gt;Conflict;   Conflict--&gt;Vote;   Vote--&gt;Confirm; <p>(b) In the event of a conflicting transaction, nodes vote for the valid transaction.</p> <p>Transferring funds from one account to another requires two transactions: a send deducting the amount from the sender's balance and a receive adding the amount to the receiving account's balance.</p> <p>Transferring amounts as separate transactions in the sender's and receiver's accounts serves a few important purposes:</p> <ol> <li> <p>Sequencing incoming transfers that are inherently asynchronous.</p> </li> <li> <p>Keeping transactions small to fit in UDP packets.</p> </li> <li> <p>Facilitating ledger pruning by minimizing the data footprint.</p> </li> <li> <p>Isolating settled transactions from unsettled ones.</p> </li> </ol> <p>More than one account transferring to the same destination account is an asynchronous operation; network latency and the sending accounts not necessarily being in communication with each other means there is no universally agreeable way to know which transaction happened first. Since addition is associative, the order the inputs are sequenced does not matter, and hence we simply need a global agreement. This is a key design component that converts a run-time agreement in to a design-time agreement. The receiving account has control over deciding which transfer arrived first and is expressed by the signed order of the incoming blocks.</p> <p>If an account wants to make a large transfer that was received as a set of many small transfers, we want to represent this in a way that fits within a UDP packet. When a receiving account sequences input transfers, it keeps a running total of its account balance so that at any time it has the ability to transfer any amount with a fixed size transaction. This differs from the input/output transaction model used by Bitcoin and other cryptocurrencies.</p> <p>Some nodes are uninterested in expending resources to store an account's full transaction history; they are only interested in each account's current balance. When an account makes a transaction, it encodes its accumulated balance and these nodes only need to keep track of the latest block, which allows them to discard historical data while maintaining correctness.</p> <p>Even with a focus on design-time agreements, there is a delay window when validating transactions due to identifying and handling bad actors in the network. Since agreements in RaiBlocks are reached quickly, on the order of milliseconds to seconds, we can present the user with two familiar categories of incoming transactions: settled and unsettled. Settled transactions are transactions where an account has generated receive blocks. Unsettled transactions have not yet been incorporated in to the receiver's cumulative balance. This is a replacement for the more complex and unfamiliar confirmations metric in other cryptocurrencies.</p>","title":"Transactions"},{"location":"whitepaper/english/#creating-an-account","text":"<p>To create an account, you need to issue an open transaction. An open transaction is always the first transaction of every account-chain and can be created upon the first receipt of funds. The account field stores the public-key (address) derived from the private-key that is used for signing. The source field contains the hash of the transaction that sent the funds. On account creation, a representative must be chosen to vote on your behalf; this can be changed later. The account can declare itself as its own representative.</p> <pre><code>open {\n   account: DC04354B1...AE8FA2661B2,\n   source: DC1E2B3F7C...182A0E26B4A,\n   representative: xrb_1anr...posrs,\n   work: 0000000000000000,\n   type: open,\n   signature: 83B0...006433265C7B204\n}\n</code></pre>","title":"Creating an Account"},{"location":"whitepaper/english/#account-balance","text":"<p>The account balance is recorded within the ledger itself. Rather than recording the amount of a transaction, verification requires checking the difference between the balance at the send block and the balance of the preceding block. The receiving account may then increment the previous balance as measured into the final balance given in the new receive block. This is done to improve processing speed when downloading high volumes of blocks. When requesting account history, amounts are already given.</p>","title":"Account Balance"},{"location":"whitepaper/english/#sending-from-an-account","text":"<p>To send from an address, the address must already have an existing open block, and therefore a balance. The previous field contains the hash of the previous block in the account-chain. The destination field contains the account for funds to be sent to. A send block is immutable once confirmed. Once broadcasted to the network, funds are immediately deducted from the balance of the sender's account and wait as pending until the receiving party signs a block to accept these funds. Pending funds should not be considered awaiting confirmation, as they are as good as spent from the sender's account and the sender cannot revoke the transaction.</p> <pre><code>send {\n   previous: 1967EA355...F2F3E5BF801,\n   balance: 010a8044a0...1d49289d88c,\n   destination: xrb_3w...m37goeuufdp,\n   work: 0000000000000000,\n   type: send,\n   signature: 83B0...006433265C7B204\n}\n</code></pre>","title":"Sending From an Account"},{"location":"whitepaper/english/#receiving-a-transaction","text":"<p>To complete a transaction, the recipient of sent funds must create a receive block on their own account-chain. The source field references the hash of the associated send transaction. Once this block is created and broadcasted, the account's balance is updated and the funds have officially moved into their account.</p> <pre><code>receive {\n   previous: DC04354B1...AE8FA2661B2,\n   source: DC1E2B3F7C6...182A0E26B4A,\n   work: 0000000000000000,\n   type: receive,\n   signature: 83B0...006433265C7B204\n}\n</code></pre>","title":"Receiving a Transaction"},{"location":"whitepaper/english/#assigning-a-representative","text":"<p>Account holders having the ability to choose a representative to vote on their behalf is a powerful decentralization tool that has no strong analog in Proof of Work or Proof of Stake protocols. In conventional PoS systems, the account owner's node must be running to participate in voting. Continuously running a node is impractical for many users; giving a representative the power to vote on an account's behalf relaxes this requirement. Account holders have the ability to reassign consensus to any account at any time. A change transaction changes the representative of an account by subtracting the vote weight from the old representative and adding the weight to the new representative. No funds are moved in this transaction, and the representative does not have spending power of the account's funds.</p> <pre><code>change {\n   previous: DC04354B1...AE8FA2661B2,\n   representative: xrb_1anrz...posrs,\n   work: 0000000000000000,\n   type: change,\n   signature: 83B0...006433265C7B204\n}\n</code></pre>","title":"Assigning a Representative"},{"location":"whitepaper/english/#forks-and-voting","text":"<p>A fork occurs when j signed blocks b_1, b_2, \\dots, b_jb_1, b_2, \\dots, b_j claim the same block as their predecessor.</p> graph RL     subgraph Account A     ida3[\"Block &lt;i&gt;i&lt;/i&gt; + 1\"]---ida4[\"Block &lt;i&gt;i&lt;/i&gt;\"]     ida2[\"Block &lt;i&gt;i&lt;/i&gt; + 2\"]--&gt;ida3     ida1[\"Block &lt;i&gt;i&lt;/i&gt; + 2\"]--&gt;ida3     end <p>These blocks cause a conflicting view on the status of an account and must be resolved. Only the account's owner has the ability to sign blocks into their account-chain, so a fork must be the result of poor programming or malicious intent (double-spend) by the account's owner.</p> <p>Upon detection, a representative will create a vote referencing the block \\hat{b}_i\\hat{b}_i in its ledger and broadcast it to the network. The weight of a node's vote, w_iw_i, is the sum of the balances of all accounts that have named it as its representative. The node will observe incoming votes from the other MM online representatives and keep a cumulative tally for 4 voting periods, 1 minute total, and confirm the winning block.</p>  \\begin{aligned}    v(b_j) &amp;= \\sum_{i=1}^M w_i{1}_{\\hat{b}_i=b_j} \\label{eq:weighted_vote} \\\\    b^* &amp;= \\mathop{\\mathrm{arg\\,max}}_{b_j} v(b_j) \\label{eq:most_votes}\\end{aligned} \\begin{aligned}    v(b_j) &amp;= \\sum_{i=1}^M w_i{1}_{\\hat{b}_i=b_j} \\label{eq:weighted_vote} \\\\    b^* &amp;= \\mathop{\\mathrm{arg\\,max}}_{b_j} v(b_j) \\label{eq:most_votes}\\end{aligned}  <p>The most popular block b^*b^* will have the majority of the votes and will be retained in the node's ledger. The block(s) that lose the vote are discarded. If a representative replaces a block in its ledger, it will create a new vote with a higher sequence number and broadcast the new vote to the network. This is the only scenario where representatives vote.</p> <p>In some circumstances, brief network connectivity issues may cause a broadcasted block to not be accepted by all peers. Any subsequent block on this account will be ignored as invalid by peers that did not see the initial broadcast. A rebroadcast of this block will be accepted by the remaining peers and subsequent blocks will be retrieved automatically. Even when a fork or missing block occurs, only the accounts referenced in the transaction are affected; the rest of the network proceeds with processing transactions for all other accounts.</p>","title":"Forks and Voting"},{"location":"whitepaper/english/#proof-of-work","text":"<p>All four transaction types have a work field that must be correctly populated. The work field allows the transaction creator to compute a nonce such that the hash of the nonce concatenated with the previous field in receive/send/change transactions or the account field in an open transaction is below a certain threshold value. Unlike Bitcoin, the PoW in RaiBlocks is simply used as an anti-spam tool, similar to Hashcash, and can be computed on the order of seconds 9. Once a transaction is sent, the PoW for the subsequent block can be precomputed since the previous block field is known; this will make transactions appear instantaneous to an end-user so long as the time between transactions is greater than the time required to compute the PoW.</p>","title":"Proof of Work"},{"location":"whitepaper/english/#transaction-verification","text":"<p>For a block to be considered valid, it must have the following attributes:</p> <ol> <li> <p>The block must not already be in the ledger (duplicate transaction).</p> </li> <li> <p>Must be signed by the account's owner.</p> </li> <li> <p>The previous block is the head block of the account-chain. If it     exists but is not the head, it is a fork.</p> </li> <li> <p>The account must have an open block.</p> </li> <li> <p>The computed hash meets the PoW threshold requirement.</p> </li> </ol> <p>If it is a receive block, check if the source block hash is pending, meaning it has not already been redeemed. If it is a send block, the balance must be less than the previous balance.</p>","title":"Transaction Verification"},{"location":"whitepaper/english/#attack-vectors","text":"<p>RaiBlocks, like all decentralized cryptocurrencies, may be attacked by malicious parties for attempted financial gain or system demise. In this section we outline a few possible attack scenarios, the consequences of such an attack, and how RaiBlock's protocol takes preventative measures.</p>","title":"Attack Vectors"},{"location":"whitepaper/english/#block-gap-synchronization","text":"<p>In a previous section, we discussed the scenario where a block may not be properly broadcasted, causing the network to ignore subsequent blocks. If a node observes a block that does not have the referenced previous block, it has two options:</p> <ol> <li> <p>Ignore the block as it might be a malicious garbage block.</p> </li> <li> <p>Request a resync with another node.</p> </li> </ol> <p>In the case of a resync, a TCP connection must be formed with a bootstrapping node to facilitate the increased amount of traffic a resync requires. However, if the block was actually a bad block, then the resync was unnecessary and needlessly increased traffic on the network. This is a Network Amplification Attack and results in a denial-of-service.</p> <p>To avoid unnecessary resyncing, nodes will wait until a certain threshold of votes have been observed for a potentially malicious block before initiating a connection to a bootstrap node to synchronize. If a block doesn't receive enough votes it can be assumed to be junk data.</p>","title":"Block Gap Synchronization"},{"location":"whitepaper/english/#transaction-flooding","text":"<p>A malicious entity could send many unnecessary but valid transactions between accounts under its control in an attempt to saturate the network. With no transaction fees, they are able to continue this attack indefinitely. However, the PoW required for each transaction limits the transaction rate the malicious entity could generate without significantly investing in computational resources. Even under such an attack in an attempt to inflate the ledger, nodes that are not full historical nodes are able to prune old transactions from their chain; this clamps the storage usage from this type of attack for almost all users.</p>","title":"Transaction Flooding"},{"location":"whitepaper/english/#sybil-attack","text":"<p>An entity could create hundreds of RaiBlocks nodes on a single machine; however, since the voting system is weighted based on account balance, adding extra nodes into the network will not gain an attacker extra votes. Therefore there is no advantage to be gained via a Sybil attack.</p>","title":"Sybil Attack"},{"location":"whitepaper/english/#penny-spend-attack","text":"<p>A penny-spend attack is where an attacker spends infinitesimal quantities to a large number of accounts in order to waste the storage resources of nodes. Block publishing is rate-limited by the PoW, so this limits the creation of accounts and transactions to a certain extent. Nodes that are not full historical nodes can prune accounts below a statistical metric where the account is most likely not a valid account. Finally, RaiBlocks is tuned to use minimal permanent storage space, so space required to store one additional account is proportional to the size of an \\text{open block} + \\text{indexing} = 96\\text{B} + 32\\text{B} = 128\\text{B}\\text{open block} + \\text{indexing} = 96\\text{B} + 32\\text{B} = 128\\text{B}. This equates to 1GB being able to store 8 million penny-spend account. If nodes wanted to prune more aggressively, they can calculate a distribution based on access frequency and delegate infrequently used accounts to slower storage.</p>","title":"Penny-Spend Attack"},{"location":"whitepaper/english/#precomputed-pow-attack","text":"<p>Since the owner of an account will be the only entity adding blocks to the account-chain, sequential blocks can be computed, along with their PoW, before being broadcasted to the network. Here the attacker generates a myriad of sequential blocks, each of minimal value, over an extended period of time. At a certain point, the attacker performs a Denial of Service (DoS) by flooding the network with lots of valid transactions, which other nodes will process and echo as quickly as possible. This is an advanced version of the transaction flooding described in the Transaction flooding section. Such an attack would only work briefly, but could be used in conjunction with other attacks, such as a &gt;50% Attack to increase effectiveness. Transaction rate-limiting and other techniques are currently being investigated to mitigate attacks.</p>","title":"Precomputed PoW Attack"},{"location":"whitepaper/english/#50-attack","text":"<p>The metric of consensus for RaiBlocks is a balance weighted voting system. If an attacker is able to gain over 50% of the voting strength, they can cause the network to oscillate consensus rendering the system broken. An attacker is able to lower the amount of balance they must forfeit by preventing good nodes from voting through a network DoS. RaiBlocks takes the following measures to prevent such an attack:</p> <ol> <li> <p>The primary defense against this type of attack is voting-weight     being tied to investment in the system. An account holder is     inherently incentivized to maintain the honesty of the system to     protect their investment. Attempting to flip the ledger would be     destructive to the system as a whole which would destroy their     investment.</p> </li> <li> <p>The cost of this attack is proportional to the market capitalization     of RaiBlocks. In PoW systems, technology can be invented that gives     disproportionate control compared to monetary investment and if the     attack is successful, this technology could be repurposed after the     attack is complete. With RaiBlocks the cost of attacking the system     scales with the system itself and if an attack were to be successful     the investment in the attack cannot be recovered.</p> </li> <li> <p>In order to maintain the maximum quorum of voters, the next line of     defense is representative voting. Account holders who are unable to     reliably participate in voting for connectivity reasons can name a     representative who can vote with the weight of their balance.     Maximizing the number and diversity of representatives increases     network resiliency.</p> </li> <li> <p>Forks in RaiBlocks are never accidental, so nodes can make policy     decisions on how to interact with forked blocks. The only time     non-attacker accounts are vulnerable to block forks is if they     receive a balance from an attacking account. Accounts wanting to be     secure from block forks can wait a little or a lot longer before     receiving from an account who generated forks or opt to never     receive at all. Receivers could also generate separate accounts to     use when receiving funds from dubious accounts in order to insulate     other accounts.</p> </li> <li> <p>A final line of defense that has not yet been implemented is block     cementing. RaiBlocks goes to great lengths to settle block forks     quickly via voting. Nodes could be configured to cement blocks,     which would prevent them from being rolled back after a certain     period of time. The network is sufficiently secured through focusing     on fast settling time to prevent ambiguous forks.</p> </li> </ol> <p>A more sophisticated version of a &gt;50\\%&gt;50\\% attack is detailed below. \"Offline\" is the percentage of representatives who have been named but are not online to vote. \"Stake\" is the amount of investment the attacker is voting with. \"Active\" is representatives that are online and voting according to the protocol. An attacker can offset the amount of stake they must forfeit by knocking other voters offline via a network DoS attack. If this attack can be sustained, the representatives being attacked will become unsynchronized, and this is demonstrated by \"Unsync.\" Finally, an attacker can gain a short burst in relative voting strength by switching their Denial of Service attack to a new set of representatives while the old set is re-synchronizing their ledger, this is demonstrated by \"Attack.\"</p> <p>If an attacker is able to cause Stake &gt;Active by a combination of these circumstances, they would be able to successfully flip votes on the ledger at the expense of their stake. We can estimate how much this type of attack could cost by examining the market cap of other systems. If we estimate 33% of representatives are offline or attacked via DoS, an attacker would need to purchase 33% of the market cap in order to attack the system via voting.</p>","title":"&gt;50% Attack"},{"location":"whitepaper/english/#bootstrap-poisoning","text":"<p>The longer an attacker is able to hold an old private-key with a balance, the higher the probability that balances that existed at that time will not have participating representatives because their balances or representatives have transferred to newer accounts. This means if a node is bootstrapped to an old representation of the network where the attacker has a quorum of voting stake compared to representatives at that point in time, they would be able to oscillate voting decisions to that node. If this new user wanted to interact with anyone besides the attacking node all of their transactions would be denied since they have different head blocks. The net result is nodes can waste the time of new nodes in the network by feeding them bad information. To prevent this, nodes can be paired with an initial database of accounts and known-good block heads; this is a replacement for downloading the database all the way back to the genesis block. The closer the download is to being current, the higher the probability of accurately defending against this attack. In the end, this attack is probably no worse than feeding junk data to nodes while bootstrapping, since they wouldn't be able to transact with anyone who has a contemporary database.</p>","title":"Bootstrap Poisoning"},{"location":"whitepaper/english/#implementation","text":"<p>Currently, the reference implementation is implemented in C++ and has been producing releases since 2014 on Github 10.</p>","title":"Implementation"},{"location":"whitepaper/english/#design-features","text":"<p>The RaiBlocks implementation adheres to the architecture standard outlined in this paper. Additional specifications are described here.</p>","title":"Design Features"},{"location":"whitepaper/english/#signing-algorithm","text":"<p>RaiBlocks uses a modified ED25519 elliptic curve algorithm with Blake2b hashing for all digital signatures 11. ED25519 was chosen for fast signing, fast verification, and high security.</p>","title":"Signing Algorithm"},{"location":"whitepaper/english/#hashing-algorithm","text":"<p>Since the hashing algorithm is only used to prevent network spam, the algorithm choice is less important when compared to mining-based cryptocurrencies. Our implementation uses Blake2b as a digest algorithm against block contents 12.</p>","title":"Hashing Algorithm"},{"location":"whitepaper/english/#key-derivation-function","text":"<p>In the reference wallet, keys are encrypted by a password and the password is fed through a key derivation function to protect against ASIC cracking attempts. Presently Argon2 13 is the winner of the only public competition aimed at creating a resilient key derivation function.</p>","title":"Key Derivation Function"},{"location":"whitepaper/english/#block-interval","text":"<p>Since each account has its own blockchain, updates can be performed asynchronous to the state of network. Therefore there are no block intervals and transactions can be published instantly.</p>","title":"Block Interval"},{"location":"whitepaper/english/#udp-message-protocol","text":"<p>Our system is designed to operate indefinitely using the minimum amount of computing resources as possible. All messages in the system were designed to be stateless and fit within a single UDP packet. This also makes it easier for lite peers with intermittent connectivity to participate in the network without reestablishing short-term TCP connections. TCP is used only for new peers when they want to bootstrap the block chains in a bulk fashion.</p> <p>Nodes can be sure their transaction was received by the network by observing transaction broadcast traffic from other nodes as it should see several copies echoed back to itself.</p>","title":"UDP Message Protocol"},{"location":"whitepaper/english/#ipv6-and-multicast","text":"<p>Building on top of connection-less UDP allows future implementations to use IPv6 multicast as a replacement for traditional transaction flooding and vote broadcast. This will reduce network bandwidth consumption and give more policy flexibility to nodes going forward.</p>","title":"IPv6 and Multicast"},{"location":"whitepaper/english/#performance","text":"<p>At the time of this writing, 4.2 million transactions have been processed by the RaiBlocks network, yielding a blockchain size of 1.7GB. Transaction times are measured on the order of seconds. A current reference implementation operating on commodity SSDs can process over 10,000 transactions per second being primarily IO bound.</p>","title":"Performance"},{"location":"whitepaper/english/#resource-usage","text":"<p>This is an overview of resources used by a RaiBlocks node. Additionally, we go over ideas for reducing resource usage for specific use cases. Reduced nodes are typically called light, pruned, or simplified payment verification (SPV) nodes.</p>","title":"Resource Usage"},{"location":"whitepaper/english/#network","text":"<p>The amount of network activity depends on how much the network contributes towards the health of a network.</p> <p>Representative</p> <p>A representative node requires maximum network resources as it observes vote traffic from other representatives and publishes its own votes.</p> <p>Trustless</p> <p>A trustless node is similar to a representative node but is only an observer, it doesn't contain a representative account private key and does not publish votes of its own.</p> <p>Trusting</p> <p>A trusting node observes vote traffic from one representative it trusts to correctly perform consensus. This cuts down on the amount of inbound vote traffic from representatives going to this node.</p> <p>Light</p> <p>A light node is also a trusting node that only observes traffic for accounts in which it is interested allowing minimal network usage.</p> <p>Bootstrap</p> <p>A bootstrap node serves up parts or all of the ledger for nodes that are bringing themselves online. This is done over a TCP connection rather than UDP since it involves a large amount of data that requires advanced flow control.</p>","title":"Network"},{"location":"whitepaper/english/#disk-capacity","text":"<p>Depending on the user demands, different node configurations require different storage requirements.</p> <p>Historical</p> <p>A node interested in keeping a full historical record of all transactions will require the maximum amount of storage.</p> <p>Current</p> <p>Due to the design of keeping accumulated balances with blocks, nodes only need to keep the latest or head blocks for each account in order to participate in consensus. If a node is uninterested in keeping a full history it can opt to keep only the head blocks.</p> <p>Light</p> <p>A light node keeps no local ledger data and only participates in the network to observe activity on accounts in which it is interested or optionally create new transactions with private keys it holds.</p>","title":"Disk Capacity"},{"location":"whitepaper/english/#cpu","text":"<p>Transaction Generating</p> <p>A node interested in creating new transactions must produce a Proof of Work nonce in order to pass RaiBlock's throttling mechanism. Computation of various hardware is benchmarked in Appendix A.</p> <p>Representative</p> <p>A representative must verify signatures for blocks, votes, and also produce its own signatures to participate in consensus. The amount of CPU resources for a representative node is significantly less than transaction generating and should work with any single CPU in a contemporary computer.</p> <p>Observer</p> <p>An observer node doesn't generate its own votes. Since signature generation overhead is minimal, the CPU requirements are almost identical to running a representative node.</p>","title":"CPU"},{"location":"whitepaper/english/#conclusion","text":"<p>In this paper we presented the framework for a trustless, feeless, low-latency cryptocurrency that utilizes a novel block-lattice structure and delegated Proof of Stake voting. The network requires minimal resources, no high-power mining hardware, and can process high transaction throughput. All of this is achieved by having individual blockchains for each account, eliminating access issues and inefficiencies of a global data-structure. We identified possible attack vectors on the system and presented arguments on how RaiBlocks is resistant to these forms of attacks.</p>","title":"Conclusion"},{"location":"whitepaper/english/#appendix-a-pow-hardware-benchmarks","text":"<p>As mentioned previously, the PoW in RaiBlocks is to reduce network spam. Our node implementation provides acceleration that can take advantage of OpenCL compatible GPUs. Table\u00a0I below provides a real-life benchmark comparison of various hardware. Currently the PoW threshold is fixed, but an adaptive threshold may be implemented as average computing power progresses.</p> <p>Table I Hardware PoW Performance</p>    Device Transactions Per Second     Nvidia Tesla V100 (AWS) 6.4   Nvidia Tesla P100 (Google,Cloud) 4.9   Nvidia Tesla K80 (Google,Cloud) 1.64   AMD RX 470 OC 1.59   Nvidia GTX 1060 3GB 1.25   Intel Core i7 4790K AVX2 0.33   Intel Core i7 4790K,WebAssembly (Firefox) 0.14   Google Cloud 4 vCores 0.14-0.16   ARM64 server 4 cores (Scaleway) 0.05-0.07","title":"Appendix A: PoW Hardware benchmarks"},{"location":"whitepaper/english/#acknowledgment","text":"<p>We would like to thank Brian Pugh and B. Cchung for compiling and formatting this paper.</p>","title":"Acknowledgment"},{"location":"whitepaper/english/#references","text":"<ol> <li> <p>S. Nakamoto, \u201cBitcoin: A peer-to-peer electronic cash system,\u201d 2008. [Online]. Available: http://bitcoin.org/bitcoin.pdf \u21a9\u21a9</p> </li> <li> <p>\u201cBitcoin median transaction fee historical chart.\u201d [Online]. Available: https://bitinfocharts.com/comparison/bitcoin-median-transaction-fee.html \u21a9</p> </li> <li> <p>\u201cBitcoin average confirmation time.\u201d [Online]. Available: https://blockchain.info/charts/avg-confirmation-time \u21a9</p> </li> <li> <p>\u201cBitcoin energy consumption index.\u201d [Online]. Available: https://digiconomist.net/bitcoin-energy-consumption \u21a9</p> </li> <li> <p>S. King and S. Nadal, \u201cPpcoin: Peer-to-peer crypto-currency withproof-of-stake,\u201d 2012. [Online]. Available: https://peercoin.net/assets/paper/peercoin-paper.pdf \u21a9</p> </li> <li> <p>C. LeMahieu, \u201cRaiblocks distributed ledger network,\u201d 2014.\u00a0\u21a9</p> </li> <li> <p>Y. Ribero and D. Raissar, \u201cDagcoin whitepaper,\u201d 2015.\u00a0\u21a9</p> </li> <li> <p>S. Popov, \u201cThe tangle,\u201d 2016.\u00a0\u21a9</p> </li> <li> <p>A. Back, \u201cHashcash - a denial of service counter-measure,\u201d 2002. [Online]. Available: http://www.hashcash.org/papers/hashcash.pdf \u21a9</p> </li> <li> <p>C. LeMahieu, \u201cRaiblocks,\u201d 2014. [Online]. Available: https://github.com/clemahieu/raiblocks \u21a9</p> </li> <li> <p>D. J. Bernstein, N. Duif, T. Lange, P. Shwabe, and B.-Y. Yang, \u201cHigh-speed high-security signatures,\u201d 2011. [Online]. Available: http://ed25519.cr.yp.to/ed25519-20110926.pdf \u21a9</p> </li> <li> <p>J.-P. Aumasson, S. Neves, Z. Wilcox-O\u2019Hearn, and C. Winnerlein, \u201cBlake2: Simpler, smaller, fast as md5,\u201d 2012. [Online]. Available: https://blake2.net/blake2.pdf \u21a9</p> </li> <li> <p>A. Biryukov, D. Dinu, and D. Khovratovich, \u201cArgon2: The memoryhard function for password hashing and other applications,\u201d 2015. [Online]. Available: https://password-hashing.net/argon2-specs.pdf \u21a9</p> </li> </ol>","title":"References"}]})